{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reacher - robot arm controller.\n",
    "\n",
    "---\n",
    "\n",
    "Created by Jesper Højmark Esbensen, 2018-10-30.\n",
    "\n",
    "This note book will create and train an agent to control the 'robot arm' in the Unity Machine Learning environment Reacher. The solution is based on the general deep reenforcement learning agent supplied in the cource [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "<img src=\"Reacher20.png\",width=750>\n",
    "\n",
    "The environment consists of a 'robot arm' with a 'hand' that the agent must control to touch a goal. The goal is a sphere that is rotating around the robot with different speed and direction of each episode. An episode is 1000 steps in the environment.\n",
    "\n",
    "A variant of the environment contains the same setup but with 20 robot arms.\n",
    "\n",
    "These and a number of other environments from Unity can be found here. [Unity environments](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Learning-Environment-Examples.md#reacher).\n",
    "\n",
    "\n",
    "### 1. Installation instructions\n",
    "\n",
    "Installation instructions can be found in the readme.md file in the github repository: https://github.com/JesperEsbensen/drlnd-continuous-contro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. This solution\n",
    "\n",
    "The solution in this note book is heavely inspired by the solution to the bi-pedal environment given in the repository: https://github.com/udacity/deep-reinforcement-learning/tree/master/ddpg-bipedal\n",
    "\n",
    "It has been modified to handle the reacher environment and the rebuild to handle multiple executions of the excercise.\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "The implementation is based on the Deep Deterministic Policy Gradient algorithme described in the paper:\n",
    "\n",
    "[Continuous control with deep reinforcement learning](https://arxiv.org/abs/1509.02971)\n",
    "\n",
    "The algorithm has shown to performe in different simulated environments. It is a continuous algorithm and therefore suitable for the reaher envrionment. \n",
    "The algorithm is based on the Deterministic Policy Gradient (DPG) method that is created around an actor-critic setup. To make the algorithm stable it uses a \"replay buffer\" and \"target/local network\". To add exploration it introduces noise to calculated actions.\n",
    "\n",
    "\n",
    "#### An experiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The code \n",
    "\n",
    "#### Imports\n",
    "This cell handles the imports of the Unity environment, pyTorch and python modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Unity for the environment\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "# Import for file handling.\n",
    "import os\n",
    "\n",
    "# Import numpy for the math\n",
    "import numpy as np\n",
    "\n",
    "# Import torch for the AI\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# A little extra than standard python.\n",
    "from collections import namedtuple, deque\n",
    "import random\n",
    "import copy\n",
    "\n",
    "# Time for timing\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment\n",
    "This cell defines a class for handling a Unity environment. It helps handle the start, close down and the extraction of values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Environment ():\n",
    "    \n",
    "    # Encapsulates the environment and enables the use of 'with' to handle open/close.\n",
    "    \n",
    "    def __init__(self, envFile):\n",
    "        \"\"\"Initialize parameters for environment.\n",
    "        Params\n",
    "        ======\n",
    "            envFile (string): Path to envrionment executable\n",
    "        \"\"\"\n",
    "        self.filename = envFile\n",
    "        self.env = UnityEnvironment(file_name=envFile)\n",
    "            \n",
    "        # get the default brain\n",
    "        self.brain_name = self.env.brain_names[0]\n",
    "        self.brain = self.env.brains[self.brain_name]\n",
    "\n",
    "        # reset the environment\n",
    "        self.env_info = self.env.reset(train_mode=True)[self.brain_name]\n",
    "        \n",
    "        print ('Created unity enviroment from ', envFile)\n",
    "        self.dump_key_attributes()\n",
    "        \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "            \n",
    "    def state_size(self):\n",
    "        return self.env_info.vector_observations.shape[1]\n",
    "        \n",
    "    def action_size(self):\n",
    "        return self.brain.vector_action_space_size\n",
    "\n",
    "    def agent_size(self):\n",
    "        return len(self.env_info.agents)\n",
    "    \n",
    "    def reset(self, train_mode=True):\n",
    "        self.env_info = self.env.reset(train_mode=True)[self.brain_name]\n",
    "        return self.env_info.vector_observations, self.env_info.rewards, self.env_info.local_done\n",
    "\n",
    "    def step(self, actions):\n",
    "        self.env_info = self.env.step(actions)[self.brain_name]\n",
    "        return self.env_info.vector_observations, self.env_info.rewards, self.env_info.local_done\n",
    "\n",
    "    def states(self, train_mode=True):\n",
    "        return self.env.reset(train_mode=True)[self.brain_name]\n",
    "    \n",
    "    def dump_key_attributes (self):\n",
    "        print('Environment     :', self.filename)\n",
    "        print('Number of agents:', self.agent_size())\n",
    "        print('State size      :', self.state_size())\n",
    "        print('Action size     :', self.action_size())\n",
    "        \n",
    "    def end():\n",
    "        self.env.close()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility\n",
    "An utility function for initializing a layer in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return -lim, lim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actor network\n",
    "The actor network to determin the actions to take from the given state. \n",
    "The network is build up from experiments. The structure is:\n",
    "\n",
    "- fully connecte layer -> batch nomalization -> relu ->  fully connecte layer -> relu -> tanh\n",
    "\n",
    "where the first fully connected layer takes a vector with the size of the states. An the final tanh layer delivers a vector of actions to take in the range ]-1,1[\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=132, fc2_units=132):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        f,t = hidden_init(self.fc1)\n",
    "        self.fc1.weight.data.uniform_(f,t)\n",
    "        f,t = hidden_init(self.fc2)\n",
    "        self.fc2.weight.data.uniform_(f,t)\n",
    "        self.fc3.weight.data.uniform_(-3e-3,3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "        x = self.fc1(state)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)        \n",
    "        x = self.fc3(x)\n",
    "        x = torch.tanh(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global settings - hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e6)  # replay buffer size\n",
    "BATCH_SIZE = 256        # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR_ACTOR = 1e-3         # learning rate of the actor \n",
    "LR_CRITIC = 1e-3        # learning rate of the critic\n",
    "WEIGHT_DECAY = 0.00     # L2 weight decay\n",
    "NOISE_SIGMA = 0.20\n",
    "NOISE_THETA = 0.15 \n",
    "NOISE_DECAY = 0.99997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critic network\n",
    "The critic network to estimate the value of taking an action - the reward. \n",
    "The network is build up from experiments. The structure is:\n",
    "\n",
    "- (states + actions) -> fully connected layer -> batch nomalization -> relu -> fully connected layer -> relu -> fully connected layer\n",
    "                                           \n",
    "The states are passed through a first layer then concatenated with the actions and passed through another layer to end with one value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic (Value) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=148, fc2_units=148):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fcs1_units (int): Number of nodes in the first hidden layer\n",
    "            fc2_units (int): Number of nodes in the second hidden layer\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.bn1 = nn.BatchNorm1d(fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units + action_size, fc2_units)\n",
    "        self.bn2 = nn.BatchNorm1d(fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, 1)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        f,t = hidden_init(self.fc1)\n",
    "        self.fc1.weight.data.uniform_(f,t)\n",
    "        f,t = hidden_init(self.fc2)\n",
    "        self.fc2.weight.data.uniform_(f,t)\n",
    "        self.fc3.weight.data.uniform_(-3e-3,3e-3)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"Build a critic (value) network that maps (state, action) pairs -> Q-values.\"\"\"\n",
    "        x = self.fc1(state)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.cat((x, action), dim=1)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Agent\n",
    "\n",
    "The agent handles the networks: actor, critic and thier target and local versions. It handles the noice generator, the replay buffer, the act and learn steps.\n",
    "Note that a decay rate of the noice has been build in. This way the noise is higher in the beginning and becomes lower with the number of steps taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, environment, random_seed, reward_level=-1.0):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            random_seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.env = environment\n",
    "        \n",
    "        self.state_size = self.env.state_size()\n",
    "        self.action_size = self.env.action_size()\n",
    "        self.agent_size = self.env.agent_size()\n",
    "        self.seed = random.seed(random_seed)\n",
    "\n",
    "        # Actor Network (w/ Target Network)\n",
    "        fc1 = self.state_size * 4\n",
    "        fc2 = fc1\n",
    "        self.actor_local = Actor(self.state_size, self.action_size, random_seed, fc1_units=fc1, fc2_units=fc2).to(device)\n",
    "        self.actor_target = Actor(self.state_size, self.action_size, random_seed, fc1_units=fc1, fc2_units=fc2).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=LR_ACTOR)\n",
    "\n",
    "        # Critic Network (w/ Target Network)\n",
    "        fc1 = (self.state_size + self.action_size) * 4\n",
    "        fc2 = fc1\n",
    "        self.critic_local = Critic(self.state_size, self.action_size, random_seed, fc1_units=fc1, fc2_units=fc2).to(device)\n",
    "        self.critic_target = Critic(self.state_size, self.action_size, random_seed, fc1_units=fc1, fc2_units=fc2).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        # Noice processes\n",
    "        self.noise = []\n",
    "        self.noise_decay = NOISE_DECAY\n",
    "        for i in range(self.agent_size):\n",
    "            self.noise.append(OUNoise(self.action_size, random_seed, theta=NOISE_THETA , sigma=NOISE_SIGMA))\n",
    "        self.noise_rate = np.ones(self.agent_size)\n",
    "        self.noice_counter = 0\n",
    "        self.step_counter = 0\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(self.action_size, BUFFER_SIZE, BATCH_SIZE, random_seed, reward_level)\n",
    "        \n",
    "        print ('Created agent: states = ', self.state_size, ' actions = ', self.action_size, ' reward level = ', reward_level)\n",
    "\n",
    "    \n",
    "    def step(self, states, actions, rewards, next_states, dones):\n",
    "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "        self.step_counter += 1\n",
    "        \n",
    "        # Save experience / reward\n",
    "        for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "            self.memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "        # Learn, if enough samples are available in memory\n",
    "        if len(self.memory) > BATCH_SIZE and self.step_counter % 20 == 0:\n",
    "            for _ in range(10):\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, add_noise=True):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        state = torch.from_numpy(state).float().to(device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "            \n",
    "        self.actor_local.train()\n",
    "        \n",
    "        if add_noise:\n",
    "            self.noise_decay = self.noise_decay * NOISE_DECAY\n",
    "            self.noice_counter += 1\n",
    "            \n",
    "            for i in range(self.agent_size):\n",
    "                noise = self.noise[i].sample()\n",
    "                \n",
    "                if self.noice_counter % 500 == 0:\n",
    "                    self.noise_rate[i] = np.linalg.norm(noise  * self.noise_decay)/float(np.linalg.norm(action[i]))\n",
    "                    \n",
    "                action[i] += noise * self.noise_decay\n",
    "            \n",
    "        return action\n",
    "\n",
    "    def reset(self):\n",
    "        for noise in self.noise:\n",
    "            noise.reset()\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update policy and value parameters using given batch of experience tuples.\n",
    "        Q_targets = r + γ * critic_target(next_state, actor_target(next_state))\n",
    "        where:\n",
    "            actor_target(state) -> action\n",
    "            critic_target(state, action) -> Q-value\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        \n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # ---------------------------- update critic ---------------------------- #\n",
    "        # Get predicted next-state actions and Q values from target models\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        # Compute Q targets for current states (y_i)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        # Compute critic loss\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "            \n",
    "        # ---------------------------- update actor ---------------------------- #\n",
    "        # Compute actor loss\n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        # Minimize the loss\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "            \n",
    "        # ----------------------- update target networks ----------------------- #\n",
    "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_local, self.actor_target, TAU)     \n",
    "        \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model: PyTorch model (weights will be copied from)\n",
    "            target_model: PyTorch model (weights will be copied to)\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "            \n",
    "    def environment(self):\n",
    "        return self.env\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise\n",
    "\n",
    "Noise is introduced to the actions generated to enabled the network to explore \"alternative\" actions.\n",
    "Note that the Ornenstein-Uhlenbeck is modified to give negaive random numbers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.2):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.array([(random.random() - 0.5)*2 for i in range(len(x))])\n",
    "        #dx = self.theta * (self.mu - x) + self.sigma * np.array([random.random() for i in range(len(x))])\n",
    "        self.state = x + dx\n",
    "        \n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replay buffer\n",
    "\n",
    "The replay buffer is a buffer where tuples of stats, action, rewards are stored. They can in random order be sampled and used  in the learning process. By selecting the steps the correlation between steps is broken.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed, reward_level=-1.0):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): action size\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (): For random generation and initilization of the noise generator.\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  # Internal memory (deque)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reward_level = reward_level\n",
    "        self.add_counter = 0\n",
    "        self.rf = 0\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "    \n",
    "        # Every thousand steps we calculate the reward fraction.\n",
    "        self.add_counter += 1\n",
    "        if self.add_counter % 1000 == 0:\n",
    "            if len (self.memory) > 0:\n",
    "                self.rf = self.rewards () / len (self.memory)\n",
    "        \n",
    "        # We add all actions that gave a success, and only some that dident.\n",
    "        if reward > 0.0001:\n",
    "            self.memory.append(e)\n",
    "        else:\n",
    "            if self.rf > self.reward_level:\n",
    "                self.memory.append(e)        \n",
    "        \n",
    "    def rewards (self):\n",
    "        rewardCounter = 0\n",
    "        for entry in self.memory:\n",
    "            if entry.reward > 0:\n",
    "                rewardCounter += 1\n",
    "        return rewardCounter\n",
    "    \n",
    "    def reward_fraction(self):\n",
    "        return self.rf\n",
    "\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "        \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main loop\n",
    "\n",
    "The main loop drives the process of having the agent act in the environment.\n",
    "Loop episodes and timesteps to drive the environment, agent and learning.\n",
    "\n",
    "When the goal is reached the process will continue for another 25% episodes to see what happens. A loop will start from a set of actor/critics files if they exist. A set of actor and critics network is stored every time a better result is reached and a separate set when the goal is reached.\n",
    "\n",
    "In addition to the average score this the main loop will display:\n",
    "* reward fraction - number of actions with success of all of the stored actions (for the experiment)\n",
    "* Noice level - vector length of noise added compared to action vector.\n",
    "* Time - loop time of episode.\n",
    "\n",
    "For every episode if at better result has been achieved the parameters are stored. When the goal is reached the parameters are also stored - and kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ddpg(name, agent, n_episodes=200, max_t=1000, print_every=100, goal=30):\n",
    "    \n",
    "    checkpointfile = name + '-best_actor.pth'\n",
    "    if os.path.isfile(checkpointfile):\n",
    "        print('\\nLoading checkpoints - and continue learning:', checkpointfile)\n",
    "        agent.actor_local.load_state_dict(torch.load(name + '-best_actor.pth'))\n",
    "        agent.actor_target.load_state_dict(torch.load(name + '-best_actor.pth'))\n",
    "        agent.critic_local.load_state_dict(torch.load(name + '-best_critic.pth'))\n",
    "        agent.critic_target.load_state_dict(torch.load(name + '-best_critic.pth'))\n",
    "    else:\n",
    "        print('\\nRestart learning - no checkpoint file found:', checkpointfile)\n",
    "        \n",
    "    env = agent.environment()\n",
    "    \n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    best_score = 0\n",
    "    goal_passed = 0\n",
    "    goal_passed_counter = 0\n",
    "    \n",
    "    # Drive episodes.\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        states, rewards, dones = env.reset()\n",
    "        score_agents = np.zeros(env.agent_size())\n",
    "        \n",
    "        agent.reset()\n",
    "\n",
    "        for t in range(max_t):\n",
    "            \n",
    "            # Calculate best actions for this step.\n",
    "            actions = agent.act(states, True)\n",
    "            \n",
    "            # Determin next state.\n",
    "            next_states, rewards, dones = env.step(actions)  # send the action to the environment\n",
    "                \n",
    "            # Agent takes step and learns.\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "                \n",
    "            # Prepare next loop.\n",
    "            states = next_states\n",
    "            score_agents += rewards\n",
    "            \n",
    "            if np.any(dones):\n",
    "                break \n",
    "        \n",
    "        score = np.mean(score_agents)\n",
    "        scores_deque.append(score)\n",
    "        scores.append(score)\n",
    "        \n",
    "        score_average = np.mean(scores_deque)\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        # Store model parameters if it is better than the last best.\n",
    "        if score_average > best_score:\n",
    "            best_score = score_average\n",
    "            torch.save(agent.actor_local.state_dict(), name + '-best_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), name + '-best_critic.pth')\n",
    "            print('\\rEpisode {}, Average Score: {:.2f}, ({:.2f}/{:.2f}), Reward fraction {:.2f}\\tTime {:.2f}, Noise rate {:.3f}. Better model.'.format( \\\n",
    "                i_episode, np.mean(scores_deque), np.max(score_agents), np.min(score_agents), agent.memory.reward_fraction(), end - start, \\\n",
    "                sum(agent.noise_rate)/float(len(agent.noise_rate))))\n",
    "        else:\n",
    "            print('\\rEpisode {}, Average Score: {:.2f}, ({:.2f}/{:.2f}), Reward fraction {:.2f}\\tTime {:.2f}, Noise rate {:.3f}.'.format( \\\n",
    "                i_episode, np.mean(scores_deque), np.max(score_agents), np.min(score_agents), agent.memory.reward_fraction(), end - start, \\\n",
    "                sum(agent.noise_rate)/float(len(agent.noise_rate))), end=\"\" )\n",
    "        \n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}, Average Score: {:.2f}, ({:.2f}/{:.2f}), Reward fraction {:.2f}\\tTime {:.2f}, Noise rate {:.3f}.'.format( \\\n",
    "                i_episode, np.mean(scores_deque), np.max(score_agents), np.min(score_agents), agent.memory.reward_fraction(), end - start, \\\n",
    "                sum(agent.noise_rate)/float(len(agent.noise_rate))))\n",
    "            \n",
    "        if score_average >= goal:\n",
    "            if goal_passed == 0:\n",
    "                goal_passed = i_episode\n",
    "                \n",
    "                print('\\nGoal reached in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, score_average))\n",
    "                torch.save(agent.actor_local.state_dict(), name + '-goal_actor.pth')\n",
    "                torch.save(agent.critic_local.state_dict(), name + '-goal_critic.pth')\n",
    "            \n",
    "        if goal_passed > 0:\n",
    "            goal_passed_counter = goal_passed_counter + 1\n",
    "            \n",
    "        if goal_passed > 0 and goal_passed_counter > goal_passed * 0.2: # Run addtional 20% episodes to see what happens.\n",
    "            break\n",
    "            \n",
    "\n",
    "            \n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting\n",
    "\n",
    "Below you find two functions for plotting the scores collected. For one timeseries and for comparing two timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotScores (scores):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotCompareScores (score1, score2):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(1, len(score1)+1), score1)\n",
    "    plt.plot(np.arange(1, len(score2)+1), score2)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Execution\n",
    "\n",
    "#### Test the reward level experiment\n",
    "The two networks are executet and compared to see what effect the reward level experiment has.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created unity enviroment from  .\\Reacher_Windows_x86_64_20Agents\\Reacher.exe\n",
      "Environment     : .\\Reacher_Windows_x86_64_20Agents\\Reacher.exe\n",
      "Number of agents: 20\n",
      "State size      : 33\n",
      "Action size     : 4\n",
      "Created agent: states =  33  actions =  4  reward level =  -1.0\n",
      "\n",
      "Restart learning - no checkpoint file found: 20Agents-best_actor.pth\n",
      "Episode 1, Average Score: 0.69, (1.60/0.15), Reward fraction 0.02\tTime 11.79, Noise rate 0.318. Better model.\n",
      "Episode 2, Average Score: 0.82, (1.84/0.00), Reward fraction 0.02\tTime 11.37, Noise rate 0.314. Better model.\n",
      "Episode 3, Average Score: 0.88, (1.97/0.25), Reward fraction 0.03\tTime 11.31, Noise rate 0.242. Better model.\n",
      "Episode 4, Average Score: 0.88, (2.19/0.10), Reward fraction 0.03\tTime 11.51, Noise rate 0.216. Better model.\n",
      "Episode 5, Average Score: 0.91, (2.02/0.13), Reward fraction 0.03\tTime 11.42, Noise rate 0.206. Better model.\n",
      "Episode 7, Average Score: 0.94, (3.08/0.36), Reward fraction 0.03\tTime 11.69, Noise rate 0.182. Better model.\n",
      "Episode 8, Average Score: 0.96, (2.78/0.07), Reward fraction 0.03\tTime 11.54, Noise rate 0.178. Better model.\n",
      "Episode 9, Average Score: 0.99, (2.21/0.26), Reward fraction 0.03\tTime 11.85, Noise rate 0.173. Better model.\n",
      "Episode 10, Average Score: 1.06, (3.31/0.40), Reward fraction 0.03\tTime 11.98, Noise rate 0.178. Better model.\n",
      "Episode 11, Average Score: 1.14, (3.13/0.59), Reward fraction 0.03\tTime 12.07, Noise rate 0.157. Better model.\n",
      "Episode 12, Average Score: 1.28, (5.50/0.43), Reward fraction 0.04\tTime 12.24, Noise rate 0.153. Better model.\n",
      "Episode 13, Average Score: 1.39, (6.35/0.17), Reward fraction 0.04\tTime 12.42, Noise rate 0.160. Better model.\n",
      "Episode 14, Average Score: 1.49, (5.04/1.04), Reward fraction 0.04\tTime 12.55, Noise rate 0.175. Better model.\n",
      "Episode 15, Average Score: 1.66, (7.00/2.15), Reward fraction 0.05\tTime 12.68, Noise rate 0.146. Better model.\n",
      "Episode 16, Average Score: 1.85, (7.63/1.91), Reward fraction 0.05\tTime 13.03, Noise rate 0.169. Better model.\n",
      "Episode 17, Average Score: 2.09, (11.37/3.10), Reward fraction 0.06\tTime 13.05, Noise rate 0.144. Better model.\n",
      "Episode 18, Average Score: 2.49, (19.30/4.49), Reward fraction 0.07\tTime 13.36, Noise rate 0.141. Better model.\n",
      "Episode 19, Average Score: 3.06, (21.07/5.13), Reward fraction 0.08\tTime 13.44, Noise rate 0.145. Better model.\n",
      "Episode 20, Average Score: 3.69, (24.87/7.22), Reward fraction 0.10\tTime 13.71, Noise rate 0.157. Better model.\n",
      "Episode 21, Average Score: 4.28, (23.01/8.18), Reward fraction 0.11\tTime 13.89, Noise rate 0.160. Better model.\n",
      "Episode 22, Average Score: 4.91, (27.73/9.72), Reward fraction 0.13\tTime 13.93, Noise rate 0.127. Better model.\n",
      "Episode 23, Average Score: 5.79, (33.99/12.23), Reward fraction 0.15\tTime 14.31, Noise rate 0.177. Better model.\n",
      "Episode 24, Average Score: 6.57, (31.84/16.50), Reward fraction 0.17\tTime 14.20, Noise rate 0.173. Better model.\n",
      "Episode 25, Average Score: 7.44, (37.55/17.85), Reward fraction 0.19\tTime 15.35, Noise rate 0.183. Better model.\n",
      "Episode 26, Average Score: 8.29, (36.14/21.20), Reward fraction 0.21\tTime 14.54, Noise rate 0.159. Better model.\n",
      "Episode 27, Average Score: 9.14, (39.12/16.22), Reward fraction 0.24\tTime 14.73, Noise rate 0.243. Better model.\n",
      "Episode 28, Average Score: 9.97, (39.32/20.55), Reward fraction 0.26\tTime 14.91, Noise rate 0.211. Better model.\n",
      "Episode 29, Average Score: 10.84, (39.63/27.02), Reward fraction 0.28\tTime 15.15, Noise rate 0.230. Better model.\n",
      "Episode 30, Average Score: 11.58, (39.60/25.73), Reward fraction 0.30\tTime 15.25, Noise rate 0.238. Better model.\n",
      "Episode 31, Average Score: 12.39, (39.53/30.58), Reward fraction 0.32\tTime 15.37, Noise rate 0.210. Better model.\n",
      "Episode 32, Average Score: 13.11, (39.60/28.46), Reward fraction 0.33\tTime 15.51, Noise rate 0.234. Better model.\n",
      "Episode 33, Average Score: 13.75, (39.62/20.45), Reward fraction 0.35\tTime 15.63, Noise rate 0.150. Better model.\n",
      "Episode 34, Average Score: 14.38, (39.62/21.17), Reward fraction 0.37\tTime 15.80, Noise rate 0.231. Better model.\n",
      "Episode 35, Average Score: 14.98, (39.64/27.47), Reward fraction 0.38\tTime 15.92, Noise rate 0.217. Better model.\n",
      "Episode 36, Average Score: 15.54, (39.56/26.43), Reward fraction 0.39\tTime 16.18, Noise rate 0.208. Better model.\n",
      "Episode 37, Average Score: 16.13, (39.55/28.70), Reward fraction 0.41\tTime 16.41, Noise rate 0.211. Better model.\n",
      "Episode 38, Average Score: 16.70, (39.62/30.59), Reward fraction 0.42\tTime 16.47, Noise rate 0.217. Better model.\n",
      "Episode 39, Average Score: 17.27, (39.63/36.53), Reward fraction 0.44\tTime 16.74, Noise rate 0.190. Better model.\n",
      "Episode 40, Average Score: 17.71, (39.63/24.75), Reward fraction 0.45\tTime 16.78, Noise rate 0.212. Better model.\n",
      "Episode 41, Average Score: 18.22, (39.60/36.82), Reward fraction 0.46\tTime 16.97, Noise rate 0.182. Better model.\n",
      "Episode 42, Average Score: 18.70, (39.63/21.06), Reward fraction 0.47\tTime 17.16, Noise rate 0.171. Better model.\n",
      "Episode 43, Average Score: 19.16, (39.64/30.59), Reward fraction 0.48\tTime 17.27, Noise rate 0.178. Better model.\n",
      "Episode 44, Average Score: 19.60, (39.65/31.29), Reward fraction 0.50\tTime 17.52, Noise rate 0.195. Better model.\n",
      "Episode 45, Average Score: 20.01, (39.60/34.93), Reward fraction 0.51\tTime 17.59, Noise rate 0.143. Better model.\n",
      "Episode 46, Average Score: 20.41, (39.61/32.34), Reward fraction 0.52\tTime 17.75, Noise rate 0.164. Better model.\n",
      "Episode 47, Average Score: 20.78, (39.63/34.56), Reward fraction 0.52\tTime 17.94, Noise rate 0.134. Better model.\n",
      "Episode 48, Average Score: 21.17, (39.67/36.61), Reward fraction 0.53\tTime 18.04, Noise rate 0.159. Better model.\n",
      "Episode 49, Average Score: 21.52, (39.62/33.80), Reward fraction 0.54\tTime 18.19, Noise rate 0.137. Better model.\n",
      "Episode 50, Average Score: 21.84, (39.62/25.69), Reward fraction 0.55\tTime 18.54, Noise rate 0.189. Better model.\n",
      "Episode 51, Average Score: 22.12, (39.62/17.59), Reward fraction 0.57\tTime 18.44, Noise rate 0.164. Better model.\n",
      "Episode 52, Average Score: 22.40, (39.64/27.43), Reward fraction 0.59\tTime 18.54, Noise rate 0.139. Better model.\n",
      "Episode 53, Average Score: 22.67, (39.63/29.32), Reward fraction 0.60\tTime 18.48, Noise rate 0.120. Better model.\n",
      "Episode 54, Average Score: 22.93, (39.61/15.01), Reward fraction 0.62\tTime 18.46, Noise rate 0.151. Better model.\n",
      "Episode 55, Average Score: 23.18, (39.63/26.81), Reward fraction 0.64\tTime 18.55, Noise rate 0.163. Better model.\n",
      "Episode 56, Average Score: 23.45, (39.59/22.28), Reward fraction 0.66\tTime 18.55, Noise rate 0.101. Better model.\n",
      "Episode 57, Average Score: 23.70, (39.64/32.68), Reward fraction 0.68\tTime 18.70, Noise rate 0.107. Better model.\n",
      "Episode 58, Average Score: 23.94, (39.61/29.51), Reward fraction 0.69\tTime 18.60, Noise rate 0.108. Better model.\n",
      "Episode 59, Average Score: 24.13, (39.52/28.53), Reward fraction 0.71\tTime 18.62, Noise rate 0.116. Better model.\n",
      "Episode 60, Average Score: 24.28, (39.58/22.24), Reward fraction 0.73\tTime 18.62, Noise rate 0.124. Better model.\n",
      "Episode 61, Average Score: 24.48, (39.63/22.77), Reward fraction 0.74\tTime 18.57, Noise rate 0.098. Better model.\n",
      "Episode 62, Average Score: 24.65, (39.63/23.77), Reward fraction 0.76\tTime 18.62, Noise rate 0.118. Better model.\n",
      "Episode 63, Average Score: 24.80, (39.60/0.00), Reward fraction 0.78\tTime 18.68, Noise rate 0.090. Better model.\n",
      "Episode 64, Average Score: 24.99, (39.63/29.97), Reward fraction 0.79\tTime 18.67, Noise rate 0.092. Better model.\n",
      "Episode 65, Average Score: 25.15, (39.58/2.55), Reward fraction 0.81\tTime 18.56, Noise rate 0.091. Better model.\n",
      "Episode 66, Average Score: 25.31, (39.64/26.47), Reward fraction 0.82\tTime 18.68, Noise rate 0.096. Better model.\n",
      "Episode 67, Average Score: 25.45, (39.52/22.89), Reward fraction 0.84\tTime 18.61, Noise rate 0.099. Better model.\n",
      "Episode 68, Average Score: 25.60, (39.59/11.57), Reward fraction 0.85\tTime 18.55, Noise rate 0.084. Better model.\n",
      "Episode 69, Average Score: 25.75, (39.61/22.98), Reward fraction 0.86\tTime 18.65, Noise rate 0.084. Better model.\n",
      "Episode 70, Average Score: 25.86, (39.54/15.53), Reward fraction 0.87\tTime 18.76, Noise rate 0.091. Better model.\n",
      "Episode 71, Average Score: 25.96, (39.58/0.00), Reward fraction 0.88\tTime 18.64, Noise rate 0.086. Better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 72, Average Score: 26.07, (39.46/17.27), Reward fraction 0.89\tTime 18.62, Noise rate 0.082. Better model.\n",
      "Episode 73, Average Score: 26.21, (39.52/24.02), Reward fraction 0.89\tTime 18.61, Noise rate 0.065. Better model.\n",
      "Episode 74, Average Score: 26.33, (39.62/15.67), Reward fraction 0.90\tTime 18.71, Noise rate 0.066. Better model.\n",
      "Episode 75, Average Score: 26.49, (39.63/29.12), Reward fraction 0.90\tTime 19.35, Noise rate 0.061. Better model.\n",
      "Episode 76, Average Score: 26.62, (39.59/22.81), Reward fraction 0.90\tTime 19.10, Noise rate 0.065. Better model.\n",
      "Episode 77, Average Score: 26.71, (39.57/12.26), Reward fraction 0.91\tTime 18.74, Noise rate 0.058. Better model.\n",
      "Episode 78, Average Score: 26.83, (39.60/26.90), Reward fraction 0.91\tTime 18.62, Noise rate 0.052. Better model.\n",
      "Episode 79, Average Score: 26.93, (39.55/15.04), Reward fraction 0.91\tTime 18.67, Noise rate 0.050. Better model.\n",
      "Episode 80, Average Score: 27.05, (39.53/16.87), Reward fraction 0.91\tTime 18.56, Noise rate 0.054. Better model.\n",
      "Episode 81, Average Score: 27.17, (39.66/26.44), Reward fraction 0.91\tTime 18.60, Noise rate 0.055. Better model.\n",
      "Episode 82, Average Score: 27.30, (39.58/24.51), Reward fraction 0.91\tTime 18.72, Noise rate 0.048. Better model.\n",
      "Episode 83, Average Score: 27.39, (39.51/23.45), Reward fraction 0.91\tTime 18.71, Noise rate 0.042. Better model.\n",
      "Episode 84, Average Score: 27.46, (39.09/16.83), Reward fraction 0.91\tTime 18.67, Noise rate 0.046. Better model.\n",
      "Episode 85, Average Score: 27.54, (39.47/25.69), Reward fraction 0.91\tTime 18.58, Noise rate 0.050. Better model.\n",
      "Episode 86, Average Score: 27.62, (38.74/28.82), Reward fraction 0.91\tTime 18.69, Noise rate 0.064. Better model.\n",
      "Episode 87, Average Score: 27.67, (39.09/15.30), Reward fraction 0.91\tTime 19.44, Noise rate 0.044. Better model.\n",
      "Episode 88, Average Score: 27.77, (39.40/28.79), Reward fraction 0.91\tTime 19.64, Noise rate 0.052. Better model.\n",
      "Episode 89, Average Score: 27.82, (39.62/22.79), Reward fraction 0.90\tTime 20.24, Noise rate 0.025. Better model.\n",
      "Episode 90, Average Score: 27.86, (39.51/19.93), Reward fraction 0.90\tTime 19.34, Noise rate 0.041. Better model.\n",
      "Episode 91, Average Score: 27.88, (39.12/17.80), Reward fraction 0.90\tTime 21.18, Noise rate 0.041. Better model.\n",
      "Episode 94, Average Score: 27.92, (39.48/22.73), Reward fraction 0.88\tTime 19.52, Noise rate 0.037. Better model.\n",
      "Episode 95, Average Score: 27.96, (38.16/15.58), Reward fraction 0.88\tTime 20.03, Noise rate 0.031. Better model.\n",
      "Episode 96, Average Score: 28.00, (39.20/16.22), Reward fraction 0.88\tTime 19.21, Noise rate 0.035. Better model.\n",
      "Episode 97, Average Score: 28.03, (36.63/25.94), Reward fraction 0.87\tTime 19.48, Noise rate 0.033. Better model.\n",
      "Episode 98, Average Score: 28.05, (35.75/23.44), Reward fraction 0.87\tTime 19.82, Noise rate 0.030. Better model.\n",
      "Episode 99, Average Score: 28.06, (34.43/11.68), Reward fraction 0.87\tTime 19.36, Noise rate 0.031. Better model.\n",
      "Episode 100, Average Score: 28.06, (38.37/9.73), Reward fraction 0.86\tTime 19.51, Noise rate 0.033.\n",
      "Episode 101, Average Score: 28.32, (39.09/13.13), Reward fraction 0.86\tTime 20.60, Noise rate 0.029. Better model.\n",
      "Episode 102, Average Score: 28.61, (39.01/20.25), Reward fraction 0.85\tTime 19.75, Noise rate 0.025. Better model.\n",
      "Episode 103, Average Score: 28.92, (38.99/19.55), Reward fraction 0.85\tTime 19.64, Noise rate 0.028. Better model.\n",
      "Episode 104, Average Score: 29.26, (36.78/25.12), Reward fraction 0.85\tTime 19.84, Noise rate 0.028. Better model.\n",
      "Episode 105, Average Score: 29.56, (38.52/11.98), Reward fraction 0.85\tTime 19.71, Noise rate 0.026. Better model.\n",
      "Episode 106, Average Score: 29.87, (37.11/23.87), Reward fraction 0.84\tTime 19.65, Noise rate 0.019. Better model.\n",
      "Episode 107, Average Score: 30.20, (37.71/23.42), Reward fraction 0.84\tTime 19.95, Noise rate 0.024. Better model.\n",
      "\n",
      "Goal reached in 107 episodes!\tAverage Score: 30.20\n",
      "Episode 108, Average Score: 30.54, (39.08/28.18), Reward fraction 0.84\tTime 20.31, Noise rate 0.017. Better model.\n",
      "Episode 109, Average Score: 30.88, (37.38/32.27), Reward fraction 0.84\tTime 20.10, Noise rate 0.022. Better model.\n",
      "Episode 110, Average Score: 31.21, (38.75/23.76), Reward fraction 0.84\tTime 19.80, Noise rate 0.018. Better model.\n",
      "Episode 111, Average Score: 31.55, (39.45/29.78), Reward fraction 0.84\tTime 19.83, Noise rate 0.020. Better model.\n",
      "Episode 112, Average Score: 31.88, (38.70/30.12), Reward fraction 0.84\tTime 19.55, Noise rate 0.019. Better model.\n",
      "Episode 113, Average Score: 32.23, (39.30/34.30), Reward fraction 0.84\tTime 19.64, Noise rate 0.023. Better model.\n",
      "Episode 114, Average Score: 32.57, (39.17/30.54), Reward fraction 0.84\tTime 20.27, Noise rate 0.014. Better model.\n",
      "Episode 115, Average Score: 32.88, (39.48/22.91), Reward fraction 0.84\tTime 19.84, Noise rate 0.022. Better model.\n",
      "Episode 116, Average Score: 33.19, (39.48/32.19), Reward fraction 0.84\tTime 19.93, Noise rate 0.019. Better model.\n",
      "Episode 117, Average Score: 33.50, (39.49/32.30), Reward fraction 0.84\tTime 20.45, Noise rate 0.016. Better model.\n",
      "Episode 118, Average Score: 33.76, (38.93/31.40), Reward fraction 0.85\tTime 19.68, Noise rate 0.016. Better model.\n",
      "Episode 119, Average Score: 33.99, (39.17/32.04), Reward fraction 0.85\tTime 19.04, Noise rate 0.018. Better model.\n",
      "Episode 120, Average Score: 34.18, (39.43/25.56), Reward fraction 0.85\tTime 18.97, Noise rate 0.017. Better model.\n",
      "Episode 121, Average Score: 34.35, (38.47/27.80), Reward fraction 0.85\tTime 19.03, Noise rate 0.014. Better model.\n",
      "Episode 122, Average Score: 34.50, (38.60/23.58), Reward fraction 0.85\tTime 19.91, Noise rate 0.014. Better model.\n",
      "Episode 123, Average Score: 34.58, (38.17/26.00), Reward fraction 0.84\tTime 18.89, Noise rate 0.016. Better model.\n",
      "Episode 124, Average Score: 34.67, (39.25/24.66), Reward fraction 0.84\tTime 18.90, Noise rate 0.012. Better model.\n",
      "Episode 125, Average Score: 34.72, (39.27/20.35), Reward fraction 0.84\tTime 18.87, Noise rate 0.011. Better model.\n",
      "Episode 126, Average Score: 34.79, (39.30/29.58), Reward fraction 0.84\tTime 18.92, Noise rate 0.014. Better model.\n",
      "Episode 127, Average Score: 34.83, (39.42/23.02), Reward fraction 0.84\tTime 18.89, Noise rate 0.012. Better model.\n",
      "Episode 128, Average Score: 34.83, (39.05/15.12), Reward fraction 0.84\tTime 18.80, Noise rate 0.009."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created unity enviroment from  .\\Reacher_Windows_x86_64_20Agents\\Reacher.exe\n",
      "Environment     : .\\Reacher_Windows_x86_64_20Agents\\Reacher.exe\n",
      "Number of agents: 20\n",
      "State size      : 33\n",
      "Action size     : 4\n",
      "Created agent: states =  33  actions =  4  reward level =  0.25\n",
      "\n",
      "Restart learning - no checkpoint file found: 20AgentsBias-best_actor.pth\n",
      "Episode 1, Average Score: 0.76, (1.66/0.04), Reward fraction 0.18\tTime 10.59, Noise rate 0.244. Better model.\n",
      "Episode 3, Average Score: 0.88, (2.88/0.28), Reward fraction 0.24\tTime 11.28, Noise rate 0.285. Better model.\n",
      "Episode 4, Average Score: 0.90, (1.99/0.18), Reward fraction 0.23\tTime 11.52, Noise rate 0.250. Better model.\n",
      "Episode 9, Average Score: 0.91, (2.42/0.19), Reward fraction 0.24\tTime 11.00, Noise rate 0.189. Better model.\n",
      "Episode 10, Average Score: 0.95, (2.06/0.38), Reward fraction 0.25\tTime 10.98, Noise rate 0.197. Better model.\n",
      "Episode 11, Average Score: 1.00, (2.83/0.21), Reward fraction 0.25\tTime 11.05, Noise rate 0.207. Better model.\n",
      "Episode 12, Average Score: 1.06, (3.17/0.44), Reward fraction 0.25\tTime 11.08, Noise rate 0.179. Better model.\n",
      "Episode 13, Average Score: 1.11, (4.64/0.36), Reward fraction 0.25\tTime 10.98, Noise rate 0.145. Better model.\n",
      "Episode 14, Average Score: 1.22, (5.93/1.18), Reward fraction 0.25\tTime 11.15, Noise rate 0.184. Better model.\n",
      "Episode 15, Average Score: 1.31, (4.72/0.96), Reward fraction 0.25\tTime 11.15, Noise rate 0.172. Better model.\n",
      "Episode 16, Average Score: 1.40, (5.69/0.59), Reward fraction 0.25\tTime 11.22, Noise rate 0.147. Better model.\n",
      "Episode 17, Average Score: 1.54, (6.37/1.69), Reward fraction 0.25\tTime 11.28, Noise rate 0.163. Better model.\n",
      "Episode 18, Average Score: 1.70, (7.48/0.98), Reward fraction 0.25\tTime 11.34, Noise rate 0.179. Better model.\n",
      "Episode 19, Average Score: 1.84, (8.95/2.16), Reward fraction 0.25\tTime 11.31, Noise rate 0.143. Better model.\n",
      "Episode 20, Average Score: 2.00, (8.92/1.83), Reward fraction 0.25\tTime 11.32, Noise rate 0.140. Better model.\n",
      "Episode 21, Average Score: 2.25, (21.77/3.55), Reward fraction 0.25\tTime 11.46, Noise rate 0.153. Better model.\n",
      "Episode 22, Average Score: 2.51, (13.28/2.57), Reward fraction 0.25\tTime 11.53, Noise rate 0.135. Better model.\n",
      "Episode 23, Average Score: 2.83, (15.24/6.07), Reward fraction 0.25\tTime 11.64, Noise rate 0.119. Better model.\n",
      "Episode 24, Average Score: 3.14, (16.35/4.77), Reward fraction 0.26\tTime 11.88, Noise rate 0.134. Better model.\n",
      "Episode 25, Average Score: 3.53, (19.85/4.44), Reward fraction 0.26\tTime 11.98, Noise rate 0.141. Better model.\n",
      "Episode 26, Average Score: 4.01, (31.11/6.89), Reward fraction 0.28\tTime 12.15, Noise rate 0.149. Better model.\n",
      "Episode 27, Average Score: 4.67, (37.15/9.90), Reward fraction 0.30\tTime 12.24, Noise rate 0.152. Better model.\n",
      "Episode 28, Average Score: 5.30, (38.24/7.37), Reward fraction 0.33\tTime 12.39, Noise rate 0.131. Better model.\n",
      "Episode 29, Average Score: 5.95, (36.34/11.33), Reward fraction 0.35\tTime 12.66, Noise rate 0.158. Better model.\n",
      "Episode 30, Average Score: 6.47, (33.90/9.84), Reward fraction 0.36\tTime 12.84, Noise rate 0.177. Better model.\n",
      "Episode 31, Average Score: 7.07, (39.08/11.38), Reward fraction 0.38\tTime 13.00, Noise rate 0.177. Better model.\n",
      "Episode 32, Average Score: 7.70, (37.74/13.59), Reward fraction 0.40\tTime 13.11, Noise rate 0.124. Better model.\n",
      "Episode 33, Average Score: 8.37, (36.94/19.49), Reward fraction 0.42\tTime 13.30, Noise rate 0.210. Better model.\n",
      "Episode 34, Average Score: 9.02, (37.44/17.85), Reward fraction 0.44\tTime 13.47, Noise rate 0.156. Better model.\n",
      "Episode 35, Average Score: 9.62, (38.97/12.77), Reward fraction 0.46\tTime 13.69, Noise rate 0.137. Better model.\n",
      "Episode 36, Average Score: 10.21, (37.26/12.30), Reward fraction 0.47\tTime 13.92, Noise rate 0.169. Better model.\n",
      "Episode 37, Average Score: 10.81, (39.26/20.08), Reward fraction 0.49\tTime 14.04, Noise rate 0.169. Better model.\n",
      "Episode 38, Average Score: 11.39, (38.85/19.13), Reward fraction 0.51\tTime 14.18, Noise rate 0.223. Better model.\n",
      "Episode 39, Average Score: 11.89, (39.21/12.82), Reward fraction 0.52\tTime 14.25, Noise rate 0.203. Better model.\n",
      "Episode 40, Average Score: 12.47, (39.36/21.55), Reward fraction 0.53\tTime 14.48, Noise rate 0.188. Better model.\n",
      "Episode 41, Average Score: 13.04, (39.57/26.15), Reward fraction 0.55\tTime 14.54, Noise rate 0.161. Better model.\n",
      "Episode 42, Average Score: 13.61, (39.54/19.61), Reward fraction 0.56\tTime 14.61, Noise rate 0.220. Better model.\n",
      "Episode 43, Average Score: 14.16, (39.60/33.18), Reward fraction 0.58\tTime 14.76, Noise rate 0.193. Better model.\n",
      "Episode 44, Average Score: 14.68, (39.58/21.90), Reward fraction 0.59\tTime 14.99, Noise rate 0.180. Better model.\n",
      "Episode 45, Average Score: 15.16, (39.48/28.49), Reward fraction 0.60\tTime 15.07, Noise rate 0.162. Better model.\n",
      "Episode 46, Average Score: 15.65, (39.59/32.67), Reward fraction 0.61\tTime 15.24, Noise rate 0.152. Better model.\n",
      "Episode 47, Average Score: 16.14, (39.58/36.03), Reward fraction 0.62\tTime 15.40, Noise rate 0.141. Better model.\n",
      "Episode 48, Average Score: 16.59, (39.47/28.61), Reward fraction 0.63\tTime 15.57, Noise rate 0.228. Better model.\n",
      "Episode 49, Average Score: 17.02, (39.64/30.58), Reward fraction 0.64\tTime 15.82, Noise rate 0.167. Better model.\n",
      "Episode 50, Average Score: 17.44, (39.56/33.09), Reward fraction 0.65\tTime 15.80, Noise rate 0.116. Better model.\n",
      "Episode 51, Average Score: 17.84, (39.55/33.43), Reward fraction 0.66\tTime 16.00, Noise rate 0.150. Better model.\n",
      "Episode 52, Average Score: 18.19, (39.59/20.48), Reward fraction 0.67\tTime 16.28, Noise rate 0.121. Better model.\n",
      "Episode 53, Average Score: 18.57, (39.62/32.43), Reward fraction 0.67\tTime 16.35, Noise rate 0.157. Better model.\n",
      "Episode 54, Average Score: 18.93, (39.59/30.80), Reward fraction 0.68\tTime 16.46, Noise rate 0.124. Better model.\n",
      "Episode 55, Average Score: 19.26, (39.60/15.57), Reward fraction 0.69\tTime 16.67, Noise rate 0.121. Better model.\n",
      "Episode 56, Average Score: 19.58, (39.58/27.08), Reward fraction 0.69\tTime 16.82, Noise rate 0.119. Better model.\n",
      "Episode 57, Average Score: 19.91, (39.64/33.23), Reward fraction 0.70\tTime 17.03, Noise rate 0.106. Better model.\n",
      "Episode 58, Average Score: 20.19, (39.57/20.73), Reward fraction 0.71\tTime 17.22, Noise rate 0.125. Better model.\n",
      "Episode 59, Average Score: 20.48, (39.36/26.85), Reward fraction 0.71\tTime 17.36, Noise rate 0.143. Better model.\n",
      "Episode 60, Average Score: 20.77, (39.61/32.30), Reward fraction 0.72\tTime 17.39, Noise rate 0.108. Better model.\n",
      "Episode 61, Average Score: 21.05, (39.59/28.62), Reward fraction 0.72\tTime 17.54, Noise rate 0.107. Better model.\n",
      "Episode 62, Average Score: 21.33, (39.57/34.50), Reward fraction 0.73\tTime 17.81, Noise rate 0.095. Better model.\n",
      "Episode 63, Average Score: 21.59, (39.57/29.53), Reward fraction 0.73\tTime 17.85, Noise rate 0.083. Better model.\n",
      "Episode 64, Average Score: 21.82, (39.49/20.49), Reward fraction 0.73\tTime 18.09, Noise rate 0.095. Better model.\n",
      "Episode 65, Average Score: 22.06, (39.56/24.08), Reward fraction 0.74\tTime 18.26, Noise rate 0.104. Better model.\n",
      "Episode 66, Average Score: 22.29, (39.50/23.26), Reward fraction 0.74\tTime 18.51, Noise rate 0.080. Better model.\n",
      "Episode 67, Average Score: 22.52, (39.59/35.87), Reward fraction 0.76\tTime 18.47, Noise rate 0.088. Better model.\n",
      "Episode 68, Average Score: 22.68, (39.52/13.79), Reward fraction 0.77\tTime 18.59, Noise rate 0.085. Better model.\n",
      "Episode 69, Average Score: 22.89, (39.48/22.21), Reward fraction 0.78\tTime 18.63, Noise rate 0.080. Better model.\n",
      "Episode 70, Average Score: 23.06, (39.56/26.75), Reward fraction 0.79\tTime 18.54, Noise rate 0.070. Better model.\n",
      "Episode 71, Average Score: 23.26, (39.43/28.24), Reward fraction 0.81\tTime 18.55, Noise rate 0.088. Better model.\n",
      "Episode 72, Average Score: 23.44, (39.60/23.82), Reward fraction 0.82\tTime 18.59, Noise rate 0.062. Better model.\n",
      "Episode 73, Average Score: 23.60, (39.55/18.34), Reward fraction 0.83\tTime 18.58, Noise rate 0.049. Better model.\n",
      "Episode 74, Average Score: 23.70, (39.42/10.95), Reward fraction 0.84\tTime 18.52, Noise rate 0.046. Better model.\n",
      "Episode 75, Average Score: 23.80, (39.29/12.72), Reward fraction 0.85\tTime 18.63, Noise rate 0.037. Better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 76, Average Score: 23.96, (39.55/22.46), Reward fraction 0.86\tTime 18.58, Noise rate 0.058. Better model.\n",
      "Episode 77, Average Score: 24.05, (39.47/1.69), Reward fraction 0.87\tTime 18.61, Noise rate 0.050. Better model.\n",
      "Episode 78, Average Score: 24.14, (39.50/17.34), Reward fraction 0.87\tTime 18.66, Noise rate 0.047. Better model.\n",
      "Episode 79, Average Score: 24.22, (39.48/12.01), Reward fraction 0.87\tTime 18.59, Noise rate 0.059. Better model.\n",
      "Episode 80, Average Score: 24.34, (39.30/15.48), Reward fraction 0.88\tTime 18.86, Noise rate 0.050. Better model.\n",
      "Episode 81, Average Score: 24.47, (39.53/23.69), Reward fraction 0.88\tTime 18.62, Noise rate 0.051. Better model.\n",
      "Episode 82, Average Score: 24.54, (38.74/4.51), Reward fraction 0.89\tTime 19.29, Noise rate 0.044. Better model.\n",
      "Episode 83, Average Score: 24.58, (38.89/0.60), Reward fraction 0.88\tTime 18.77, Noise rate 0.041. Better model.\n",
      "Episode 84, Average Score: 24.63, (37.20/1.30), Reward fraction 0.88\tTime 18.54, Noise rate 0.052. Better model.\n",
      "Episode 85, Average Score: 24.71, (39.42/5.85), Reward fraction 0.88\tTime 18.67, Noise rate 0.047. Better model.\n",
      "Episode 86, Average Score: 24.77, (38.70/9.52), Reward fraction 0.88\tTime 18.56, Noise rate 0.040. Better model.\n",
      "Episode 87, Average Score: 24.88, (38.14/25.47), Reward fraction 0.88\tTime 18.67, Noise rate 0.055. Better model.\n",
      "Episode 88, Average Score: 24.98, (38.36/17.40), Reward fraction 0.89\tTime 18.61, Noise rate 0.048. Better model.\n",
      "Episode 89, Average Score: 25.08, (38.93/16.64), Reward fraction 0.89\tTime 18.58, Noise rate 0.053. Better model.\n",
      "Episode 90, Average Score: 25.15, (39.43/18.29), Reward fraction 0.88\tTime 18.59, Noise rate 0.053. Better model.\n",
      "Episode 91, Average Score: 25.26, (37.73/29.09), Reward fraction 0.88\tTime 18.63, Noise rate 0.053. Better model.\n",
      "Episode 92, Average Score: 25.37, (39.54/22.97), Reward fraction 0.88\tTime 18.61, Noise rate 0.058. Better model.\n",
      "Episode 93, Average Score: 25.46, (39.29/22.46), Reward fraction 0.88\tTime 18.72, Noise rate 0.036. Better model.\n",
      "Episode 94, Average Score: 25.56, (37.91/24.61), Reward fraction 0.88\tTime 18.53, Noise rate 0.042. Better model.\n",
      "Episode 95, Average Score: 25.67, (39.45/30.18), Reward fraction 0.88\tTime 18.57, Noise rate 0.028. Better model.\n",
      "Episode 96, Average Score: 25.74, (38.23/22.69), Reward fraction 0.88\tTime 18.53, Noise rate 0.034. Better model.\n",
      "Episode 97, Average Score: 25.79, (39.06/21.32), Reward fraction 0.87\tTime 18.61, Noise rate 0.031. Better model.\n",
      "Episode 98, Average Score: 25.88, (39.34/23.12), Reward fraction 0.87\tTime 18.67, Noise rate 0.029. Better model.\n",
      "Episode 99, Average Score: 25.93, (37.01/12.37), Reward fraction 0.87\tTime 18.70, Noise rate 0.023. Better model.\n",
      "Episode 100, Average Score: 25.96, (38.26/12.95), Reward fraction 0.87\tTime 18.68, Noise rate 0.023. Better model.\n",
      "Episode 100, Average Score: 25.96, (38.26/12.95), Reward fraction 0.87\tTime 18.68, Noise rate 0.023.\n",
      "Episode 101, Average Score: 26.24, (37.94/15.52), Reward fraction 0.86\tTime 18.61, Noise rate 0.025. Better model.\n",
      "Episode 102, Average Score: 26.49, (38.97/8.60), Reward fraction 0.86\tTime 18.65, Noise rate 0.022. Better model.\n",
      "Episode 103, Average Score: 26.74, (38.07/15.87), Reward fraction 0.85\tTime 18.55, Noise rate 0.026. Better model.\n",
      "Episode 104, Average Score: 26.99, (38.68/11.03), Reward fraction 0.84\tTime 18.68, Noise rate 0.023. Better model.\n",
      "Episode 105, Average Score: 27.28, (36.76/22.43), Reward fraction 0.84\tTime 18.69, Noise rate 0.020. Better model.\n",
      "Episode 106, Average Score: 27.54, (38.32/15.75), Reward fraction 0.84\tTime 18.62, Noise rate 0.019. Better model.\n",
      "Episode 107, Average Score: 27.80, (33.35/13.03), Reward fraction 0.83\tTime 19.48, Noise rate 0.018. Better model.\n",
      "Episode 108, Average Score: 28.02, (32.34/12.31), Reward fraction 0.82\tTime 18.66, Noise rate 0.019. Better model.\n",
      "Episode 109, Average Score: 28.30, (34.44/24.15), Reward fraction 0.82\tTime 18.64, Noise rate 0.021. Better model.\n",
      "Episode 110, Average Score: 28.54, (32.52/12.48), Reward fraction 0.81\tTime 18.59, Noise rate 0.019. Better model.\n",
      "Episode 111, Average Score: 28.79, (36.35/15.34), Reward fraction 0.81\tTime 18.69, Noise rate 0.020. Better model.\n",
      "Episode 112, Average Score: 29.04, (34.22/11.82), Reward fraction 0.80\tTime 18.64, Noise rate 0.018. Better model.\n",
      "Episode 113, Average Score: 29.30, (37.17/18.52), Reward fraction 0.80\tTime 18.52, Noise rate 0.021. Better model.\n",
      "Episode 114, Average Score: 29.50, (34.61/7.85), Reward fraction 0.79\tTime 18.58, Noise rate 0.016. Better model.\n",
      "Episode 115, Average Score: 29.73, (38.99/13.89), Reward fraction 0.79\tTime 18.55, Noise rate 0.015. Better model.\n",
      "Episode 116, Average Score: 29.97, (33.42/17.42), Reward fraction 0.78\tTime 18.62, Noise rate 0.014. Better model.\n",
      "Episode 117, Average Score: 30.20, (35.89/15.51), Reward fraction 0.77\tTime 18.78, Noise rate 0.020. Better model.\n",
      "\n",
      "Goal reached in 117 episodes!\tAverage Score: 30.20\n",
      "Episode 118, Average Score: 30.43, (33.94/21.00), Reward fraction 0.77\tTime 18.54, Noise rate 0.019. Better model.\n",
      "Episode 119, Average Score: 30.66, (36.02/18.86), Reward fraction 0.77\tTime 18.52, Noise rate 0.012. Better model.\n",
      "Episode 120, Average Score: 30.90, (38.82/17.35), Reward fraction 0.76\tTime 18.45, Noise rate 0.018. Better model.\n",
      "Episode 121, Average Score: 31.09, (35.37/10.88), Reward fraction 0.76\tTime 18.51, Noise rate 0.014. Better model.\n",
      "Episode 122, Average Score: 31.25, (32.14/11.29), Reward fraction 0.75\tTime 18.47, Noise rate 0.011. Better model.\n",
      "Episode 123, Average Score: 31.44, (34.39/23.89), Reward fraction 0.75\tTime 18.61, Noise rate 0.009. Better model.\n",
      "Episode 124, Average Score: 31.59, (32.54/14.13), Reward fraction 0.75\tTime 18.63, Noise rate 0.012. Better model.\n",
      "Episode 125, Average Score: 31.75, (35.54/13.87), Reward fraction 0.75\tTime 18.56, Noise rate 0.010. Better model.\n",
      "Episode 126, Average Score: 31.85, (36.92/2.24), Reward fraction 0.74\tTime 18.52, Noise rate 0.015. Better model.\n",
      "Episode 127, Average Score: 31.91, (36.72/17.89), Reward fraction 0.74\tTime 18.49, Noise rate 0.013. Better model.\n",
      "Episode 128, Average Score: 31.95, (35.74/12.58), Reward fraction 0.74\tTime 18.56, Noise rate 0.009. Better model.\n",
      "Episode 129, Average Score: 31.96, (32.57/18.42), Reward fraction 0.74\tTime 18.59, Noise rate 0.008. Better model.\n",
      "Episode 130, Average Score: 31.98, (28.85/15.92), Reward fraction 0.73\tTime 18.69, Noise rate 0.011. Better model.\n",
      "Episode 140, Average Score: 31.64, (36.18/22.80), Reward fraction 0.71\tTime 18.63, Noise rate 0.007."
     ]
    }
   ],
   "source": [
    "with Environment (envFile='.\\Reacher_Windows_x86_64_20Agents\\Reacher.exe') as env:\n",
    "    s1 = ddpg ( '20Agents', Agent(env, random_seed=2, reward_level=-1.0), goal=30, n_episodes=200 )\n",
    "\n",
    "with Environment (envFile='.\\Reacher_Windows_x86_64_20Agents\\Reacher.exe') as env:\n",
    "    s2 = ddpg ( '20AgentsBias', Agent(env, random_seed=2, reward_level=0.25), goal=30, n_episodes=200 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnMtyXgiccy7LeSFwzrks9//JuYv3EafpFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotCompareScores (s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal was reached in 107 episodes for the non modified version for the network, and in 117 for the version where a minimum for successful actions where required. The modified version will run faster until the 25% reward level is reached, but it does not seem to improve the performance in a significant way.\n",
    "\n",
    "\n",
    "\n",
    "#### Test test same DDPG on the Single agent version of the reacher environement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created unity enviroment from  .\\Reacher_Windows_x86_64\\Reacher.exe\n",
      "Environment     : .\\Reacher_Windows_x86_64\\Reacher.exe\n",
      "Number of agents: 1\n",
      "State size      : 33\n",
      "Action size     : 4\n",
      "Created agent: states =  33  actions =  4  reward level =  -1.0\n",
      "\n",
      "Restart learning - no checkpoint file found: SingleAgent-best_actor.pth\n",
      "Episode 1, Average Score: 1.21, (1.21/1.21), Reward fraction 0.03\tTime 7.42, Noise rate 0.260. Better model.\n",
      "Episode 28, Average Score: 1.24, (3.62/3.62), Reward fraction 0.03\tTime 9.46, Noise rate 0.064. Better model.\n",
      "Episode 30, Average Score: 1.28, (2.61/2.61), Reward fraction 0.04\tTime 9.41, Noise rate 0.086. Better model.\n",
      "Episode 33, Average Score: 1.34, (3.34/3.34), Reward fraction 0.04\tTime 9.45, Noise rate 0.082. Better model.\n",
      "Episode 34, Average Score: 1.37, (2.37/2.37), Reward fraction 0.04\tTime 9.55, Noise rate 0.089. Better model.\n",
      "Episode 35, Average Score: 1.47, (4.90/4.90), Reward fraction 0.04\tTime 9.48, Noise rate 0.090. Better model.\n",
      "Episode 36, Average Score: 1.58, (5.35/5.35), Reward fraction 0.04\tTime 9.52, Noise rate 0.035. Better model.\n",
      "Episode 38, Average Score: 1.60, (2.78/2.78), Reward fraction 0.04\tTime 9.53, Noise rate 0.081. Better model.\n",
      "Episode 39, Average Score: 1.64, (2.97/2.97), Reward fraction 0.05\tTime 9.44, Noise rate 0.085. Better model.\n",
      "Episode 40, Average Score: 1.73, (5.44/5.44), Reward fraction 0.05\tTime 9.50, Noise rate 0.092. Better model.\n",
      "Episode 42, Average Score: 1.74, (2.53/2.53), Reward fraction 0.05\tTime 9.51, Noise rate 0.081. Better model.\n",
      "Episode 43, Average Score: 1.79, (3.97/3.97), Reward fraction 0.05\tTime 9.64, Noise rate 0.060. Better model.\n",
      "Episode 44, Average Score: 1.80, (2.01/2.01), Reward fraction 0.05\tTime 9.45, Noise rate 0.082. Better model.\n",
      "Episode 45, Average Score: 1.85, (4.06/4.06), Reward fraction 0.05\tTime 9.49, Noise rate 0.052. Better model.\n",
      "Episode 46, Average Score: 1.89, (3.60/3.60), Reward fraction 0.05\tTime 9.49, Noise rate 0.053. Better model.\n",
      "Episode 47, Average Score: 1.98, (6.45/6.45), Reward fraction 0.05\tTime 9.45, Noise rate 0.080. Better model.\n",
      "Episode 48, Average Score: 2.06, (5.48/5.48), Reward fraction 0.06\tTime 9.54, Noise rate 0.058. Better model.\n",
      "Episode 49, Average Score: 2.16, (7.02/7.02), Reward fraction 0.06\tTime 9.51, Noise rate 0.131. Better model.\n",
      "Episode 50, Average Score: 2.21, (4.85/4.85), Reward fraction 0.06\tTime 9.54, Noise rate 0.020. Better model.\n",
      "Episode 51, Average Score: 2.29, (6.20/6.20), Reward fraction 0.06\tTime 9.50, Noise rate 0.035. Better model.\n",
      "Episode 52, Average Score: 2.36, (5.77/5.77), Reward fraction 0.06\tTime 9.50, Noise rate 0.083. Better model.\n",
      "Episode 53, Average Score: 2.41, (5.26/5.26), Reward fraction 0.07\tTime 9.59, Noise rate 0.035. Better model.\n",
      "Episode 54, Average Score: 2.42, (2.82/2.82), Reward fraction 0.07\tTime 9.47, Noise rate 0.032. Better model.\n",
      "Episode 55, Average Score: 2.47, (5.36/5.36), Reward fraction 0.07\tTime 9.56, Noise rate 0.021. Better model.\n",
      "Episode 56, Average Score: 2.56, (7.43/7.43), Reward fraction 0.07\tTime 9.65, Noise rate 0.048. Better model.\n",
      "Episode 57, Average Score: 2.68, (9.33/9.33), Reward fraction 0.07\tTime 9.44, Noise rate 0.112. Better model.\n",
      "Episode 58, Average Score: 2.83, (11.48/11.48), Reward fraction 0.08\tTime 9.49, Noise rate 0.044. Better model.\n",
      "Episode 59, Average Score: 2.83, (2.95/2.95), Reward fraction 0.08\tTime 9.50, Noise rate 0.051. Better model.\n",
      "Episode 60, Average Score: 2.93, (8.88/8.88), Reward fraction 0.08\tTime 9.58, Noise rate 0.037. Better model.\n",
      "Episode 61, Average Score: 3.01, (7.60/7.60), Reward fraction 0.08\tTime 9.56, Noise rate 0.017. Better model.\n",
      "Episode 62, Average Score: 3.12, (9.53/9.53), Reward fraction 0.08\tTime 9.51, Noise rate 0.050. Better model.\n",
      "Episode 63, Average Score: 3.23, (10.60/10.60), Reward fraction 0.09\tTime 9.53, Noise rate 0.018. Better model.\n",
      "Episode 65, Average Score: 3.25, (5.51/5.51), Reward fraction 0.09\tTime 9.61, Noise rate 0.022. Better model.\n",
      "Episode 66, Average Score: 3.32, (7.90/7.90), Reward fraction 0.09\tTime 9.58, Noise rate 0.073. Better model.\n",
      "Episode 67, Average Score: 3.35, (5.23/5.23), Reward fraction 0.09\tTime 9.54, Noise rate 0.020. Better model.\n",
      "Episode 68, Average Score: 3.36, (3.90/3.90), Reward fraction 0.09\tTime 9.69, Noise rate 0.023. Better model.\n",
      "Episode 69, Average Score: 3.53, (15.28/15.28), Reward fraction 0.09\tTime 9.53, Noise rate 0.100. Better model.\n",
      "Episode 70, Average Score: 3.68, (13.62/13.62), Reward fraction 0.10\tTime 9.56, Noise rate 0.017. Better model.\n",
      "Episode 71, Average Score: 3.96, (24.10/24.10), Reward fraction 0.11\tTime 9.60, Noise rate 0.123. Better model.\n",
      "Episode 73, Average Score: 4.18, (20.05/20.05), Reward fraction 0.11\tTime 9.61, Noise rate 0.026. Better model.\n",
      "Episode 74, Average Score: 4.28, (11.71/11.71), Reward fraction 0.11\tTime 9.55, Noise rate 0.034. Better model.\n",
      "Episode 75, Average Score: 4.30, (5.39/5.39), Reward fraction 0.11\tTime 9.58, Noise rate 0.015. Better model.\n",
      "Episode 76, Average Score: 4.35, (8.56/8.56), Reward fraction 0.12\tTime 9.59, Noise rate 0.041. Better model.\n",
      "Episode 77, Average Score: 4.44, (11.16/11.16), Reward fraction 0.12\tTime 9.54, Noise rate 0.021. Better model.\n",
      "Episode 78, Average Score: 4.48, (7.59/7.59), Reward fraction 0.12\tTime 9.67, Noise rate 0.013. Better model.\n",
      "Episode 79, Average Score: 4.51, (6.74/6.74), Reward fraction 0.12\tTime 9.61, Noise rate 0.044. Better model.\n",
      "Episode 80, Average Score: 4.57, (9.62/9.62), Reward fraction 0.12\tTime 9.71, Noise rate 0.012. Better model.\n",
      "Episode 81, Average Score: 4.61, (7.66/7.66), Reward fraction 0.12\tTime 9.71, Noise rate 0.038. Better model.\n",
      "Episode 82, Average Score: 4.67, (9.69/9.69), Reward fraction 0.12\tTime 9.60, Noise rate 0.020. Better model.\n",
      "Episode 83, Average Score: 4.79, (14.36/14.36), Reward fraction 0.13\tTime 9.68, Noise rate 0.038. Better model.\n",
      "Episode 84, Average Score: 4.89, (13.17/13.17), Reward fraction 0.13\tTime 9.52, Noise rate 0.088. Better model.\n",
      "Episode 85, Average Score: 4.94, (9.21/9.21), Reward fraction 0.13\tTime 9.62, Noise rate 0.008. Better model.\n",
      "Episode 86, Average Score: 4.99, (9.43/9.43), Reward fraction 0.13\tTime 9.65, Noise rate 0.019. Better model.\n",
      "Episode 87, Average Score: 5.00, (5.76/5.76), Reward fraction 0.13\tTime 9.61, Noise rate 0.043. Better model.\n",
      "Episode 88, Average Score: 5.04, (7.95/7.95), Reward fraction 0.13\tTime 9.75, Noise rate 0.022. Better model.\n",
      "Episode 89, Average Score: 5.17, (17.03/17.03), Reward fraction 0.14\tTime 9.61, Noise rate 0.020. Better model.\n",
      "Episode 90, Average Score: 5.25, (12.43/12.43), Reward fraction 0.14\tTime 9.72, Noise rate 0.022. Better model.\n",
      "Episode 91, Average Score: 5.43, (21.28/21.28), Reward fraction 0.14\tTime 9.63, Noise rate 0.020. Better model.\n",
      "Episode 92, Average Score: 5.48, (9.92/9.92), Reward fraction 0.14\tTime 9.61, Noise rate 0.017. Better model.\n",
      "Episode 93, Average Score: 5.61, (18.16/18.16), Reward fraction 0.15\tTime 9.79, Noise rate 0.015. Better model.\n",
      "Episode 95, Average Score: 5.73, (19.01/19.01), Reward fraction 0.15\tTime 9.73, Noise rate 0.022. Better model.\n",
      "Episode 96, Average Score: 5.80, (12.14/12.14), Reward fraction 0.15\tTime 9.69, Noise rate 0.015. Better model.\n",
      "Episode 98, Average Score: 5.99, (26.81/26.81), Reward fraction 0.16\tTime 9.72, Noise rate 0.037. Better model.\n",
      "Episode 99, Average Score: 6.01, (7.85/7.85), Reward fraction 0.16\tTime 9.73, Noise rate 0.007. Better model.\n",
      "Episode 100, Average Score: 6.25, (29.89/29.89), Reward fraction 0.16\tTime 9.68, Noise rate 0.013. Better model.\n",
      "Episode 100, Average Score: 6.25, (29.89/29.89), Reward fraction 0.16\tTime 9.68, Noise rate 0.013.\n",
      "Episode 101, Average Score: 6.38, (14.20/14.20), Reward fraction 0.17\tTime 9.71, Noise rate 0.005. Better model.\n",
      "Episode 102, Average Score: 6.54, (15.93/15.93), Reward fraction 0.17\tTime 9.69, Noise rate 0.010. Better model.\n",
      "Episode 103, Average Score: 6.57, (3.95/3.95), Reward fraction 0.17\tTime 9.73, Noise rate 0.011. Better model.\n",
      "Episode 104, Average Score: 6.64, (7.68/7.68), Reward fraction 0.17\tTime 9.75, Noise rate 0.012. Better model.\n",
      "Episode 105, Average Score: 6.72, (8.68/8.68), Reward fraction 0.17\tTime 9.67, Noise rate 0.012. Better model.\n",
      "Episode 106, Average Score: 6.94, (21.20/21.20), Reward fraction 0.17\tTime 9.75, Noise rate 0.005. Better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 107, Average Score: 7.16, (23.43/23.43), Reward fraction 0.18\tTime 9.61, Noise rate 0.020. Better model.\n",
      "Episode 108, Average Score: 7.31, (16.08/16.08), Reward fraction 0.18\tTime 9.72, Noise rate 0.010. Better model.\n",
      "Episode 109, Average Score: 7.53, (22.63/22.63), Reward fraction 0.18\tTime 9.77, Noise rate 0.015. Better model.\n",
      "Episode 110, Average Score: 7.83, (30.60/30.60), Reward fraction 0.19\tTime 9.67, Noise rate 0.007. Better model.\n",
      "Episode 111, Average Score: 7.93, (12.53/12.53), Reward fraction 0.19\tTime 9.75, Noise rate 0.012. Better model.\n",
      "Episode 112, Average Score: 8.05, (12.84/12.84), Reward fraction 0.19\tTime 9.72, Noise rate 0.007. Better model.\n",
      "Episode 113, Average Score: 8.15, (10.48/10.48), Reward fraction 0.19\tTime 9.80, Noise rate 0.009. Better model.\n",
      "Episode 114, Average Score: 8.33, (20.18/20.18), Reward fraction 0.19\tTime 9.75, Noise rate 0.013. Better model.\n",
      "Episode 115, Average Score: 8.63, (30.57/30.57), Reward fraction 0.20\tTime 9.75, Noise rate 0.009. Better model.\n",
      "Episode 116, Average Score: 8.74, (12.67/12.67), Reward fraction 0.20\tTime 9.73, Noise rate 0.008. Better model.\n",
      "Episode 117, Average Score: 9.05, (31.51/31.51), Reward fraction 0.20\tTime 9.70, Noise rate 0.010. Better model.\n",
      "Episode 118, Average Score: 9.06, (4.23/4.23), Reward fraction 0.20\tTime 9.86, Noise rate 0.007. Better model.\n",
      "Episode 119, Average Score: 9.34, (29.25/29.25), Reward fraction 0.21\tTime 9.76, Noise rate 0.006. Better model.\n",
      "Episode 120, Average Score: 9.58, (25.04/25.04), Reward fraction 0.21\tTime 9.74, Noise rate 0.011. Better model.\n",
      "Episode 121, Average Score: 9.80, (23.55/23.55), Reward fraction 0.22\tTime 9.79, Noise rate 0.011. Better model.\n",
      "Episode 122, Average Score: 10.10, (31.77/31.77), Reward fraction 0.22\tTime 9.74, Noise rate 0.008. Better model.\n",
      "Episode 123, Average Score: 10.19, (9.80/9.80), Reward fraction 0.22\tTime 9.67, Noise rate 0.007. Better model.\n",
      "Episode 124, Average Score: 10.34, (16.42/16.42), Reward fraction 0.22\tTime 10.66, Noise rate 0.002. Better model.\n",
      "Episode 125, Average Score: 10.60, (27.34/27.34), Reward fraction 0.23\tTime 9.76, Noise rate 0.008. Better model.\n",
      "Episode 126, Average Score: 10.94, (35.43/35.43), Reward fraction 0.23\tTime 9.77, Noise rate 0.008. Better model.\n",
      "Episode 127, Average Score: 11.27, (35.34/35.34), Reward fraction 0.24\tTime 9.84, Noise rate 0.005. Better model.\n",
      "Episode 128, Average Score: 11.45, (21.79/21.79), Reward fraction 0.24\tTime 9.76, Noise rate 0.023. Better model.\n",
      "Episode 129, Average Score: 11.77, (32.24/32.24), Reward fraction 0.24\tTime 9.81, Noise rate 0.005. Better model.\n",
      "Episode 130, Average Score: 11.81, (6.54/6.54), Reward fraction 0.24\tTime 9.85, Noise rate 0.008. Better model.\n",
      "Episode 131, Average Score: 12.08, (27.72/27.72), Reward fraction 0.25\tTime 9.81, Noise rate 0.004. Better model.\n",
      "Episode 132, Average Score: 12.14, (7.59/7.59), Reward fraction 0.25\tTime 9.85, Noise rate 0.005. Better model.\n",
      "Episode 133, Average Score: 12.43, (33.24/33.24), Reward fraction 0.25\tTime 9.76, Noise rate 0.006. Better model.\n",
      "Episode 134, Average Score: 12.53, (11.79/11.79), Reward fraction 0.25\tTime 9.83, Noise rate 0.007. Better model.\n",
      "Episode 135, Average Score: 12.82, (34.06/34.06), Reward fraction 0.26\tTime 9.86, Noise rate 0.014. Better model.\n",
      "Episode 136, Average Score: 13.09, (32.71/32.71), Reward fraction 0.26\tTime 9.82, Noise rate 0.011. Better model.\n",
      "Episode 137, Average Score: 13.39, (30.67/30.67), Reward fraction 0.26\tTime 9.84, Noise rate 0.004. Better model.\n",
      "Episode 138, Average Score: 13.69, (33.17/33.17), Reward fraction 0.27\tTime 9.82, Noise rate 0.002. Better model.\n",
      "Episode 139, Average Score: 13.92, (25.89/25.89), Reward fraction 0.27\tTime 9.94, Noise rate 0.008. Better model.\n",
      "Episode 140, Average Score: 14.15, (28.04/28.04), Reward fraction 0.27\tTime 9.87, Noise rate 0.009. Better model.\n",
      "Episode 141, Average Score: 14.39, (25.29/25.29), Reward fraction 0.28\tTime 9.82, Noise rate 0.003. Better model.\n",
      "Episode 142, Average Score: 14.43, (7.19/7.19), Reward fraction 0.28\tTime 9.99, Noise rate 0.003. Better model.\n",
      "Episode 143, Average Score: 14.73, (33.78/33.78), Reward fraction 0.28\tTime 9.79, Noise rate 0.006. Better model.\n",
      "Episode 144, Average Score: 14.96, (25.14/25.14), Reward fraction 0.28\tTime 9.88, Noise rate 0.003. Better model.\n",
      "Episode 145, Average Score: 15.12, (19.69/19.69), Reward fraction 0.28\tTime 9.91, Noise rate 0.005. Better model.\n",
      "Episode 146, Average Score: 15.45, (36.66/36.66), Reward fraction 0.29\tTime 9.78, Noise rate 0.006. Better model.\n",
      "Episode 147, Average Score: 15.69, (30.48/30.48), Reward fraction 0.29\tTime 9.91, Noise rate 0.003. Better model.\n",
      "Episode 148, Average Score: 15.98, (35.05/35.05), Reward fraction 0.29\tTime 9.99, Noise rate 0.005. Better model.\n",
      "Episode 149, Average Score: 16.21, (29.72/29.72), Reward fraction 0.30\tTime 9.89, Noise rate 0.004. Better model.\n",
      "Episode 150, Average Score: 16.46, (30.09/30.09), Reward fraction 0.30\tTime 9.90, Noise rate 0.007. Better model.\n",
      "Episode 151, Average Score: 16.64, (24.04/24.04), Reward fraction 0.30\tTime 9.87, Noise rate 0.010. Better model.\n",
      "Episode 152, Average Score: 16.93, (34.54/34.54), Reward fraction 0.31\tTime 9.93, Noise rate 0.004. Better model.\n",
      "Episode 153, Average Score: 17.18, (29.97/29.97), Reward fraction 0.31\tTime 9.91, Noise rate 0.011. Better model.\n",
      "Episode 154, Average Score: 17.48, (32.95/32.95), Reward fraction 0.31\tTime 9.95, Noise rate 0.005. Better model.\n",
      "Episode 155, Average Score: 17.56, (13.20/13.20), Reward fraction 0.31\tTime 9.89, Noise rate 0.006. Better model.\n",
      "Episode 157, Average Score: 17.57, (14.38/14.38), Reward fraction 0.31\tTime 9.85, Noise rate 0.002. Better model.\n",
      "Episode 158, Average Score: 17.69, (23.88/23.88), Reward fraction 0.31\tTime 9.98, Noise rate 0.003. Better model.\n",
      "Episode 159, Average Score: 18.06, (39.45/39.45), Reward fraction 0.32\tTime 9.89, Noise rate 0.003. Better model.\n",
      "Episode 160, Average Score: 18.07, (10.70/10.70), Reward fraction 0.32\tTime 9.98, Noise rate 0.003. Better model.\n",
      "Episode 161, Average Score: 18.23, (23.03/23.03), Reward fraction 0.32\tTime 9.99, Noise rate 0.008. Better model.\n",
      "Episode 162, Average Score: 18.41, (27.94/27.94), Reward fraction 0.32\tTime 9.90, Noise rate 0.002. Better model.\n",
      "Episode 164, Average Score: 18.65, (35.57/35.57), Reward fraction 0.32\tTime 10.04, Noise rate 0.004. Better model.\n",
      "Episode 165, Average Score: 18.92, (32.87/32.87), Reward fraction 0.33\tTime 9.97, Noise rate 0.010. Better model.\n",
      "Episode 166, Average Score: 19.21, (36.46/36.46), Reward fraction 0.33\tTime 10.20, Noise rate 0.002. Better model.\n",
      "Episode 167, Average Score: 19.55, (39.48/39.48), Reward fraction 0.33\tTime 9.99, Noise rate 0.002. Better model.\n",
      "Episode 168, Average Score: 19.73, (21.59/21.59), Reward fraction 0.34\tTime 9.95, Noise rate 0.001. Better model.\n",
      "Episode 169, Average Score: 19.93, (34.96/34.96), Reward fraction 0.34\tTime 10.04, Noise rate 0.003. Better model.\n",
      "Episode 170, Average Score: 20.13, (33.58/33.58), Reward fraction 0.34\tTime 10.01, Noise rate 0.005. Better model.\n",
      "Episode 171, Average Score: 20.20, (31.04/31.04), Reward fraction 0.34\tTime 10.06, Noise rate 0.006. Better model.\n",
      "Episode 172, Average Score: 20.52, (36.23/36.23), Reward fraction 0.35\tTime 10.05, Noise rate 0.002. Better model.\n",
      "Episode 173, Average Score: 20.60, (28.16/28.16), Reward fraction 0.35\tTime 10.03, Noise rate 0.001. Better model.\n",
      "Episode 174, Average Score: 20.76, (27.79/27.79), Reward fraction 0.35\tTime 10.06, Noise rate 0.002. Better model.\n",
      "Episode 175, Average Score: 20.97, (25.64/25.64), Reward fraction 0.35\tTime 9.99, Noise rate 0.001. Better model.\n",
      "Episode 176, Average Score: 21.05, (17.47/17.47), Reward fraction 0.35\tTime 10.06, Noise rate 0.006. Better model.\n",
      "Episode 177, Average Score: 21.21, (26.41/26.41), Reward fraction 0.36\tTime 10.09, Noise rate 0.001. Better model.\n",
      "Episode 181, Average Score: 21.33, (26.79/26.79), Reward fraction 0.35\tTime 10.03, Noise rate 0.003. Better model.\n",
      "Episode 182, Average Score: 21.60, (36.71/36.71), Reward fraction 0.36\tTime 10.11, Noise rate 0.003. Better model.\n",
      "Episode 183, Average Score: 21.63, (17.21/17.21), Reward fraction 0.36\tTime 10.02, Noise rate 0.001. Better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 184, Average Score: 21.86, (35.84/35.84), Reward fraction 0.36\tTime 10.14, Noise rate 0.001. Better model.\n",
      "Episode 185, Average Score: 22.15, (38.11/38.11), Reward fraction 0.36\tTime 10.15, Noise rate 0.004. Better model.\n",
      "Episode 186, Average Score: 22.36, (31.04/31.04), Reward fraction 0.37\tTime 10.05, Noise rate 0.001. Better model.\n",
      "Episode 187, Average Score: 22.68, (37.33/37.33), Reward fraction 0.37\tTime 10.14, Noise rate 0.000. Better model.\n",
      "Episode 188, Average Score: 22.93, (33.24/33.24), Reward fraction 0.37\tTime 10.14, Noise rate 0.001. Better model.\n",
      "Episode 189, Average Score: 22.96, (20.00/20.00), Reward fraction 0.37\tTime 10.07, Noise rate 0.002. Better model.\n",
      "Episode 190, Average Score: 23.22, (38.15/38.15), Reward fraction 0.38\tTime 10.23, Noise rate 0.005. Better model.\n",
      "Episode 191, Average Score: 23.33, (32.68/32.68), Reward fraction 0.38\tTime 10.23, Noise rate 0.004. Better model.\n",
      "Episode 192, Average Score: 23.63, (39.39/39.39), Reward fraction 0.38\tTime 10.09, Noise rate 0.001. Better model.\n",
      "Episode 193, Average Score: 23.70, (25.48/25.48), Reward fraction 0.38\tTime 10.18, Noise rate 0.002. Better model.\n",
      "Episode 194, Average Score: 23.95, (28.91/28.91), Reward fraction 0.38\tTime 10.15, Noise rate 0.001. Better model.\n",
      "Episode 196, Average Score: 24.09, (36.86/36.86), Reward fraction 0.39\tTime 10.25, Noise rate 0.001. Better model.\n",
      "Episode 197, Average Score: 24.42, (36.34/36.34), Reward fraction 0.39\tTime 10.11, Noise rate 0.001. Better model.\n",
      "Episode 200, Average Score: 24.21, (33.02/33.02), Reward fraction 0.39\tTime 10.20, Noise rate 0.002.\n",
      "Episode 202, Average Score: 24.58, (34.13/34.13), Reward fraction 0.39\tTime 10.40, Noise rate 0.000. Better model.\n",
      "Episode 203, Average Score: 24.58, (4.39/4.39), Reward fraction 0.39\tTime 10.25, Noise rate 0.001. Better model.\n",
      "Episode 204, Average Score: 24.85, (34.64/34.64), Reward fraction 0.39\tTime 10.32, Noise rate 0.001. Better model.\n",
      "Episode 205, Average Score: 25.14, (37.66/37.66), Reward fraction 0.40\tTime 10.29, Noise rate 0.000. Better model.\n",
      "Episode 206, Average Score: 25.23, (29.56/29.56), Reward fraction 0.40\tTime 10.30, Noise rate 0.001. Better model.\n",
      "Episode 207, Average Score: 25.24, (24.94/24.94), Reward fraction 0.40\tTime 10.36, Noise rate 0.001. Better model.\n",
      "Episode 300, Average Score: 21.69, (28.23/28.23), Reward fraction 0.44\tTime 10.86, Noise rate 0.000.\n",
      "Episode 400, Average Score: 19.44, (12.32/12.32), Reward fraction 0.46\tTime 11.58, Noise rate 0.000.\n",
      "Episode 479, Average Score: 25.41, (32.53/32.53), Reward fraction 0.49\tTime 12.17, Noise rate 0.000. Better model.\n",
      "Episode 480, Average Score: 25.46, (31.21/31.21), Reward fraction 0.49\tTime 12.35, Noise rate 0.000. Better model.\n",
      "Episode 482, Average Score: 25.50, (29.53/29.53), Reward fraction 0.49\tTime 12.16, Noise rate 0.000. Better model.\n",
      "Episode 483, Average Score: 25.80, (34.78/34.78), Reward fraction 0.49\tTime 12.23, Noise rate 0.000. Better model.\n",
      "Episode 484, Average Score: 26.14, (36.75/36.75), Reward fraction 0.49\tTime 12.67, Noise rate 0.000. Better model.\n",
      "Episode 485, Average Score: 26.16, (30.46/30.46), Reward fraction 0.49\tTime 12.93, Noise rate 0.000. Better model.\n",
      "Episode 486, Average Score: 26.27, (38.69/38.69), Reward fraction 0.49\tTime 12.10, Noise rate 0.000. Better model.\n",
      "Episode 487, Average Score: 26.28, (35.41/35.41), Reward fraction 0.50\tTime 12.10, Noise rate 0.000. Better model.\n",
      "Episode 488, Average Score: 26.59, (35.10/35.10), Reward fraction 0.50\tTime 12.20, Noise rate 0.000. Better model.\n",
      "Episode 489, Average Score: 26.74, (35.23/35.23), Reward fraction 0.50\tTime 12.20, Noise rate 0.000. Better model.\n",
      "Episode 490, Average Score: 27.08, (37.40/37.40), Reward fraction 0.50\tTime 12.26, Noise rate 0.000. Better model.\n",
      "Episode 497, Average Score: 27.19, (34.06/34.06), Reward fraction 0.50\tTime 12.16, Noise rate 0.000. Better model.\n",
      "Episode 498, Average Score: 27.20, (31.35/31.35), Reward fraction 0.50\tTime 12.25, Noise rate 0.000. Better model.\n",
      "Episode 500, Average Score: 26.92, (3.19/3.19), Reward fraction 0.50\tTime 12.42, Noise rate 0.000.0.\n"
     ]
    }
   ],
   "source": [
    "# Run for the one agent environment \n",
    "with Environment (envFile='.\\Reacher_Windows_x86_64\\Reacher.exe') as env:\n",
    "    singleReacher = ddpg ( 'SingleAgent', Agent(env, random_seed=2), goal=30, n_episodes=500 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktxPvAMFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotScores( singleReacher )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single reacher environment was not solved. It seems to continouosly contain a lot of noice. But with the 1/20 number of agents it also gets less relevant observations. Whit tuning it could propably reach the goal.\n",
    "\n",
    "\n",
    "#### Test test same DDPG on the Crawler agent environement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: CrawlerBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 129\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 20\n",
      "        Vector Action descriptions: , , , , , , , , , , , , , , , , , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created unity enviroment from  .\\Crawler_Windows_x86_64\\Crawler.exe\n",
      "Environment     : .\\Crawler_Windows_x86_64\\Crawler.exe\n",
      "Number of agents: 12\n",
      "State size      : 129\n",
      "Action size     : 20\n",
      "Created agent: states =  129  actions =  20  reward level =  -1.0\n",
      "\n",
      "Restart learning - no checkpoint file found: Crawler-best_actor.pth\n",
      "Episode 1, Average Score: 4.70, (8.68/2.14), Reward fraction 0.00\tTime 0.76, Noise rate 1.000. Better model.\n",
      "Episode 100, Average Score: 0.44, (1.20/-0.79), Reward fraction 0.63\tTime 0.04, Noise rate 0.117.\n",
      "Episode 200, Average Score: 0.84, (1.31/-0.52), Reward fraction 0.69\tTime 0.04, Noise rate 0.154.\n",
      "Episode 300, Average Score: 0.95, (1.11/-0.50), Reward fraction 0.71\tTime 0.22, Noise rate 0.150.\n",
      "Episode 400, Average Score: 1.10, (3.69/-1.85), Reward fraction 0.72\tTime 0.24, Noise rate 0.211.\n",
      "Episode 500, Average Score: 1.76, (5.29/1.63), Reward fraction 0.73\tTime 0.26, Noise rate 0.146...\n",
      "Episode 600, Average Score: 3.02, (7.40/-0.63), Reward fraction 0.74\tTime 0.25, Noise rate 0.187..\n",
      "Episode 653, Average Score: 4.72, (12.04/2.84), Reward fraction 0.75\tTime 0.47, Noise rate 0.190. Better model.\n",
      "Episode 654, Average Score: 4.76, (10.12/3.04), Reward fraction 0.75\tTime 0.09, Noise rate 0.190. Better model.\n",
      "Episode 655, Average Score: 4.79, (6.43/0.65), Reward fraction 0.75\tTime 0.24, Noise rate 0.190. Better model.\n",
      "Episode 656, Average Score: 4.80, (10.68/3.64), Reward fraction 0.75\tTime 0.27, Noise rate 0.190. Better model.\n",
      "Episode 657, Average Score: 4.85, (9.37/2.67), Reward fraction 0.75\tTime 0.27, Noise rate 0.190. Better model.\n",
      "Episode 658, Average Score: 4.88, (9.70/2.80), Reward fraction 0.75\tTime 0.26, Noise rate 0.190. Better model.\n",
      "Episode 660, Average Score: 4.90, (6.00/1.88), Reward fraction 0.75\tTime 0.24, Noise rate 0.190. Better model.\n",
      "Episode 661, Average Score: 4.94, (8.16/2.07), Reward fraction 0.75\tTime 0.28, Noise rate 0.190. Better model.\n",
      "Episode 663, Average Score: 4.95, (5.14/0.92), Reward fraction 0.75\tTime 0.23, Noise rate 0.190. Better model.\n",
      "Episode 664, Average Score: 4.96, (4.16/1.14), Reward fraction 0.75\tTime 0.23, Noise rate 0.190. Better model.\n",
      "Episode 665, Average Score: 4.96, (8.48/2.96), Reward fraction 0.75\tTime 0.08, Noise rate 0.190. Better model.\n",
      "Episode 670, Average Score: 4.99, (6.42/2.23), Reward fraction 0.75\tTime 0.07, Noise rate 0.190. Better model.\n",
      "Episode 671, Average Score: 5.04, (8.79/2.60), Reward fraction 0.75\tTime 0.24, Noise rate 0.190. Better model.\n",
      "Episode 672, Average Score: 5.09, (7.92/1.39), Reward fraction 0.75\tTime 0.27, Noise rate 0.190. Better model.\n",
      "Episode 673, Average Score: 5.14, (10.23/2.82), Reward fraction 0.75\tTime 0.27, Noise rate 0.190. Better model.\n",
      "Episode 676, Average Score: 5.15, (7.96/1.96), Reward fraction 0.75\tTime 0.27, Noise rate 0.190. Better model.\n",
      "Episode 678, Average Score: 5.19, (12.77/3.97), Reward fraction 0.76\tTime 0.27, Noise rate 0.157. Better model.\n",
      "Episode 679, Average Score: 5.20, (7.01/1.21), Reward fraction 0.76\tTime 0.24, Noise rate 0.157. Better model.\n",
      "Episode 680, Average Score: 5.23, (7.39/0.85), Reward fraction 0.76\tTime 0.28, Noise rate 0.157. Better model.\n",
      "Episode 681, Average Score: 5.24, (7.52/1.57), Reward fraction 0.76\tTime 0.08, Noise rate 0.157. Better model.\n",
      "Episode 682, Average Score: 5.30, (11.85/1.56), Reward fraction 0.76\tTime 0.46, Noise rate 0.157. Better model.\n",
      "Episode 683, Average Score: 5.32, (7.50/1.10), Reward fraction 0.76\tTime 0.09, Noise rate 0.157. Better model.\n",
      "Episode 684, Average Score: 5.34, (10.34/2.64), Reward fraction 0.76\tTime 0.27, Noise rate 0.157. Better model.\n",
      "Episode 685, Average Score: 5.37, (8.22/1.75), Reward fraction 0.76\tTime 0.26, Noise rate 0.157. Better model.\n",
      "Episode 686, Average Score: 5.40, (9.67/4.74), Reward fraction 0.76\tTime 0.27, Noise rate 0.157. Better model.\n",
      "Episode 688, Average Score: 5.40, (9.05/2.86), Reward fraction 0.76\tTime 0.26, Noise rate 0.157. Better model.\n",
      "Episode 689, Average Score: 5.44, (10.62/2.01), Reward fraction 0.76\tTime 0.27, Noise rate 0.157. Better model.\n",
      "Episode 690, Average Score: 5.46, (7.34/2.87), Reward fraction 0.76\tTime 0.25, Noise rate 0.157. Better model.\n",
      "Episode 691, Average Score: 5.51, (12.57/2.52), Reward fraction 0.76\tTime 0.29, Noise rate 0.157. Better model.\n",
      "Episode 692, Average Score: 5.52, (7.21/1.79), Reward fraction 0.76\tTime 0.24, Noise rate 0.157. Better model.\n",
      "Episode 694, Average Score: 5.56, (11.42/4.09), Reward fraction 0.76\tTime 0.27, Noise rate 0.157. Better model.\n",
      "Episode 695, Average Score: 5.63, (12.78/5.97), Reward fraction 0.76\tTime 0.50, Noise rate 0.157. Better model.\n",
      "Episode 696, Average Score: 5.70, (11.68/4.78), Reward fraction 0.76\tTime 0.26, Noise rate 0.157. Better model.\n",
      "Episode 697, Average Score: 5.74, (8.38/1.64), Reward fraction 0.76\tTime 0.07, Noise rate 0.157. Better model.\n",
      "Episode 698, Average Score: 5.77, (6.85/1.87), Reward fraction 0.76\tTime 0.27, Noise rate 0.157. Better model.\n",
      "Episode 699, Average Score: 5.81, (7.25/2.28), Reward fraction 0.76\tTime 0.30, Noise rate 0.157. Better model.\n",
      "Episode 700, Average Score: 5.85, (10.97/4.90), Reward fraction 0.76\tTime 0.29, Noise rate 0.157. Better model.\n",
      "Episode 700, Average Score: 5.85, (10.97/4.90), Reward fraction 0.76\tTime 0.29, Noise rate 0.157.\n",
      "Episode 701, Average Score: 5.85, (4.09/-0.14), Reward fraction 0.76\tTime 0.05, Noise rate 0.157. Better model.\n",
      "Episode 702, Average Score: 5.88, (7.48/2.95), Reward fraction 0.76\tTime 0.25, Noise rate 0.157. Better model.\n",
      "Episode 703, Average Score: 5.92, (7.20/2.55), Reward fraction 0.76\tTime 0.27, Noise rate 0.157. Better model.\n",
      "Episode 704, Average Score: 5.92, (7.17/2.43), Reward fraction 0.76\tTime 0.24, Noise rate 0.157. Better model.\n",
      "Episode 705, Average Score: 5.96, (12.84/3.77), Reward fraction 0.76\tTime 0.29, Noise rate 0.193. Better model.\n",
      "Episode 706, Average Score: 5.97, (8.41/3.80), Reward fraction 0.76\tTime 0.26, Noise rate 0.193. Better model.\n",
      "Episode 707, Average Score: 6.00, (8.26/3.36), Reward fraction 0.76\tTime 0.08, Noise rate 0.193. Better model.\n",
      "Episode 708, Average Score: 6.05, (11.31/7.39), Reward fraction 0.76\tTime 0.44, Noise rate 0.193. Better model.\n",
      "Episode 709, Average Score: 6.06, (11.70/7.18), Reward fraction 0.76\tTime 0.28, Noise rate 0.193. Better model.\n",
      "Episode 710, Average Score: 6.09, (14.34/4.51), Reward fraction 0.76\tTime 0.30, Noise rate 0.193. Better model.\n",
      "Episode 716, Average Score: 6.11, (15.02/5.09), Reward fraction 0.76\tTime 0.28, Noise rate 0.193. Better model.\n",
      "Episode 717, Average Score: 6.14, (11.61/3.45), Reward fraction 0.76\tTime 0.27, Noise rate 0.193. Better model.\n",
      "Episode 718, Average Score: 6.15, (12.17/6.50), Reward fraction 0.76\tTime 0.30, Noise rate 0.193. Better model.\n",
      "Episode 719, Average Score: 6.15, (11.63/4.33), Reward fraction 0.76\tTime 0.27, Noise rate 0.193. Better model.\n",
      "Episode 720, Average Score: 6.17, (9.46/3.24), Reward fraction 0.76\tTime 0.26, Noise rate 0.193. Better model.\n",
      "Episode 721, Average Score: 6.19, (13.04/8.29), Reward fraction 0.76\tTime 0.31, Noise rate 0.193. Better model.\n",
      "Episode 722, Average Score: 6.21, (10.62/5.63), Reward fraction 0.76\tTime 0.29, Noise rate 0.193. Better model.\n",
      "Episode 723, Average Score: 6.22, (11.92/8.06), Reward fraction 0.76\tTime 0.27, Noise rate 0.193. Better model.\n",
      "Episode 732, Average Score: 6.27, (13.03/5.42), Reward fraction 0.77\tTime 0.27, Noise rate 0.183. Better model.\n",
      "Episode 733, Average Score: 6.30, (11.80/5.98), Reward fraction 0.77\tTime 0.27, Noise rate 0.183. Better model.\n",
      "Episode 734, Average Score: 6.31, (11.39/4.44), Reward fraction 0.77\tTime 0.28, Noise rate 0.183. Better model.\n",
      "Episode 735, Average Score: 6.35, (11.10/5.99), Reward fraction 0.77\tTime 0.28, Noise rate 0.183. Better model.\n",
      "Episode 736, Average Score: 6.38, (9.62/4.10), Reward fraction 0.77\tTime 0.25, Noise rate 0.183. Better model.\n",
      "Episode 737, Average Score: 6.43, (15.80/6.17), Reward fraction 0.77\tTime 0.28, Noise rate 0.183. Better model.\n",
      "Episode 738, Average Score: 6.50, (13.41/5.08), Reward fraction 0.77\tTime 0.28, Noise rate 0.183. Better model.\n",
      "Episode 739, Average Score: 6.58, (13.46/7.30), Reward fraction 0.77\tTime 0.30, Noise rate 0.183. Better model.\n",
      "Episode 740, Average Score: 6.62, (9.99/3.51), Reward fraction 0.77\tTime 0.27, Noise rate 0.183. Better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 741, Average Score: 6.66, (12.57/5.39), Reward fraction 0.77\tTime 0.28, Noise rate 0.183. Better model.\n",
      "Episode 742, Average Score: 6.69, (11.55/5.78), Reward fraction 0.77\tTime 0.27, Noise rate 0.183. Better model.\n",
      "Episode 743, Average Score: 6.76, (13.30/6.05), Reward fraction 0.77\tTime 0.28, Noise rate 0.183. Better model.\n",
      "Episode 744, Average Score: 6.77, (10.28/6.72), Reward fraction 0.77\tTime 0.27, Noise rate 0.183. Better model.\n",
      "Episode 745, Average Score: 6.81, (12.04/7.59), Reward fraction 0.77\tTime 0.28, Noise rate 0.183. Better model.\n",
      "Episode 746, Average Score: 6.85, (10.49/3.70), Reward fraction 0.77\tTime 0.27, Noise rate 0.183. Better model.\n",
      "Episode 747, Average Score: 6.88, (11.61/2.73), Reward fraction 0.77\tTime 0.27, Noise rate 0.183. Better model.\n",
      "Episode 755, Average Score: 6.89, (10.90/6.49), Reward fraction 0.77\tTime 0.27, Noise rate 0.183. Better model.\n",
      "Episode 756, Average Score: 6.89, (9.35/6.08), Reward fraction 0.77\tTime 0.25, Noise rate 0.183. Better model.\n",
      "Episode 757, Average Score: 6.91, (8.28/5.30), Reward fraction 0.77\tTime 0.30, Noise rate 0.182. Better model.\n",
      "Episode 758, Average Score: 6.96, (12.79/6.94), Reward fraction 0.77\tTime 0.28, Noise rate 0.182. Better model.\n",
      "Episode 759, Average Score: 6.99, (7.72/4.08), Reward fraction 0.77\tTime 0.27, Noise rate 0.182. Better model.\n",
      "Episode 760, Average Score: 7.01, (8.19/2.90), Reward fraction 0.77\tTime 0.07, Noise rate 0.182. Better model.\n",
      "Episode 761, Average Score: 7.02, (8.92/2.09), Reward fraction 0.77\tTime 0.28, Noise rate 0.182. Better model.\n",
      "Episode 766, Average Score: 7.05, (11.85/4.52), Reward fraction 0.77\tTime 0.27, Noise rate 0.182. Better model.\n",
      "Episode 767, Average Score: 7.05, (6.24/1.93), Reward fraction 0.77\tTime 0.07, Noise rate 0.182. Better model.\n",
      "Episode 771, Average Score: 7.05, (8.30/3.65), Reward fraction 0.77\tTime 0.24, Noise rate 0.182. Better model.\n",
      "Episode 772, Average Score: 7.07, (10.58/2.88), Reward fraction 0.77\tTime 0.08, Noise rate 0.182. Better model.\n",
      "Episode 774, Average Score: 7.08, (7.34/2.03), Reward fraction 0.77\tTime 0.23, Noise rate 0.182. Better model.\n",
      "Episode 775, Average Score: 7.14, (13.42/6.38), Reward fraction 0.77\tTime 0.27, Noise rate 0.182. Better model.\n",
      "Episode 776, Average Score: 7.17, (9.31/5.25), Reward fraction 0.77\tTime 0.27, Noise rate 0.182. Better model.\n",
      "Episode 777, Average Score: 7.24, (12.41/5.67), Reward fraction 0.77\tTime 0.27, Noise rate 0.182. Better model.\n",
      "Episode 778, Average Score: 7.25, (11.80/5.45), Reward fraction 0.77\tTime 0.27, Noise rate 0.182. Better model.\n",
      "Episode 779, Average Score: 7.32, (13.73/9.41), Reward fraction 0.77\tTime 0.30, Noise rate 0.182. Better model.\n",
      "Episode 780, Average Score: 7.37, (13.28/6.46), Reward fraction 0.77\tTime 0.27, Noise rate 0.182. Better model.\n",
      "Episode 781, Average Score: 7.40, (12.30/4.60), Reward fraction 0.77\tTime 0.27, Noise rate 0.182. Better model.\n",
      "Episode 782, Average Score: 7.43, (11.66/6.27), Reward fraction 0.77\tTime 0.30, Noise rate 0.182. Better model.\n",
      "Episode 783, Average Score: 7.44, (10.09/3.45), Reward fraction 0.77\tTime 0.25, Noise rate 0.182. Better model.\n",
      "Episode 784, Average Score: 7.49, (13.51/5.55), Reward fraction 0.77\tTime 0.28, Noise rate 0.182. Better model.\n",
      "Episode 785, Average Score: 7.53, (11.88/7.99), Reward fraction 0.77\tTime 0.27, Noise rate 0.182. Better model.\n",
      "Episode 786, Average Score: 7.54, (11.87/6.87), Reward fraction 0.78\tTime 0.28, Noise rate 0.168. Better model.\n",
      "Episode 787, Average Score: 7.56, (11.12/6.11), Reward fraction 0.78\tTime 0.26, Noise rate 0.168. Better model.\n",
      "Episode 788, Average Score: 7.59, (11.01/7.22), Reward fraction 0.78\tTime 0.26, Noise rate 0.168. Better model.\n",
      "Episode 790, Average Score: 7.59, (9.22/4.41), Reward fraction 0.78\tTime 0.08, Noise rate 0.168. Better model.\n",
      "Episode 791, Average Score: 7.64, (15.49/8.48), Reward fraction 0.78\tTime 0.46, Noise rate 0.168. Better model.\n",
      "Episode 792, Average Score: 7.69, (10.60/7.34), Reward fraction 0.78\tTime 0.08, Noise rate 0.168. Better model.\n",
      "Episode 793, Average Score: 7.71, (8.40/4.63), Reward fraction 0.78\tTime 0.25, Noise rate 0.168. Better model.\n",
      "Episode 794, Average Score: 7.76, (13.32/8.61), Reward fraction 0.78\tTime 0.29, Noise rate 0.168. Better model.\n",
      "Episode 798, Average Score: 7.78, (9.56/5.97), Reward fraction 0.78\tTime 0.27, Noise rate 0.168. Better model.\n",
      "Episode 799, Average Score: 7.79, (8.21/2.48), Reward fraction 0.78\tTime 0.25, Noise rate 0.168. Better model.\n",
      "Episode 800, Average Score: 7.80, (12.02/5.12), Reward fraction 0.78\tTime 0.29, Noise rate 0.168. Better model.\n",
      "Episode 800, Average Score: 7.80, (12.02/5.12), Reward fraction 0.78\tTime 0.29, Noise rate 0.168.\n",
      "Episode 801, Average Score: 7.86, (11.44/5.34), Reward fraction 0.78\tTime 0.29, Noise rate 0.168. Better model.\n",
      "Episode 802, Average Score: 7.87, (8.33/3.63), Reward fraction 0.78\tTime 0.08, Noise rate 0.168. Better model.\n",
      "Episode 804, Average Score: 7.87, (7.73/4.70), Reward fraction 0.78\tTime 0.25, Noise rate 0.168. Better model.\n",
      "Episode 806, Average Score: 7.88, (10.71/3.42), Reward fraction 0.78\tTime 0.25, Noise rate 0.168. Better model.\n",
      "Episode 807, Average Score: 7.89, (9.78/3.91), Reward fraction 0.78\tTime 0.25, Noise rate 0.168. Better model.\n",
      "Episode 813, Average Score: 7.90, (10.70/7.94), Reward fraction 0.78\tTime 0.26, Noise rate 0.168. Better model.\n",
      "Episode 814, Average Score: 7.91, (8.45/5.58), Reward fraction 0.78\tTime 0.30, Noise rate 0.150. Better model.\n",
      "Episode 817, Average Score: 7.94, (17.36/8.57), Reward fraction 0.78\tTime 0.48, Noise rate 0.150. Better model.\n",
      "Episode 819, Average Score: 7.95, (11.09/6.72), Reward fraction 0.78\tTime 0.28, Noise rate 0.150. Better model.\n",
      "Episode 820, Average Score: 7.96, (9.62/6.94), Reward fraction 0.78\tTime 0.27, Noise rate 0.150. Better model.\n",
      "Episode 824, Average Score: 8.04, (16.83/11.24), Reward fraction 0.78\tTime 0.46, Noise rate 0.150. Better model.\n",
      "Episode 826, Average Score: 8.06, (9.78/4.56), Reward fraction 0.78\tTime 0.09, Noise rate 0.150. Better model.\n",
      "Episode 827, Average Score: 8.07, (15.60/8.15), Reward fraction 0.78\tTime 0.45, Noise rate 0.150. Better model.\n",
      "Episode 828, Average Score: 8.12, (13.40/8.19), Reward fraction 0.78\tTime 0.28, Noise rate 0.150. Better model.\n",
      "Episode 829, Average Score: 8.16, (11.29/8.33), Reward fraction 0.78\tTime 0.26, Noise rate 0.150. Better model.\n",
      "Episode 830, Average Score: 8.19, (13.53/7.45), Reward fraction 0.78\tTime 0.29, Noise rate 0.150. Better model.\n",
      "Episode 831, Average Score: 8.20, (12.99/7.94), Reward fraction 0.78\tTime 0.28, Noise rate 0.150. Better model.\n",
      "Episode 832, Average Score: 8.21, (14.00/9.63), Reward fraction 0.78\tTime 0.29, Noise rate 0.150. Better model.\n",
      "Episode 833, Average Score: 8.23, (16.16/4.53), Reward fraction 0.78\tTime 0.27, Noise rate 0.150. Better model.\n",
      "Episode 834, Average Score: 8.25, (15.58/8.35), Reward fraction 0.78\tTime 0.29, Noise rate 0.150. Better model.\n",
      "Episode 835, Average Score: 8.27, (13.71/5.56), Reward fraction 0.78\tTime 0.31, Noise rate 0.150. Better model.\n",
      "Episode 836, Average Score: 8.28, (10.50/6.19), Reward fraction 0.78\tTime 0.26, Noise rate 0.150. Better model.\n",
      "Episode 838, Average Score: 8.30, (14.25/7.59), Reward fraction 0.78\tTime 0.31, Noise rate 0.151. Better model.\n",
      "Episode 853, Average Score: 8.33, (11.62/7.23), Reward fraction 0.78\tTime 0.27, Noise rate 0.151. Better model.\n",
      "Episode 856, Average Score: 8.34, (13.78/8.15), Reward fraction 0.78\tTime 0.28, Noise rate 0.151. Better model.\n",
      "Episode 857, Average Score: 8.35, (10.20/4.12), Reward fraction 0.78\tTime 0.08, Noise rate 0.151. Better model.\n",
      "Episode 858, Average Score: 8.35, (11.44/6.13), Reward fraction 0.78\tTime 0.27, Noise rate 0.151. Better model.\n",
      "Episode 860, Average Score: 8.36, (12.74/6.67), Reward fraction 0.78\tTime 0.27, Noise rate 0.151. Better model.\n",
      "Episode 862, Average Score: 8.43, (11.57/6.30), Reward fraction 0.79\tTime 0.27, Noise rate 0.151. Better model.\n",
      "Episode 863, Average Score: 8.49, (12.59/8.14), Reward fraction 0.79\tTime 0.26, Noise rate 0.151. Better model.\n",
      "Episode 864, Average Score: 8.56, (14.57/8.55), Reward fraction 0.79\tTime 0.27, Noise rate 0.151. Better model.\n",
      "Episode 865, Average Score: 8.63, (13.76/8.52), Reward fraction 0.79\tTime 0.29, Noise rate 0.166. Better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 866, Average Score: 8.66, (14.99/5.27), Reward fraction 0.79\tTime 0.27, Noise rate 0.166. Better model.\n",
      "Episode 867, Average Score: 8.71, (11.70/7.93), Reward fraction 0.79\tTime 0.27, Noise rate 0.166. Better model.\n",
      "Episode 868, Average Score: 8.76, (12.02/5.56), Reward fraction 0.79\tTime 0.27, Noise rate 0.166. Better model.\n",
      "Episode 869, Average Score: 8.81, (10.72/6.02), Reward fraction 0.79\tTime 0.28, Noise rate 0.166. Better model.\n",
      "Episode 870, Average Score: 8.87, (14.03/9.58), Reward fraction 0.79\tTime 0.28, Noise rate 0.166. Better model.\n",
      "Episode 871, Average Score: 8.92, (15.01/9.33), Reward fraction 0.79\tTime 0.30, Noise rate 0.166. Better model.\n",
      "Episode 872, Average Score: 8.96, (14.26/9.20), Reward fraction 0.79\tTime 0.27, Noise rate 0.166. Better model.\n",
      "Episode 873, Average Score: 9.02, (14.18/8.01), Reward fraction 0.79\tTime 0.29, Noise rate 0.166. Better model.\n",
      "Episode 874, Average Score: 9.06, (10.82/7.30), Reward fraction 0.79\tTime 0.29, Noise rate 0.166. Better model.\n",
      "Episode 875, Average Score: 9.10, (19.00/10.27), Reward fraction 0.79\tTime 0.29, Noise rate 0.166. Better model.\n",
      "Episode 876, Average Score: 9.15, (13.46/9.60), Reward fraction 0.79\tTime 0.48, Noise rate 0.166. Better model.\n",
      "Episode 877, Average Score: 9.15, (12.19/9.19), Reward fraction 0.79\tTime 0.32, Noise rate 0.166. Better model.\n",
      "Episode 878, Average Score: 9.19, (15.33/8.92), Reward fraction 0.79\tTime 0.30, Noise rate 0.166. Better model.\n",
      "Episode 880, Average Score: 9.20, (13.02/9.20), Reward fraction 0.79\tTime 0.28, Noise rate 0.166. Better model.\n",
      "Episode 881, Average Score: 9.25, (16.92/10.58), Reward fraction 0.79\tTime 0.30, Noise rate 0.166. Better model.\n",
      "Episode 882, Average Score: 9.27, (13.90/9.66), Reward fraction 0.79\tTime 0.27, Noise rate 0.166. Better model.\n",
      "Episode 883, Average Score: 9.34, (15.82/11.72), Reward fraction 0.79\tTime 0.29, Noise rate 0.166. Better model.\n",
      "Episode 884, Average Score: 9.37, (17.64/9.07), Reward fraction 0.79\tTime 0.47, Noise rate 0.166. Better model.\n",
      "Episode 885, Average Score: 9.39, (16.16/8.29), Reward fraction 0.79\tTime 0.28, Noise rate 0.166. Better model.\n",
      "Episode 886, Average Score: 9.43, (16.58/9.28), Reward fraction 0.79\tTime 0.29, Noise rate 0.166. Better model.\n",
      "Episode 887, Average Score: 9.47, (15.59/9.54), Reward fraction 0.79\tTime 0.31, Noise rate 0.166. Better model.\n",
      "Episode 888, Average Score: 9.52, (17.07/9.15), Reward fraction 0.79\tTime 0.30, Noise rate 0.155. Better model.\n",
      "Episode 889, Average Score: 9.57, (14.50/8.99), Reward fraction 0.79\tTime 0.27, Noise rate 0.155. Better model.\n",
      "Episode 890, Average Score: 9.64, (16.73/12.42), Reward fraction 0.79\tTime 0.30, Noise rate 0.155. Better model.\n",
      "Episode 893, Average Score: 9.66, (12.86/7.93), Reward fraction 0.79\tTime 0.28, Noise rate 0.155. Better model.\n",
      "Episode 894, Average Score: 9.67, (14.94/6.76), Reward fraction 0.79\tTime 0.28, Noise rate 0.155. Better model.\n",
      "Episode 895, Average Score: 9.72, (17.35/6.91), Reward fraction 0.79\tTime 0.30, Noise rate 0.155. Better model.\n",
      "Episode 896, Average Score: 9.72, (10.00/4.42), Reward fraction 0.79\tTime 0.25, Noise rate 0.155. Better model.\n",
      "Episode 897, Average Score: 9.79, (15.87/10.79), Reward fraction 0.79\tTime 0.28, Noise rate 0.155. Better model.\n",
      "Episode 898, Average Score: 9.82, (12.77/7.39), Reward fraction 0.79\tTime 0.27, Noise rate 0.155. Better model.\n",
      "Episode 899, Average Score: 9.83, (9.96/5.43), Reward fraction 0.79\tTime 0.26, Noise rate 0.155. Better model.\n",
      "Episode 900, Average Score: 9.86, (14.70/9.21), Reward fraction 0.79\tTime 0.29, Noise rate 0.155. Better model.\n",
      "Episode 900, Average Score: 9.86, (14.70/9.21), Reward fraction 0.79\tTime 0.29, Noise rate 0.155.\n",
      "Episode 901, Average Score: 9.87, (12.78/5.00), Reward fraction 0.79\tTime 0.27, Noise rate 0.155. Better model.\n",
      "Episode 902, Average Score: 9.92, (15.78/7.62), Reward fraction 0.79\tTime 0.29, Noise rate 0.155. Better model.\n",
      "Episode 903, Average Score: 9.99, (13.97/8.05), Reward fraction 0.79\tTime 0.30, Noise rate 0.155. Better model.\n",
      "Episode 904, Average Score: 10.04, (12.62/8.10), Reward fraction 0.79\tTime 0.46, Noise rate 0.155. Better model.\n",
      "Episode 905, Average Score: 10.11, (17.31/11.25), Reward fraction 0.79\tTime 0.29, Noise rate 0.155. Better model.\n",
      "Episode 906, Average Score: 10.15, (15.41/6.36), Reward fraction 0.79\tTime 0.30, Noise rate 0.155. Better model.\n",
      "Episode 907, Average Score: 10.22, (17.22/10.65), Reward fraction 0.79\tTime 0.31, Noise rate 0.155. Better model.\n",
      "Episode 908, Average Score: 10.27, (16.85/8.40), Reward fraction 0.79\tTime 0.30, Noise rate 0.155. Better model.\n",
      "Episode 909, Average Score: 10.30, (12.08/2.55), Reward fraction 0.79\tTime 0.29, Noise rate 0.155. Better model.\n",
      "Episode 910, Average Score: 10.34, (18.65/10.74), Reward fraction 0.79\tTime 0.47, Noise rate 0.158. Better model.\n",
      "Episode 911, Average Score: 10.37, (16.54/8.82), Reward fraction 0.79\tTime 0.28, Noise rate 0.158. Better model.\n",
      "Episode 913, Average Score: 10.40, (16.32/11.27), Reward fraction 0.79\tTime 0.29, Noise rate 0.158. Better model.\n",
      "Episode 914, Average Score: 10.41, (10.96/5.74), Reward fraction 0.79\tTime 0.26, Noise rate 0.158. Better model.\n",
      "Episode 916, Average Score: 10.45, (18.04/12.39), Reward fraction 0.79\tTime 0.28, Noise rate 0.158. Better model.\n",
      "Episode 917, Average Score: 10.47, (17.56/7.33), Reward fraction 0.79\tTime 0.29, Noise rate 0.158. Better model.\n",
      "Episode 918, Average Score: 10.52, (17.47/8.88), Reward fraction 0.79\tTime 0.30, Noise rate 0.158. Better model.\n",
      "Episode 919, Average Score: 10.57, (16.86/12.50), Reward fraction 0.79\tTime 0.50, Noise rate 0.158. Better model.\n",
      "Episode 920, Average Score: 10.61, (15.27/6.11), Reward fraction 0.79\tTime 0.28, Noise rate 0.158. Better model.\n",
      "Episode 921, Average Score: 10.67, (16.59/7.24), Reward fraction 0.79\tTime 0.29, Noise rate 0.158. Better model.\n",
      "Episode 922, Average Score: 10.69, (14.46/6.02), Reward fraction 0.79\tTime 0.31, Noise rate 0.158. Better model.\n",
      "Episode 923, Average Score: 10.69, (14.09/6.62), Reward fraction 0.79\tTime 0.27, Noise rate 0.158. Better model.\n",
      "Episode 925, Average Score: 10.72, (14.45/9.72), Reward fraction 0.79\tTime 0.33, Noise rate 0.158. Better model.\n",
      "Episode 926, Average Score: 10.80, (20.88/13.38), Reward fraction 0.79\tTime 0.49, Noise rate 0.158. Better model.\n",
      "Episode 927, Average Score: 10.86, (20.11/14.60), Reward fraction 0.79\tTime 0.33, Noise rate 0.158. Better model.\n",
      "Episode 928, Average Score: 10.93, (22.09/14.31), Reward fraction 0.79\tTime 0.53, Noise rate 0.158. Better model.\n",
      "Episode 929, Average Score: 10.99, (18.40/11.55), Reward fraction 0.79\tTime 0.30, Noise rate 0.158. Better model.\n",
      "Episode 931, Average Score: 11.00, (18.14/8.47), Reward fraction 0.79\tTime 0.30, Noise rate 0.158. Better model.\n",
      "Episode 933, Average Score: 11.01, (14.89/6.94), Reward fraction 0.79\tTime 0.28, Noise rate 0.148. Better model.\n",
      "Episode 934, Average Score: 11.04, (17.88/9.80), Reward fraction 0.79\tTime 0.48, Noise rate 0.148. Better model.\n",
      "Episode 936, Average Score: 11.10, (20.47/13.34), Reward fraction 0.80\tTime 0.32, Noise rate 0.148. Better model.\n",
      "Episode 937, Average Score: 11.12, (15.84/8.21), Reward fraction 0.80\tTime 0.30, Noise rate 0.148. Better model.\n",
      "Episode 938, Average Score: 11.16, (17.16/12.07), Reward fraction 0.80\tTime 0.29, Noise rate 0.148. Better model.\n",
      "Episode 939, Average Score: 11.23, (17.46/11.75), Reward fraction 0.80\tTime 0.31, Noise rate 0.148. Better model.\n",
      "Episode 940, Average Score: 11.27, (15.93/10.40), Reward fraction 0.80\tTime 0.51, Noise rate 0.148. Better model.\n",
      "Episode 941, Average Score: 11.30, (13.41/7.83), Reward fraction 0.80\tTime 0.27, Noise rate 0.148. Better model.\n",
      "Episode 942, Average Score: 11.35, (16.17/8.23), Reward fraction 0.80\tTime 0.28, Noise rate 0.148. Better model.\n",
      "Episode 943, Average Score: 11.40, (13.92/5.39), Reward fraction 0.80\tTime 0.29, Noise rate 0.148. Better model.\n",
      "Episode 944, Average Score: 11.48, (17.89/13.28), Reward fraction 0.80\tTime 0.30, Noise rate 0.148. Better model.\n",
      "Episode 945, Average Score: 11.52, (16.12/10.47), Reward fraction 0.80\tTime 0.29, Noise rate 0.148. Better model.\n",
      "Episode 946, Average Score: 11.58, (17.01/10.18), Reward fraction 0.80\tTime 0.29, Noise rate 0.148. Better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 947, Average Score: 11.58, (10.27/4.09), Reward fraction 0.80\tTime 0.25, Noise rate 0.148. Better model.\n",
      "Episode 951, Average Score: 11.61, (14.67/9.19), Reward fraction 0.80\tTime 0.31, Noise rate 0.148. Better model.\n",
      "Episode 952, Average Score: 11.65, (16.80/8.15), Reward fraction 0.80\tTime 0.29, Noise rate 0.148. Better model.\n",
      "Episode 953, Average Score: 11.69, (18.87/4.67), Reward fraction 0.80\tTime 0.28, Noise rate 0.148. Better model.\n",
      "Episode 954, Average Score: 11.82, (24.38/10.01), Reward fraction 0.80\tTime 0.54, Noise rate 0.153. Better model.\n",
      "Episode 956, Average Score: 11.83, (14.54/5.47), Reward fraction 0.80\tTime 0.29, Noise rate 0.153. Better model.\n",
      "Episode 957, Average Score: 11.90, (18.46/10.55), Reward fraction 0.80\tTime 0.31, Noise rate 0.153. Better model.\n",
      "Episode 958, Average Score: 11.96, (20.32/8.67), Reward fraction 0.80\tTime 0.49, Noise rate 0.153. Better model.\n",
      "Episode 959, Average Score: 12.01, (10.50/5.28), Reward fraction 0.80\tTime 0.08, Noise rate 0.153. Better model.\n",
      "Episode 961, Average Score: 12.02, (12.05/3.55), Reward fraction 0.80\tTime 0.27, Noise rate 0.153. Better model.\n",
      "Episode 962, Average Score: 12.05, (15.31/9.75), Reward fraction 0.80\tTime 0.30, Noise rate 0.153. Better model.\n",
      "Episode 963, Average Score: 12.07, (16.54/6.82), Reward fraction 0.80\tTime 0.28, Noise rate 0.153. Better model.\n",
      "Episode 964, Average Score: 12.12, (20.04/11.51), Reward fraction 0.80\tTime 0.47, Noise rate 0.153. Better model.\n",
      "Episode 966, Average Score: 12.12, (16.25/10.96), Reward fraction 0.80\tTime 0.31, Noise rate 0.153. Better model.\n",
      "Episode 967, Average Score: 12.13, (13.74/7.63), Reward fraction 0.80\tTime 0.29, Noise rate 0.153. Better model.\n",
      "Episode 968, Average Score: 12.16, (16.06/4.01), Reward fraction 0.80\tTime 0.29, Noise rate 0.153. Better model.\n",
      "Episode 969, Average Score: 12.16, (12.89/6.41), Reward fraction 0.80\tTime 0.26, Noise rate 0.153. Better model.\n",
      "Episode 970, Average Score: 12.21, (19.70/13.64), Reward fraction 0.80\tTime 0.33, Noise rate 0.153. Better model.\n",
      "Episode 972, Average Score: 12.23, (18.63/9.02), Reward fraction 0.80\tTime 0.49, Noise rate 0.153. Better model.\n",
      "Episode 973, Average Score: 12.26, (18.38/9.35), Reward fraction 0.80\tTime 0.33, Noise rate 0.153. Better model.\n",
      "Episode 974, Average Score: 12.30, (16.78/9.69), Reward fraction 0.80\tTime 0.29, Noise rate 0.153. Better model.\n",
      "Episode 975, Average Score: 12.30, (19.04/11.26), Reward fraction 0.80\tTime 0.51, Noise rate 0.153. Better model.\n",
      "Episode 976, Average Score: 12.33, (18.50/9.99), Reward fraction 0.80\tTime 0.33, Noise rate 0.151. Better model.\n",
      "Episode 977, Average Score: 12.42, (22.94/13.98), Reward fraction 0.80\tTime 0.31, Noise rate 0.151. Better model.\n",
      "Episode 978, Average Score: 12.44, (17.16/11.46), Reward fraction 0.80\tTime 0.48, Noise rate 0.151. Better model.\n",
      "Episode 979, Average Score: 12.49, (19.81/11.60), Reward fraction 0.80\tTime 0.31, Noise rate 0.151. Better model.\n",
      "Episode 980, Average Score: 12.53, (17.67/10.09), Reward fraction 0.80\tTime 0.29, Noise rate 0.151. Better model.\n",
      "Episode 982, Average Score: 12.56, (18.35/12.07), Reward fraction 0.80\tTime 0.49, Noise rate 0.151. Better model.\n",
      "Episode 987, Average Score: 12.58, (19.45/14.89), Reward fraction 0.80\tTime 0.52, Noise rate 0.151. Better model.\n",
      "Episode 989, Average Score: 12.58, (15.20/5.53), Reward fraction 0.80\tTime 0.28, Noise rate 0.151. Better model.\n",
      "Episode 992, Average Score: 12.62, (18.00/11.56), Reward fraction 0.80\tTime 0.47, Noise rate 0.151. Better model.\n",
      "Episode 996, Average Score: 12.63, (13.48/7.39), Reward fraction 0.80\tTime 0.27, Noise rate 0.151. Better model.\n",
      "Episode 998, Average Score: 12.67, (20.49/13.72), Reward fraction 0.80\tTime 0.32, Noise rate 0.157. Better model.\n",
      "Episode 1000, Average Score: 12.69, (17.85/10.03), Reward fraction 0.80\tTime 0.30, Noise rate 0.157. Better model.\n",
      "Episode 1000, Average Score: 12.69, (17.85/10.03), Reward fraction 0.80\tTime 0.30, Noise rate 0.157.\n",
      "Episode 1001, Average Score: 12.73, (18.01/7.74), Reward fraction 0.80\tTime 0.51, Noise rate 0.157. Better model.\n",
      "Episode 1002, Average Score: 12.74, (17.95/10.40), Reward fraction 0.80\tTime 0.29, Noise rate 0.157. Better model.\n",
      "Episode 1004, Average Score: 12.74, (16.17/7.86), Reward fraction 0.80\tTime 0.31, Noise rate 0.157. Better model.\n",
      "Episode 1100, Average Score: 11.75, (13.54/8.48), Reward fraction 0.81\tTime 0.29, Noise rate 0.141..\n",
      "Episode 1160, Average Score: 12.86, (26.88/17.31), Reward fraction 0.82\tTime 0.33, Noise rate 0.108. Better model.\n",
      "Episode 1161, Average Score: 12.87, (16.02/8.52), Reward fraction 0.82\tTime 0.53, Noise rate 0.108. Better model.\n",
      "Episode 1162, Average Score: 12.95, (22.02/17.52), Reward fraction 0.82\tTime 0.31, Noise rate 0.108. Better model.\n",
      "Episode 1163, Average Score: 12.99, (18.70/10.62), Reward fraction 0.82\tTime 0.30, Noise rate 0.108. Better model.\n",
      "Episode 1164, Average Score: 13.00, (17.54/9.36), Reward fraction 0.82\tTime 0.34, Noise rate 0.108. Better model.\n",
      "Episode 1166, Average Score: 13.03, (18.40/11.45), Reward fraction 0.82\tTime 0.50, Noise rate 0.108. Better model.\n",
      "Episode 1168, Average Score: 13.13, (23.75/17.09), Reward fraction 0.82\tTime 0.34, Noise rate 0.108. Better model.\n",
      "Episode 1169, Average Score: 13.20, (18.60/5.44), Reward fraction 0.82\tTime 0.48, Noise rate 0.108. Better model.\n",
      "Episode 1170, Average Score: 13.23, (21.03/12.67), Reward fraction 0.82\tTime 0.31, Noise rate 0.108. Better model.\n",
      "Episode 1171, Average Score: 13.26, (17.24/7.64), Reward fraction 0.82\tTime 0.32, Noise rate 0.108. Better model.\n",
      "Episode 1172, Average Score: 13.27, (12.53/6.21), Reward fraction 0.82\tTime 0.27, Noise rate 0.108. Better model.\n",
      "Episode 1173, Average Score: 13.35, (21.27/13.33), Reward fraction 0.82\tTime 0.52, Noise rate 0.108. Better model.\n",
      "Episode 1174, Average Score: 13.41, (20.45/14.04), Reward fraction 0.82\tTime 0.36, Noise rate 0.135. Better model.\n",
      "Episode 1175, Average Score: 13.46, (18.05/6.00), Reward fraction 0.82\tTime 0.33, Noise rate 0.135. Better model.\n",
      "Episode 1176, Average Score: 13.46, (15.27/6.79), Reward fraction 0.82\tTime 0.29, Noise rate 0.135. Better model.\n",
      "Episode 1177, Average Score: 13.53, (20.74/9.38), Reward fraction 0.82\tTime 0.51, Noise rate 0.135. Better model.\n",
      "Episode 1178, Average Score: 13.57, (16.83/5.92), Reward fraction 0.82\tTime 0.32, Noise rate 0.135. Better model.\n",
      "Episode 1179, Average Score: 13.61, (19.57/6.24), Reward fraction 0.82\tTime 0.30, Noise rate 0.135. Better model.\n",
      "Episode 1181, Average Score: 13.69, (19.51/13.44), Reward fraction 0.82\tTime 0.33, Noise rate 0.135. Better model.\n",
      "Episode 1182, Average Score: 13.75, (15.96/9.99), Reward fraction 0.82\tTime 0.29, Noise rate 0.135. Better model.\n",
      "Episode 1183, Average Score: 13.85, (18.14/12.95), Reward fraction 0.82\tTime 0.49, Noise rate 0.135. Better model.\n",
      "Episode 1184, Average Score: 13.88, (15.70/5.81), Reward fraction 0.82\tTime 0.29, Noise rate 0.135. Better model.\n",
      "Episode 1187, Average Score: 13.94, (17.20/11.32), Reward fraction 0.82\tTime 0.29, Noise rate 0.135. Better model.\n",
      "Episode 1188, Average Score: 14.00, (17.86/15.12), Reward fraction 0.82\tTime 0.52, Noise rate 0.135. Better model.\n",
      "Episode 1189, Average Score: 14.09, (18.67/13.58), Reward fraction 0.82\tTime 0.30, Noise rate 0.135. Better model.\n",
      "Episode 1190, Average Score: 14.11, (11.79/5.38), Reward fraction 0.82\tTime 0.29, Noise rate 0.135. Better model.\n",
      "Episode 1191, Average Score: 14.12, (17.57/14.11), Reward fraction 0.82\tTime 0.30, Noise rate 0.135. Better model.\n",
      "Episode 1192, Average Score: 14.17, (17.71/12.07), Reward fraction 0.82\tTime 0.32, Noise rate 0.135. Better model.\n",
      "Episode 1193, Average Score: 14.17, (13.21/5.19), Reward fraction 0.82\tTime 0.30, Noise rate 0.135. Better model.\n",
      "Episode 1195, Average Score: 14.20, (19.27/6.36), Reward fraction 0.82\tTime 0.31, Noise rate 0.135. Better model.\n",
      "Episode 1200, Average Score: 14.19, (15.14/5.13), Reward fraction 0.82\tTime 0.28, Noise rate 0.070..\n",
      "Episode 1205, Average Score: 14.26, (24.86/17.29), Reward fraction 0.82\tTime 0.33, Noise rate 0.070. Better model.\n",
      "Episode 1206, Average Score: 14.27, (21.09/12.39), Reward fraction 0.82\tTime 0.53, Noise rate 0.070. Better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1214, Average Score: 14.31, (22.39/17.26), Reward fraction 0.82\tTime 0.52, Noise rate 0.070. Better model.\n",
      "Episode 1219, Average Score: 14.32, (24.59/13.17), Reward fraction 0.82\tTime 0.52, Noise rate 0.133. Better model.\n",
      "Episode 1220, Average Score: 14.38, (23.15/14.20), Reward fraction 0.82\tTime 0.39, Noise rate 0.133. Better model.\n",
      "Episode 1221, Average Score: 14.46, (22.10/13.69), Reward fraction 0.82\tTime 0.33, Noise rate 0.133. Better model.\n",
      "Episode 1222, Average Score: 14.57, (25.44/11.72), Reward fraction 0.82\tTime 0.55, Noise rate 0.133. Better model.\n",
      "Episode 1223, Average Score: 14.60, (19.02/10.84), Reward fraction 0.82\tTime 0.32, Noise rate 0.133. Better model.\n",
      "Episode 1224, Average Score: 14.63, (21.59/12.85), Reward fraction 0.82\tTime 0.54, Noise rate 0.133. Better model.\n",
      "Episode 1225, Average Score: 14.72, (23.64/13.05), Reward fraction 0.82\tTime 0.33, Noise rate 0.133. Better model.\n",
      "Episode 1226, Average Score: 14.82, (23.02/13.99), Reward fraction 0.82\tTime 0.54, Noise rate 0.133. Better model.\n",
      "Episode 1227, Average Score: 14.91, (21.49/13.70), Reward fraction 0.82\tTime 0.32, Noise rate 0.133. Better model.\n",
      "Episode 1228, Average Score: 14.97, (19.23/9.48), Reward fraction 0.82\tTime 0.31, Noise rate 0.133. Better model.\n",
      "Episode 1229, Average Score: 15.02, (21.12/11.32), Reward fraction 0.82\tTime 0.52, Noise rate 0.133. Better model.\n",
      "Episode 1230, Average Score: 15.03, (20.70/11.91), Reward fraction 0.82\tTime 0.30, Noise rate 0.133. Better model.\n",
      "Episode 1231, Average Score: 15.05, (13.97/5.89), Reward fraction 0.82\tTime 0.28, Noise rate 0.133. Better model.\n",
      "Episode 1232, Average Score: 15.07, (22.46/17.23), Reward fraction 0.82\tTime 0.31, Noise rate 0.133. Better model.\n",
      "Episode 1239, Average Score: 15.12, (21.67/17.15), Reward fraction 0.82\tTime 0.54, Noise rate 0.133. Better model.\n",
      "Episode 1240, Average Score: 15.22, (20.78/14.69), Reward fraction 0.82\tTime 0.30, Noise rate 0.133. Better model.\n",
      "Episode 1241, Average Score: 15.25, (21.56/11.38), Reward fraction 0.82\tTime 0.31, Noise rate 0.133. Better model.\n",
      "Episode 1243, Average Score: 15.30, (21.73/14.40), Reward fraction 0.82\tTime 0.52, Noise rate 0.133. Better model.\n",
      "Episode 1244, Average Score: 15.40, (24.49/19.61), Reward fraction 0.82\tTime 0.33, Noise rate 0.133. Better model.\n",
      "Episode 1245, Average Score: 15.48, (24.91/13.47), Reward fraction 0.82\tTime 0.51, Noise rate 0.133. Better model.\n",
      "Episode 1246, Average Score: 15.49, (20.57/8.78), Reward fraction 0.82\tTime 0.33, Noise rate 0.133. Better model.\n",
      "Episode 1249, Average Score: 15.53, (22.93/12.58), Reward fraction 0.82\tTime 0.57, Noise rate 0.133. Better model.\n",
      "Episode 1250, Average Score: 15.54, (18.59/6.74), Reward fraction 0.82\tTime 0.30, Noise rate 0.133. Better model.\n",
      "Episode 1296, Average Score: 15.55, (23.43/11.19), Reward fraction 0.83\tTime 0.54, Noise rate 0.130. Better model.\n",
      "Episode 1297, Average Score: 15.64, (23.87/13.22), Reward fraction 0.83\tTime 0.35, Noise rate 0.135. Better model.\n",
      "Episode 1298, Average Score: 15.68, (16.52/5.16), Reward fraction 0.83\tTime 0.29, Noise rate 0.135. Better model.\n",
      "Episode 1300, Average Score: 15.75, (24.13/13.27), Reward fraction 0.83\tTime 0.54, Noise rate 0.135. Better model.\n",
      "Episode 1300, Average Score: 15.75, (24.13/13.27), Reward fraction 0.83\tTime 0.54, Noise rate 0.135.\n",
      "Episode 1302, Average Score: 15.78, (23.74/13.82), Reward fraction 0.83\tTime 0.32, Noise rate 0.135. Better model.\n",
      "Episode 1303, Average Score: 15.83, (19.70/9.79), Reward fraction 0.83\tTime 0.49, Noise rate 0.135. Better model.\n",
      "Episode 1304, Average Score: 15.84, (18.79/10.15), Reward fraction 0.83\tTime 0.34, Noise rate 0.135. Better model.\n",
      "Episode 1307, Average Score: 15.87, (23.52/17.33), Reward fraction 0.83\tTime 0.59, Noise rate 0.135. Better model.\n",
      "Episode 1308, Average Score: 15.87, (19.20/6.75), Reward fraction 0.83\tTime 0.32, Noise rate 0.135. Better model.\n",
      "Episode 1309, Average Score: 15.98, (29.03/17.34), Reward fraction 0.83\tTime 0.57, Noise rate 0.135. Better model.\n",
      "Episode 1310, Average Score: 16.03, (14.38/6.66), Reward fraction 0.83\tTime 0.30, Noise rate 0.135. Better model.\n",
      "Episode 1311, Average Score: 16.20, (30.03/13.22), Reward fraction 0.83\tTime 0.36, Noise rate 0.135. Better model.\n",
      "Episode 1313, Average Score: 16.27, (27.54/20.03), Reward fraction 0.83\tTime 0.56, Noise rate 0.135. Better model.\n",
      "Episode 1314, Average Score: 16.31, (26.86/12.44), Reward fraction 0.83\tTime 0.53, Noise rate 0.135. Better model.\n",
      "Episode 1315, Average Score: 16.40, (20.58/10.92), Reward fraction 0.83\tTime 0.31, Noise rate 0.135. Better model.\n",
      "Episode 1316, Average Score: 16.46, (28.80/22.05), Reward fraction 0.83\tTime 0.56, Noise rate 0.126. Better model.\n",
      "Episode 1317, Average Score: 16.48, (17.71/13.86), Reward fraction 0.83\tTime 0.32, Noise rate 0.126. Better model.\n",
      "Episode 1318, Average Score: 16.53, (21.67/9.36), Reward fraction 0.83\tTime 0.32, Noise rate 0.126. Better model.\n",
      "Episode 1320, Average Score: 16.58, (29.15/18.84), Reward fraction 0.83\tTime 0.35, Noise rate 0.126. Better model.\n",
      "Episode 1321, Average Score: 16.63, (28.02/19.12), Reward fraction 0.83\tTime 0.58, Noise rate 0.126. Better model.\n",
      "Episode 1335, Average Score: 16.68, (23.14/16.28), Reward fraction 0.83\tTime 0.51, Noise rate 0.115. Better model.\n",
      "Episode 1336, Average Score: 16.73, (25.10/13.35), Reward fraction 0.83\tTime 0.34, Noise rate 0.115. Better model.\n",
      "Episode 1337, Average Score: 16.75, (27.76/13.25), Reward fraction 0.83\tTime 0.56, Noise rate 0.115. Better model.\n",
      "Episode 1338, Average Score: 16.79, (26.49/15.55), Reward fraction 0.83\tTime 0.54, Noise rate 0.115. Better model.\n",
      "Episode 1339, Average Score: 16.85, (27.16/21.53), Reward fraction 0.83\tTime 0.36, Noise rate 0.115. Better model.\n",
      "Episode 1341, Average Score: 16.88, (26.70/16.49), Reward fraction 0.83\tTime 0.35, Noise rate 0.115. Better model.\n",
      "Episode 1342, Average Score: 16.96, (24.84/17.64), Reward fraction 0.83\tTime 0.57, Noise rate 0.115. Better model.\n",
      "Episode 1343, Average Score: 17.00, (26.65/12.54), Reward fraction 0.83\tTime 0.38, Noise rate 0.115. Better model.\n",
      "Episode 1347, Average Score: 17.00, (22.87/16.32), Reward fraction 0.83\tTime 0.32, Noise rate 0.115. Better model.\n",
      "Episode 1350, Average Score: 17.07, (26.13/17.24), Reward fraction 0.83\tTime 0.34, Noise rate 0.115. Better model.\n",
      "Episode 1351, Average Score: 17.15, (22.10/13.33), Reward fraction 0.83\tTime 0.54, Noise rate 0.117. Better model.\n",
      "Episode 1352, Average Score: 17.18, (21.02/6.49), Reward fraction 0.83\tTime 0.31, Noise rate 0.117. Better model.\n",
      "Episode 1353, Average Score: 17.26, (22.69/8.75), Reward fraction 0.83\tTime 0.32, Noise rate 0.117. Better model.\n",
      "Episode 1354, Average Score: 17.34, (19.73/11.18), Reward fraction 0.83\tTime 0.55, Noise rate 0.117. Better model.\n",
      "Episode 1355, Average Score: 17.39, (24.10/16.27), Reward fraction 0.83\tTime 0.35, Noise rate 0.117. Better model.\n",
      "Episode 1356, Average Score: 17.47, (24.90/15.44), Reward fraction 0.83\tTime 0.54, Noise rate 0.117. Better model.\n",
      "Episode 1357, Average Score: 17.52, (22.79/13.39), Reward fraction 0.83\tTime 0.35, Noise rate 0.117. Better model.\n",
      "Episode 1360, Average Score: 17.60, (26.16/13.18), Reward fraction 0.83\tTime 0.37, Noise rate 0.117. Better model.\n",
      "Episode 1361, Average Score: 17.63, (27.70/19.54), Reward fraction 0.83\tTime 0.53, Noise rate 0.117. Better model.\n",
      "Episode 1362, Average Score: 17.66, (22.69/8.40), Reward fraction 0.83\tTime 0.35, Noise rate 0.117. Better model.\n",
      "Episode 1363, Average Score: 17.69, (21.79/12.47), Reward fraction 0.83\tTime 0.50, Noise rate 0.117. Better model.\n",
      "Episode 1364, Average Score: 17.76, (30.33/17.18), Reward fraction 0.83\tTime 0.35, Noise rate 0.117. Better model.\n",
      "Episode 1365, Average Score: 17.83, (25.80/17.78), Reward fraction 0.83\tTime 0.58, Noise rate 0.117. Better model.\n",
      "Episode 1366, Average Score: 17.94, (27.72/16.83), Reward fraction 0.83\tTime 0.54, Noise rate 0.117. Better model.\n",
      "Episode 1367, Average Score: 18.08, (26.45/16.23), Reward fraction 0.83\tTime 0.38, Noise rate 0.117. Better model.\n",
      "Episode 1368, Average Score: 18.15, (29.53/16.05), Reward fraction 0.83\tTime 0.57, Noise rate 0.120. Better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1370, Average Score: 18.26, (28.00/13.66), Reward fraction 0.83\tTime 0.56, Noise rate 0.120. Better model.\n",
      "Episode 1371, Average Score: 18.29, (16.42/6.90), Reward fraction 0.83\tTime 0.30, Noise rate 0.120. Better model.\n",
      "Episode 1372, Average Score: 18.43, (26.67/17.52), Reward fraction 0.83\tTime 0.53, Noise rate 0.120. Better model.\n",
      "Episode 1373, Average Score: 18.51, (24.38/17.75), Reward fraction 0.83\tTime 0.36, Noise rate 0.120. Better model.\n",
      "Episode 1374, Average Score: 18.59, (27.31/16.23), Reward fraction 0.83\tTime 0.53, Noise rate 0.120. Better model.\n",
      "Episode 1375, Average Score: 18.76, (30.80/20.75), Reward fraction 0.83\tTime 0.57, Noise rate 0.120. Better model.\n",
      "Episode 1376, Average Score: 18.81, (26.21/12.12), Reward fraction 0.83\tTime 0.38, Noise rate 0.120. Better model.\n",
      "Episode 1377, Average Score: 18.87, (23.28/15.05), Reward fraction 0.83\tTime 0.53, Noise rate 0.120. Better model.\n",
      "Episode 1378, Average Score: 19.01, (27.57/21.77), Reward fraction 0.84\tTime 0.40, Noise rate 0.120. Better model.\n",
      "Episode 1379, Average Score: 19.10, (19.47/14.05), Reward fraction 0.84\tTime 0.58, Noise rate 0.120. Better model.\n",
      "Episode 1380, Average Score: 19.12, (26.57/9.18), Reward fraction 0.84\tTime 0.36, Noise rate 0.120. Better model.\n",
      "Episode 1400, Average Score: 19.08, (26.87/14.66), Reward fraction 0.84\tTime 0.53, Noise rate 0.087.\n",
      "Episode 1401, Average Score: 19.13, (23.86/16.56), Reward fraction 0.84\tTime 0.36, Noise rate 0.087. Better model.\n",
      "Episode 1500, Average Score: 18.00, (25.64/18.38), Reward fraction 0.84\tTime 0.55, Noise rate 0.102.\n",
      "Episode 1600, Average Score: 17.94, (20.67/11.17), Reward fraction 0.85\tTime 0.36, Noise rate 0.105.\n",
      "Episode 1700, Average Score: 15.96, (14.34/4.90), Reward fraction 0.86\tTime 0.31, Noise rate 0.100..\n",
      "Episode 1800, Average Score: 18.50, (16.73/4.97), Reward fraction 0.86\tTime 0.35, Noise rate 0.072..\n",
      "Episode 1900, Average Score: 16.49, (27.13/9.95), Reward fraction 0.87\tTime 0.57, Noise rate 0.080..\n",
      "Episode 2000, Average Score: 17.72, (17.59/9.32), Reward fraction 0.87\tTime 0.55, Noise rate 0.080..\n",
      "Episode 2100, Average Score: 18.65, (13.71/3.54), Reward fraction 0.87\tTime 0.31, Noise rate 0.067..\n",
      "Episode 2200, Average Score: 18.78, (23.38/6.15), Reward fraction 0.88\tTime 0.41, Noise rate 0.066..\n",
      "Episode 2256, Average Score: 19.18, (27.90/12.63), Reward fraction 0.88\tTime 0.66, Noise rate 0.061. Better model.\n",
      "Episode 2257, Average Score: 19.24, (22.20/13.59), Reward fraction 0.88\tTime 0.37, Noise rate 0.061. Better model.\n",
      "Episode 2258, Average Score: 19.26, (23.30/12.88), Reward fraction 0.88\tTime 0.62, Noise rate 0.061. Better model.\n",
      "Episode 2259, Average Score: 19.30, (20.11/11.46), Reward fraction 0.88\tTime 0.39, Noise rate 0.061. Better model.\n",
      "Episode 2262, Average Score: 19.31, (24.17/14.72), Reward fraction 0.88\tTime 0.40, Noise rate 0.061. Better model.\n",
      "Episode 2263, Average Score: 19.34, (24.07/17.01), Reward fraction 0.88\tTime 0.60, Noise rate 0.061. Better model.\n",
      "Episode 2264, Average Score: 19.41, (29.89/20.93), Reward fraction 0.88\tTime 0.67, Noise rate 0.061. Better model.\n",
      "Episode 2266, Average Score: 19.47, (30.23/17.98), Reward fraction 0.88\tTime 0.62, Noise rate 0.061. Better model.\n",
      "Episode 2267, Average Score: 19.48, (22.31/16.73), Reward fraction 0.88\tTime 0.42, Noise rate 0.061. Better model.\n",
      "Episode 2268, Average Score: 19.60, (36.75/10.09), Reward fraction 0.88\tTime 0.70, Noise rate 0.061. Better model.\n",
      "Episode 2269, Average Score: 19.66, (26.80/8.38), Reward fraction 0.88\tTime 0.71, Noise rate 0.063. Better model.\n",
      "Episode 2270, Average Score: 19.69, (23.84/14.57), Reward fraction 0.88\tTime 0.38, Noise rate 0.063. Better model.\n",
      "Episode 2271, Average Score: 19.80, (31.90/15.06), Reward fraction 0.88\tTime 0.64, Noise rate 0.063. Better model.\n",
      "Episode 2272, Average Score: 19.83, (22.95/15.23), Reward fraction 0.88\tTime 0.64, Noise rate 0.063. Better model.\n",
      "Episode 2273, Average Score: 19.84, (24.75/15.59), Reward fraction 0.88\tTime 0.36, Noise rate 0.063. Better model.\n",
      "Episode 2278, Average Score: 19.89, (25.10/17.82), Reward fraction 0.88\tTime 0.43, Noise rate 0.063. Better model.\n",
      "Episode 2279, Average Score: 19.91, (22.72/13.28), Reward fraction 0.88\tTime 0.61, Noise rate 0.063. Better model.\n",
      "Episode 2280, Average Score: 19.96, (25.22/19.05), Reward fraction 0.88\tTime 0.45, Noise rate 0.063. Better model.\n",
      "Episode 2281, Average Score: 19.97, (28.23/18.57), Reward fraction 0.88\tTime 0.61, Noise rate 0.063. Better model.\n",
      "Episode 2282, Average Score: 20.04, (27.22/20.12), Reward fraction 0.88\tTime 0.62, Noise rate 0.063. Better model.\n",
      "Episode 2283, Average Score: 20.07, (26.37/15.98), Reward fraction 0.88\tTime 0.42, Noise rate 0.063. Better model.\n",
      "Episode 2284, Average Score: 20.11, (25.71/11.91), Reward fraction 0.88\tTime 0.60, Noise rate 0.063. Better model.\n",
      "Episode 2285, Average Score: 20.25, (27.29/18.64), Reward fraction 0.88\tTime 0.37, Noise rate 0.063. Better model.\n",
      "Episode 2286, Average Score: 20.29, (26.99/20.50), Reward fraction 0.88\tTime 0.68, Noise rate 0.054. Better model.\n",
      "Episode 2294, Average Score: 20.31, (26.20/16.00), Reward fraction 0.88\tTime 0.42, Noise rate 0.054. Better model.\n",
      "Episode 2295, Average Score: 20.32, (26.77/13.82), Reward fraction 0.88\tTime 0.61, Noise rate 0.054. Better model.\n",
      "Episode 2300, Average Score: 20.30, (24.70/17.48), Reward fraction 0.88\tTime 0.70, Noise rate 0.054.\n",
      "Episode 2318, Average Score: 20.35, (27.63/17.86), Reward fraction 0.88\tTime 0.63, Noise rate 0.049. Better model.\n",
      "Episode 2323, Average Score: 20.38, (29.55/17.36), Reward fraction 0.88\tTime 0.62, Noise rate 0.050. Better model.\n",
      "Episode 2324, Average Score: 20.44, (25.43/19.02), Reward fraction 0.88\tTime 0.36, Noise rate 0.050. Better model.\n",
      "Episode 2325, Average Score: 20.56, (30.85/19.73), Reward fraction 0.88\tTime 0.67, Noise rate 0.050. Better model.\n",
      "Episode 2326, Average Score: 20.58, (25.86/14.38), Reward fraction 0.88\tTime 0.62, Noise rate 0.050. Better model.\n",
      "Episode 2327, Average Score: 20.61, (25.23/17.18), Reward fraction 0.88\tTime 0.36, Noise rate 0.050. Better model.\n",
      "Episode 2328, Average Score: 20.70, (30.77/19.78), Reward fraction 0.88\tTime 0.70, Noise rate 0.050. Better model.\n",
      "Episode 2329, Average Score: 20.74, (25.75/18.24), Reward fraction 0.88\tTime 0.37, Noise rate 0.050. Better model.\n",
      "Episode 2331, Average Score: 20.77, (28.93/19.54), Reward fraction 0.88\tTime 0.39, Noise rate 0.050. Better model.\n",
      "Episode 2332, Average Score: 20.80, (26.43/21.13), Reward fraction 0.88\tTime 0.61, Noise rate 0.050. Better model.\n",
      "Episode 2333, Average Score: 20.87, (30.18/23.39), Reward fraction 0.88\tTime 0.67, Noise rate 0.050. Better model.\n",
      "Episode 2334, Average Score: 20.88, (27.41/11.36), Reward fraction 0.88\tTime 0.38, Noise rate 0.050. Better model.\n",
      "Episode 2335, Average Score: 20.93, (24.85/21.09), Reward fraction 0.88\tTime 0.68, Noise rate 0.058. Better model.\n",
      "Episode 2340, Average Score: 20.96, (24.60/18.29), Reward fraction 0.88\tTime 0.36, Noise rate 0.058. Better model.\n",
      "Episode 2342, Average Score: 20.98, (31.79/21.56), Reward fraction 0.88\tTime 0.63, Noise rate 0.058. Better model.\n",
      "Episode 2344, Average Score: 20.99, (31.53/11.90), Reward fraction 0.88\tTime 0.62, Noise rate 0.058. Better model.\n",
      "Episode 2345, Average Score: 21.06, (28.86/4.99), Reward fraction 0.88\tTime 0.63, Noise rate 0.058. Better model.\n",
      "Episode 2346, Average Score: 21.10, (20.05/11.81), Reward fraction 0.88\tTime 0.40, Noise rate 0.058. Better model.\n",
      "Episode 2347, Average Score: 21.18, (24.29/11.49), Reward fraction 0.88\tTime 0.39, Noise rate 0.058. Better model.\n",
      "Episode 2348, Average Score: 21.22, (27.09/19.76), Reward fraction 0.88\tTime 0.63, Noise rate 0.058. Better model.\n",
      "Episode 2349, Average Score: 21.29, (29.22/21.40), Reward fraction 0.88\tTime 0.46, Noise rate 0.058. Better model.\n",
      "Episode 2350, Average Score: 21.39, (24.09/21.54), Reward fraction 0.88\tTime 0.61, Noise rate 0.058. Better model.\n",
      "Episode 2352, Average Score: 21.41, (26.41/17.90), Reward fraction 0.88\tTime 0.66, Noise rate 0.049. Better model.\n",
      "Episode 2353, Average Score: 21.43, (26.50/16.34), Reward fraction 0.88\tTime 0.37, Noise rate 0.049. Better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2357, Average Score: 21.45, (28.44/18.19), Reward fraction 0.88\tTime 0.70, Noise rate 0.049. Better model.\n",
      "Episode 2358, Average Score: 21.45, (24.34/15.44), Reward fraction 0.88\tTime 0.38, Noise rate 0.049. Better model.\n",
      "Episode 2359, Average Score: 21.50, (24.95/18.00), Reward fraction 0.88\tTime 0.63, Noise rate 0.049. Better model.\n",
      "Episode 2360, Average Score: 21.51, (25.36/15.55), Reward fraction 0.88\tTime 0.46, Noise rate 0.049. Better model.\n",
      "Episode 2361, Average Score: 21.53, (23.63/19.84), Reward fraction 0.88\tTime 0.61, Noise rate 0.049. Better model.\n",
      "Episode 2362, Average Score: 21.57, (27.78/17.60), Reward fraction 0.88\tTime 0.44, Noise rate 0.049. Better model.\n",
      "Episode 2390, Average Score: 21.58, (28.16/13.47), Reward fraction 0.88\tTime 0.64, Noise rate 0.049. Better model.\n",
      "Episode 2392, Average Score: 21.63, (37.77/20.75), Reward fraction 0.88\tTime 0.67, Noise rate 0.049. Better model.\n",
      "Episode 2397, Average Score: 21.68, (33.02/20.09), Reward fraction 0.88\tTime 0.66, Noise rate 0.049. Better model.\n",
      "Episode 2398, Average Score: 21.70, (23.09/16.51), Reward fraction 0.88\tTime 0.69, Noise rate 0.049. Better model.\n",
      "Episode 2399, Average Score: 21.71, (24.39/14.07), Reward fraction 0.88\tTime 0.38, Noise rate 0.049. Better model.\n",
      "Episode 2400, Average Score: 21.70, (23.74/15.34), Reward fraction 0.88\tTime 0.61, Noise rate 0.049.\n",
      "Episode 2402, Average Score: 21.75, (26.86/16.81), Reward fraction 0.88\tTime 0.66, Noise rate 0.055. Better model.\n",
      "Episode 2403, Average Score: 21.80, (26.31/18.86), Reward fraction 0.88\tTime 0.39, Noise rate 0.055. Better model.\n",
      "Episode 2404, Average Score: 21.83, (24.85/15.06), Reward fraction 0.88\tTime 0.72, Noise rate 0.055. Better model.\n",
      "Episode 2405, Average Score: 21.91, (29.15/22.27), Reward fraction 0.88\tTime 0.69, Noise rate 0.055. Better model.\n",
      "Episode 2406, Average Score: 21.98, (29.93/19.36), Reward fraction 0.88\tTime 0.77, Noise rate 0.055. Better model.\n",
      "Episode 2407, Average Score: 22.00, (26.09/13.53), Reward fraction 0.88\tTime 0.66, Noise rate 0.055. Better model.\n",
      "Episode 2408, Average Score: 22.10, (30.89/21.44), Reward fraction 0.88\tTime 0.46, Noise rate 0.055. Better model.\n",
      "Episode 2409, Average Score: 22.17, (36.86/20.05), Reward fraction 0.88\tTime 0.71, Noise rate 0.055. Better model.\n",
      "Episode 2410, Average Score: 22.19, (27.01/19.27), Reward fraction 0.88\tTime 0.61, Noise rate 0.055. Better model.\n",
      "Episode 2412, Average Score: 22.23, (38.74/20.84), Reward fraction 0.88\tTime 0.67, Noise rate 0.055. Better model.\n",
      "Episode 2413, Average Score: 22.24, (24.53/14.77), Reward fraction 0.88\tTime 0.62, Noise rate 0.055. Better model.\n",
      "Episode 2414, Average Score: 22.24, (22.17/16.47), Reward fraction 0.88\tTime 0.42, Noise rate 0.055. Better model.\n",
      "Episode 2415, Average Score: 22.33, (23.16/17.63), Reward fraction 0.88\tTime 0.63, Noise rate 0.055. Better model.\n",
      "Episode 2419, Average Score: 22.37, (30.18/16.80), Reward fraction 0.88\tTime 0.72, Noise rate 0.047. Better model.\n",
      "Episode 2420, Average Score: 22.46, (29.25/18.09), Reward fraction 0.88\tTime 0.39, Noise rate 0.047. Better model.\n",
      "Episode 2426, Average Score: 22.52, (42.10/25.31), Reward fraction 0.88\tTime 0.70, Noise rate 0.047. Better model.\n",
      "Episode 2427, Average Score: 22.53, (25.10/19.25), Reward fraction 0.89\tTime 0.67, Noise rate 0.047. Better model.\n",
      "Episode 2430, Average Score: 22.62, (39.62/22.69), Reward fraction 0.89\tTime 0.78, Noise rate 0.047. Better model.\n",
      "Episode 2500, Average Score: 22.24, (24.19/18.06), Reward fraction 0.89\tTime 0.63, Noise rate 0.051.\n",
      "Episode 2536, Average Score: 22.63, (38.94/23.18), Reward fraction 0.89\tTime 0.74, Noise rate 0.049. Better model.\n",
      "Episode 2537, Average Score: 22.71, (28.49/22.51), Reward fraction 0.89\tTime 0.64, Noise rate 0.049. Better model.\n",
      "Episode 2538, Average Score: 22.73, (23.42/15.58), Reward fraction 0.89\tTime 0.38, Noise rate 0.049. Better model.\n",
      "Episode 2539, Average Score: 22.80, (27.37/18.66), Reward fraction 0.89\tTime 0.71, Noise rate 0.049. Better model.\n",
      "Episode 2540, Average Score: 22.82, (30.52/24.60), Reward fraction 0.89\tTime 0.65, Noise rate 0.049. Better model.\n",
      "Episode 2541, Average Score: 22.89, (34.47/22.17), Reward fraction 0.89\tTime 0.75, Noise rate 0.042. Better model.\n",
      "Episode 2549, Average Score: 22.97, (34.01/23.23), Reward fraction 0.89\tTime 0.71, Noise rate 0.042. Better model.\n",
      "Episode 2550, Average Score: 22.97, (24.44/14.64), Reward fraction 0.89\tTime 0.63, Noise rate 0.042. Better model.\n",
      "Episode 2551, Average Score: 23.03, (33.77/21.62), Reward fraction 0.89\tTime 0.48, Noise rate 0.042. Better model.\n",
      "Episode 2557, Average Score: 23.03, (26.18/22.04), Reward fraction 0.89\tTime 0.67, Noise rate 0.041. Better model.\n",
      "Episode 2558, Average Score: 23.16, (36.49/26.24), Reward fraction 0.89\tTime 0.82, Noise rate 0.041. Better model.\n",
      "Episode 2559, Average Score: 23.18, (24.35/16.42), Reward fraction 0.89\tTime 0.38, Noise rate 0.041. Better model.\n",
      "Episode 2560, Average Score: 23.23, (24.90/17.69), Reward fraction 0.89\tTime 0.65, Noise rate 0.041. Better model.\n",
      "Episode 2561, Average Score: 23.27, (27.60/20.47), Reward fraction 0.89\tTime 0.44, Noise rate 0.041. Better model.\n",
      "Episode 2562, Average Score: 23.28, (21.92/13.64), Reward fraction 0.89\tTime 0.62, Noise rate 0.041. Better model.\n",
      "Episode 2600, Average Score: 22.25, (21.30/13.37), Reward fraction 0.89\tTime 0.44, Noise rate 0.035.\n",
      "Episode 2700, Average Score: 20.25, (27.16/19.67), Reward fraction 0.89\tTime 0.39, Noise rate 0.039.\n",
      "Episode 2764, Average Score: 23.33, (53.95/23.83), Reward fraction 0.89\tTime 0.83, Noise rate 0.020. Better model.\n",
      "Episode 2765, Average Score: 23.39, (21.45/14.65), Reward fraction 0.89\tTime 0.39, Noise rate 0.020. Better model.\n",
      "Episode 2766, Average Score: 23.50, (32.90/21.46), Reward fraction 0.89\tTime 0.76, Noise rate 0.020. Better model.\n",
      "Episode 2767, Average Score: 23.55, (35.53/21.07), Reward fraction 0.89\tTime 0.69, Noise rate 0.020. Better model.\n",
      "Episode 2768, Average Score: 23.58, (26.73/22.63), Reward fraction 0.89\tTime 0.72, Noise rate 0.036. Better model.\n",
      "Episode 2769, Average Score: 23.63, (26.37/22.47), Reward fraction 0.89\tTime 0.39, Noise rate 0.036. Better model.\n",
      "Episode 2772, Average Score: 23.78, (52.22/24.24), Reward fraction 0.89\tTime 1.06, Noise rate 0.036. Better model.\n",
      "Episode 2773, Average Score: 23.98, (51.69/28.22), Reward fraction 0.89\tTime 1.23, Noise rate 0.036. Better model.\n",
      "Episode 2774, Average Score: 24.05, (41.93/13.89), Reward fraction 0.89\tTime 0.79, Noise rate 0.036. Better model.\n",
      "Episode 2775, Average Score: 24.22, (47.64/24.15), Reward fraction 0.89\tTime 1.03, Noise rate 0.036. Better model.\n",
      "Episode 2776, Average Score: 24.32, (41.78/13.96), Reward fraction 0.89\tTime 0.78, Noise rate 0.036. Better model.\n",
      "Episode 2777, Average Score: 24.33, (38.28/12.32), Reward fraction 0.89\tTime 1.01, Noise rate 0.036. Better model.\n",
      "Episode 2781, Average Score: 24.44, (41.62/15.21), Reward fraction 0.89\tTime 0.72, Noise rate 0.037. Better model.\n",
      "Episode 2782, Average Score: 24.50, (25.62/12.06), Reward fraction 0.89\tTime 0.76, Noise rate 0.037. Better model.\n",
      "Episode 2783, Average Score: 24.58, (27.14/22.24), Reward fraction 0.89\tTime 0.66, Noise rate 0.037. Better model.\n",
      "Episode 2784, Average Score: 24.65, (26.36/11.02), Reward fraction 0.89\tTime 0.42, Noise rate 0.037. Better model.\n",
      "Episode 2785, Average Score: 24.70, (30.95/7.47), Reward fraction 0.89\tTime 0.75, Noise rate 0.037. Better model.\n",
      "Episode 2786, Average Score: 24.70, (27.82/8.82), Reward fraction 0.89\tTime 0.41, Noise rate 0.037. Better model.\n",
      "Episode 2792, Average Score: 24.82, (46.31/21.47), Reward fraction 0.89\tTime 1.07, Noise rate 0.037. Better model.\n",
      "Episode 2793, Average Score: 24.83, (25.44/9.10), Reward fraction 0.89\tTime 0.41, Noise rate 0.037. Better model.\n",
      "Episode 2796, Average Score: 24.85, (43.24/20.71), Reward fraction 0.89\tTime 0.80, Noise rate 0.035. Better model.\n",
      "Episode 2797, Average Score: 24.93, (29.11/22.25), Reward fraction 0.89\tTime 0.66, Noise rate 0.035. Better model.\n",
      "Episode 2799, Average Score: 25.00, (33.79/23.24), Reward fraction 0.89\tTime 0.69, Noise rate 0.035. Better model.\n",
      "Episode 2800, Average Score: 24.98, (25.59/18.64), Reward fraction 0.89\tTime 0.69, Noise rate 0.035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2801, Average Score: 25.02, (31.10/25.02), Reward fraction 0.89\tTime 0.48, Noise rate 0.035. Better model.\n",
      "Episode 2802, Average Score: 25.06, (31.98/23.75), Reward fraction 0.89\tTime 0.70, Noise rate 0.035. Better model.\n",
      "Episode 2803, Average Score: 25.11, (30.03/23.39), Reward fraction 0.89\tTime 0.74, Noise rate 0.035. Better model.\n",
      "Episode 2804, Average Score: 25.11, (30.24/19.39), Reward fraction 0.89\tTime 0.39, Noise rate 0.035. Better model.\n",
      "Episode 2813, Average Score: 25.21, (30.87/24.93), Reward fraction 0.89\tTime 0.67, Noise rate 0.039. Better model.\n",
      "Episode 2815, Average Score: 25.26, (34.94/26.38), Reward fraction 0.89\tTime 0.43, Noise rate 0.039. Better model.\n",
      "Episode 2817, Average Score: 25.34, (30.91/24.58), Reward fraction 0.89\tTime 0.68, Noise rate 0.039. Better model.\n",
      "Episode 2818, Average Score: 25.37, (29.72/22.71), Reward fraction 0.89\tTime 0.47, Noise rate 0.039. Better model.\n",
      "Episode 2821, Average Score: 25.39, (32.13/16.34), Reward fraction 0.89\tTime 0.74, Noise rate 0.039. Better model.\n",
      "Episode 2825, Average Score: 25.43, (37.46/28.11), Reward fraction 0.89\tTime 0.77, Noise rate 0.034. Better model.\n",
      "Episode 2826, Average Score: 25.44, (30.05/9.82), Reward fraction 0.89\tTime 0.68, Noise rate 0.034. Better model.\n",
      "Episode 2827, Average Score: 25.65, (50.32/28.99), Reward fraction 0.89\tTime 1.11, Noise rate 0.034. Better model.\n",
      "Episode 2828, Average Score: 25.67, (31.66/25.10), Reward fraction 0.89\tTime 0.67, Noise rate 0.034. Better model.\n",
      "Episode 2829, Average Score: 25.78, (30.09/23.86), Reward fraction 0.89\tTime 0.48, Noise rate 0.034. Better model.\n",
      "Episode 2831, Average Score: 25.82, (38.79/24.10), Reward fraction 0.89\tTime 0.75, Noise rate 0.034. Better model.\n",
      "Episode 2832, Average Score: 25.85, (29.35/23.27), Reward fraction 0.89\tTime 0.75, Noise rate 0.034. Better model.\n",
      "Episode 2833, Average Score: 25.92, (29.93/9.88), Reward fraction 0.89\tTime 0.40, Noise rate 0.034. Better model.\n",
      "Episode 2834, Average Score: 26.02, (55.09/13.06), Reward fraction 0.89\tTime 1.13, Noise rate 0.034. Better model.\n",
      "Episode 2836, Average Score: 26.14, (54.51/25.53), Reward fraction 0.89\tTime 1.07, Noise rate 0.032. Better model.\n",
      "Episode 2837, Average Score: 26.25, (30.61/17.87), Reward fraction 0.89\tTime 0.68, Noise rate 0.032. Better model.\n",
      "Episode 2838, Average Score: 26.41, (45.83/19.36), Reward fraction 0.89\tTime 0.85, Noise rate 0.032. Better model.\n",
      "Episode 2839, Average Score: 26.43, (28.57/22.23), Reward fraction 0.89\tTime 0.69, Noise rate 0.032. Better model.\n",
      "Episode 2840, Average Score: 26.49, (28.70/21.70), Reward fraction 0.89\tTime 0.74, Noise rate 0.032. Better model.\n",
      "Episode 2841, Average Score: 26.60, (39.82/26.49), Reward fraction 0.89\tTime 0.74, Noise rate 0.032. Better model.\n",
      "Episode 2842, Average Score: 26.63, (35.05/18.14), Reward fraction 0.89\tTime 0.74, Noise rate 0.032. Better model.\n",
      "Episode 2843, Average Score: 26.70, (27.16/18.25), Reward fraction 0.89\tTime 0.39, Noise rate 0.032. Better model.\n",
      "Episode 2844, Average Score: 26.90, (52.16/31.44), Reward fraction 0.89\tTime 1.11, Noise rate 0.032. Better model.\n",
      "Episode 2845, Average Score: 26.93, (35.15/23.43), Reward fraction 0.89\tTime 0.69, Noise rate 0.032. Better model.\n",
      "Episode 2846, Average Score: 27.02, (32.96/26.10), Reward fraction 0.89\tTime 0.50, Noise rate 0.032. Better model.\n",
      "Episode 2848, Average Score: 27.05, (34.78/22.04), Reward fraction 0.89\tTime 0.72, Noise rate 0.032. Better model.\n",
      "Episode 2849, Average Score: 27.17, (37.41/24.35), Reward fraction 0.89\tTime 0.76, Noise rate 0.027. Better model.\n",
      "Episode 2850, Average Score: 27.24, (36.58/19.97), Reward fraction 0.89\tTime 0.70, Noise rate 0.027. Better model.\n",
      "Episode 2863, Average Score: 27.26, (42.48/13.88), Reward fraction 0.89\tTime 1.08, Noise rate 0.028. Better model.\n",
      "Episode 2864, Average Score: 27.31, (47.28/22.67), Reward fraction 0.89\tTime 1.11, Noise rate 0.028. Better model.\n",
      "Episode 2865, Average Score: 27.35, (25.53/19.07), Reward fraction 0.89\tTime 0.40, Noise rate 0.028. Better model.\n",
      "Episode 2866, Average Score: 27.37, (36.60/18.80), Reward fraction 0.89\tTime 0.69, Noise rate 0.028. Better model.\n",
      "Episode 2869, Average Score: 27.41, (35.28/24.66), Reward fraction 0.89\tTime 0.79, Noise rate 0.028. Better model.\n",
      "Episode 2870, Average Score: 27.61, (61.62/32.78), Reward fraction 0.89\tTime 1.14, Noise rate 0.028. Better model.\n",
      "Episode 2871, Average Score: 27.63, (31.88/22.50), Reward fraction 0.89\tTime 0.68, Noise rate 0.028. Better model.\n",
      "Episode 2893, Average Score: 27.65, (30.05/19.91), Reward fraction 0.89\tTime 0.69, Noise rate 0.030. Better model.\n",
      "Episode 2894, Average Score: 27.67, (30.78/13.68), Reward fraction 0.89\tTime 0.49, Noise rate 0.030. Better model.\n",
      "Episode 2896, Average Score: 27.70, (49.91/28.17), Reward fraction 0.89\tTime 1.16, Noise rate 0.030. Better model.\n",
      "Episode 2897, Average Score: 27.75, (34.65/22.95), Reward fraction 0.89\tTime 0.43, Noise rate 0.030. Better model.\n",
      "Episode 2898, Average Score: 27.81, (34.96/24.30), Reward fraction 0.89\tTime 0.78, Noise rate 0.030. Better model.\n",
      "Episode 2900, Average Score: 27.83, (32.05/20.45), Reward fraction 0.89\tTime 0.76, Noise rate 0.031. Better model.\n",
      "Episode 2900, Average Score: 27.83, (32.05/20.45), Reward fraction 0.89\tTime 0.76, Noise rate 0.031.\n",
      "Episode 2901, Average Score: 27.95, (49.47/30.27), Reward fraction 0.89\tTime 0.79, Noise rate 0.031. Better model.\n",
      "Episode 2902, Average Score: 27.97, (35.94/23.97), Reward fraction 0.89\tTime 0.79, Noise rate 0.031. Better model.\n",
      "Episode 2903, Average Score: 28.11, (59.52/22.82), Reward fraction 0.89\tTime 1.14, Noise rate 0.031. Better model.\n",
      "Episode 2904, Average Score: 28.14, (31.93/23.33), Reward fraction 0.89\tTime 0.68, Noise rate 0.031. Better model.\n",
      "Episode 2905, Average Score: 28.19, (29.29/15.10), Reward fraction 0.89\tTime 0.40, Noise rate 0.031. Better model.\n",
      "Episode 2906, Average Score: 28.25, (39.56/17.51), Reward fraction 0.89\tTime 1.07, Noise rate 0.031. Better model.\n",
      "Episode 2908, Average Score: 28.27, (28.00/23.34), Reward fraction 0.89\tTime 0.77, Noise rate 0.031. Better model.\n",
      "Episode 2911, Average Score: 28.28, (31.85/22.90), Reward fraction 0.89\tTime 0.42, Noise rate 0.031. Better model.\n",
      "Episode 2923, Average Score: 28.43, (51.08/25.31), Reward fraction 0.89\tTime 1.15, Noise rate 0.030. Better model.\n",
      "Episode 2924, Average Score: 28.49, (42.98/25.65), Reward fraction 0.89\tTime 1.09, Noise rate 0.033. Better model.\n",
      "Episode 2926, Average Score: 28.51, (31.26/26.68), Reward fraction 0.89\tTime 0.69, Noise rate 0.033. Better model.\n",
      "Episode 2927, Average Score: 28.54, (47.22/37.06), Reward fraction 0.89\tTime 0.82, Noise rate 0.033. Better model.\n",
      "Episode 2929, Average Score: 28.62, (51.91/31.41), Reward fraction 0.89\tTime 0.83, Noise rate 0.033. Better model.\n",
      "Episode 2930, Average Score: 28.68, (36.29/23.25), Reward fraction 0.89\tTime 0.73, Noise rate 0.033. Better model.\n",
      "Episode 2931, Average Score: 28.75, (46.02/29.19), Reward fraction 0.89\tTime 1.13, Noise rate 0.033. Better model.\n",
      "Episode 2932, Average Score: 28.76, (30.51/22.64), Reward fraction 0.89\tTime 0.69, Noise rate 0.033. Better model.\n",
      "Episode 2933, Average Score: 28.95, (56.19/19.62), Reward fraction 0.89\tTime 1.13, Noise rate 0.033. Better model.\n",
      "Episode 2935, Average Score: 29.01, (35.39/18.22), Reward fraction 0.89\tTime 0.45, Noise rate 0.033. Better model.\n",
      "Episode 2936, Average Score: 29.06, (52.12/27.43), Reward fraction 0.89\tTime 1.17, Noise rate 0.030. Better model.\n",
      "Episode 2938, Average Score: 29.22, (57.39/43.52), Reward fraction 0.89\tTime 1.17, Noise rate 0.030. Better model.\n",
      "Episode 2939, Average Score: 29.26, (36.24/14.02), Reward fraction 0.89\tTime 0.70, Noise rate 0.030. Better model.\n",
      "Episode 2941, Average Score: 29.29, (43.72/32.41), Reward fraction 0.89\tTime 1.04, Noise rate 0.030. Better model.\n",
      "Episode 2942, Average Score: 29.46, (48.87/25.49), Reward fraction 0.89\tTime 1.12, Noise rate 0.030. Better model.\n",
      "Episode 2943, Average Score: 29.51, (32.31/18.65), Reward fraction 0.89\tTime 0.42, Noise rate 0.030. Better model.\n",
      "Episode 2946, Average Score: 29.56, (48.79/18.99), Reward fraction 0.89\tTime 1.15, Noise rate 0.030. Better model.\n",
      "Episode 2947, Average Score: 29.68, (52.66/21.80), Reward fraction 0.89\tTime 1.16, Noise rate 0.032. Better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2948, Average Score: 29.70, (37.32/22.65), Reward fraction 0.89\tTime 0.73, Noise rate 0.032. Better model.\n",
      "Episode 2951, Average Score: 29.88, (52.29/33.82), Reward fraction 0.90\tTime 1.12, Noise rate 0.032. Better model.\n",
      "Episode 2952, Average Score: 30.16, (54.70/29.33), Reward fraction 0.90\tTime 0.78, Noise rate 0.032. Better model.\n",
      "Episode 2953, Average Score: 30.22, (34.74/23.13), Reward fraction 0.90\tTime 0.77, Noise rate 0.032. Better model.\n",
      "Episode 2954, Average Score: 30.23, (35.34/26.45), Reward fraction 0.90\tTime 0.74, Noise rate 0.032. Better model.\n",
      "Episode 2955, Average Score: 30.35, (40.01/26.73), Reward fraction 0.90\tTime 1.14, Noise rate 0.032. Better model.\n",
      "Episode 2956, Average Score: 30.42, (34.60/25.76), Reward fraction 0.90\tTime 0.43, Noise rate 0.032. Better model.\n",
      "Episode 2957, Average Score: 30.59, (49.37/23.02), Reward fraction 0.90\tTime 1.11, Noise rate 0.032. Better model.\n",
      "Episode 2958, Average Score: 30.72, (47.41/30.37), Reward fraction 0.90\tTime 0.77, Noise rate 0.032. Better model.\n",
      "Episode 2959, Average Score: 30.96, (55.39/25.89), Reward fraction 0.90\tTime 1.16, Noise rate 0.015. Better model.\n",
      "Episode 2974, Average Score: 30.98, (31.79/22.21), Reward fraction 0.90\tTime 0.41, Noise rate 0.026. Better model.\n",
      "Episode 2975, Average Score: 31.03, (39.75/14.47), Reward fraction 0.90\tTime 0.82, Noise rate 0.026. Better model.\n",
      "Episode 2976, Average Score: 31.06, (34.10/24.64), Reward fraction 0.90\tTime 0.70, Noise rate 0.026. Better model.\n",
      "Episode 2982, Average Score: 31.11, (45.33/24.03), Reward fraction 0.90\tTime 1.05, Noise rate 0.026. Better model.\n",
      "Episode 2987, Average Score: 31.17, (39.68/13.40), Reward fraction 0.90\tTime 0.84, Noise rate 0.027. Better model.\n",
      "Episode 2988, Average Score: 31.29, (51.20/22.50), Reward fraction 0.90\tTime 1.03, Noise rate 0.027. Better model.\n",
      "Episode 2989, Average Score: 31.29, (34.51/16.58), Reward fraction 0.90\tTime 0.78, Noise rate 0.027. Better model.\n",
      "Episode 2990, Average Score: 31.42, (52.80/21.82), Reward fraction 0.90\tTime 0.77, Noise rate 0.027. Better model.\n",
      "Episode 2994, Average Score: 31.44, (35.85/24.52), Reward fraction 0.90\tTime 0.70, Noise rate 0.027. Better model.\n",
      "Episode 3000, Average Score: 31.27, (30.74/15.06), Reward fraction 0.90\tTime 0.78, Noise rate 0.030.\n",
      "Episode 3016, Average Score: 31.53, (67.05/23.92), Reward fraction 0.90\tTime 1.23, Noise rate 0.028. Better model.\n",
      "Episode 3017, Average Score: 31.55, (35.11/10.08), Reward fraction 0.90\tTime 0.75, Noise rate 0.028. Better model.\n",
      "Episode 3018, Average Score: 31.63, (33.83/27.20), Reward fraction 0.90\tTime 0.79, Noise rate 0.028. Better model.\n",
      "Episode 3019, Average Score: 31.77, (50.57/23.46), Reward fraction 0.90\tTime 0.80, Noise rate 0.028. Better model.\n",
      "Episode 3063, Average Score: 31.78, (34.34/29.16), Reward fraction 0.90\tTime 0.79, Noise rate 0.026. Better model.\n",
      "Episode 3065, Average Score: 31.79, (35.31/27.31), Reward fraction 0.90\tTime 0.80, Noise rate 0.026. Better model.\n",
      "Episode 3068, Average Score: 31.89, (37.07/19.30), Reward fraction 0.90\tTime 0.46, Noise rate 0.026. Better model.\n",
      "Episode 3070, Average Score: 31.97, (49.04/29.50), Reward fraction 0.90\tTime 1.14, Noise rate 0.026. Better model.\n",
      "Episode 3071, Average Score: 32.05, (56.51/26.36), Reward fraction 0.90\tTime 1.17, Noise rate 0.028. Better model.\n",
      "Episode 3072, Average Score: 32.25, (57.57/30.47), Reward fraction 0.90\tTime 1.23, Noise rate 0.028. Better model.\n",
      "Episode 3081, Average Score: 32.30, (48.57/29.19), Reward fraction 0.90\tTime 1.19, Noise rate 0.028. Better model.\n",
      "Episode 3083, Average Score: 32.38, (51.85/23.16), Reward fraction 0.90\tTime 1.70, Noise rate 0.026. Better model.\n",
      "Episode 3084, Average Score: 32.42, (30.72/21.54), Reward fraction 0.90\tTime 0.79, Noise rate 0.026. Better model.\n",
      "Episode 3085, Average Score: 32.59, (48.60/32.99), Reward fraction 0.90\tTime 0.93, Noise rate 0.026. Better model.\n",
      "Episode 3093, Average Score: 32.62, (42.23/28.43), Reward fraction 0.90\tTime 0.86, Noise rate 0.026. Better model.\n",
      "Episode 3094, Average Score: 32.81, (65.76/26.37), Reward fraction 0.90\tTime 1.31, Noise rate 0.025. Better model.\n",
      "Episode 3097, Average Score: 32.91, (50.76/32.61), Reward fraction 0.90\tTime 1.11, Noise rate 0.025. Better model.\n",
      "Episode 3098, Average Score: 32.95, (37.78/30.02), Reward fraction 0.90\tTime 0.53, Noise rate 0.025. Better model.\n",
      "Episode 3099, Average Score: 33.08, (37.49/30.94), Reward fraction 0.90\tTime 0.74, Noise rate 0.025. Better model.\n",
      "Episode 3100, Average Score: 33.10, (34.68/15.26), Reward fraction 0.90\tTime 0.82, Noise rate 0.025. Better model.\n",
      "Episode 3100, Average Score: 33.10, (34.68/15.26), Reward fraction 0.90\tTime 0.82, Noise rate 0.025.\n",
      "Episode 3101, Average Score: 33.12, (42.05/14.31), Reward fraction 0.90\tTime 0.76, Noise rate 0.025. Better model.\n",
      "Episode 3102, Average Score: 33.27, (38.24/18.87), Reward fraction 0.90\tTime 0.77, Noise rate 0.025. Better model.\n",
      "Episode 3103, Average Score: 33.28, (34.97/27.51), Reward fraction 0.90\tTime 0.83, Noise rate 0.025. Better model.\n",
      "Episode 3105, Average Score: 33.42, (55.53/28.81), Reward fraction 0.90\tTime 0.90, Noise rate 0.025. Better model.\n",
      "Episode 3106, Average Score: 33.63, (37.69/32.56), Reward fraction 0.90\tTime 0.74, Noise rate 0.025. Better model.\n",
      "Episode 3107, Average Score: 33.78, (49.53/34.87), Reward fraction 0.90\tTime 1.18, Noise rate 0.023. Better model.\n",
      "Episode 3108, Average Score: 33.82, (35.08/30.02), Reward fraction 0.90\tTime 0.76, Noise rate 0.023. Better model.\n",
      "Episode 3116, Average Score: 33.82, (69.92/37.77), Reward fraction 0.90\tTime 1.19, Noise rate 0.023. Better model.\n",
      "Episode 3117, Average Score: 33.88, (37.13/30.36), Reward fraction 0.90\tTime 0.83, Noise rate 0.023. Better model.\n",
      "Episode 3118, Average Score: 33.89, (36.05/25.91), Reward fraction 0.90\tTime 0.74, Noise rate 0.023. Better model.\n",
      "Episode 3124, Average Score: 34.01, (90.35/46.81), Reward fraction 0.90\tTime 1.92, Noise rate 0.023. Better model.\n",
      "Episode 3125, Average Score: 34.02, (35.70/16.31), Reward fraction 0.90\tTime 0.76, Noise rate 0.023. Better model.\n",
      "Episode 3126, Average Score: 34.23, (57.92/20.92), Reward fraction 0.90\tTime 1.23, Noise rate 0.023. Better model.\n",
      "Episode 3127, Average Score: 34.40, (61.35/17.08), Reward fraction 0.90\tTime 1.22, Noise rate 0.023. Better model.\n",
      "Episode 3129, Average Score: 34.50, (67.43/23.69), Reward fraction 0.90\tTime 1.22, Noise rate 0.025. Better model.\n",
      "Episode 3130, Average Score: 34.50, (40.26/16.88), Reward fraction 0.90\tTime 0.78, Noise rate 0.025. Better model.\n",
      "Episode 3131, Average Score: 34.59, (49.87/34.52), Reward fraction 0.90\tTime 1.26, Noise rate 0.025. Better model.\n",
      "Episode 3134, Average Score: 34.60, (37.85/28.28), Reward fraction 0.90\tTime 0.74, Noise rate 0.025. Better model.\n",
      "Episode 3135, Average Score: 34.72, (50.96/33.19), Reward fraction 0.90\tTime 1.18, Noise rate 0.025. Better model.\n",
      "Episode 3136, Average Score: 34.84, (70.90/31.42), Reward fraction 0.90\tTime 1.61, Noise rate 0.025. Better model.\n",
      "Episode 3148, Average Score: 34.86, (56.24/33.50), Reward fraction 0.90\tTime 1.16, Noise rate 0.024. Better model.\n",
      "Episode 3152, Average Score: 34.86, (49.45/16.77), Reward fraction 0.90\tTime 1.13, Noise rate 0.023. Better model.\n",
      "Episode 3164, Average Score: 34.89, (52.42/23.84), Reward fraction 0.90\tTime 0.78, Noise rate 0.022. Better model.\n",
      "Episode 3165, Average Score: 34.90, (34.51/27.02), Reward fraction 0.90\tTime 0.86, Noise rate 0.022. Better model.\n",
      "Episode 3166, Average Score: 34.96, (34.57/25.57), Reward fraction 0.90\tTime 0.77, Noise rate 0.022. Better model.\n",
      "Episode 3167, Average Score: 35.05, (48.20/28.30), Reward fraction 0.90\tTime 0.97, Noise rate 0.022. Better model.\n",
      "Episode 3200, Average Score: 32.82, (33.09/23.35), Reward fraction 0.90\tTime 0.82, Noise rate 0.022.\n",
      "Episode 3300, Average Score: 29.81, (32.73/9.58), Reward fraction 0.91\tTime 0.89, Noise rate 0.020..\n",
      "Episode 3400, Average Score: 26.05, (39.09/14.34), Reward fraction 0.92\tTime 1.20, Noise rate 0.018.\n",
      "Episode 3500, Average Score: 27.48, (35.90/24.94), Reward fraction 0.92\tTime 0.47, Noise rate 0.015.\n",
      "Episode 3600, Average Score: 30.39, (30.02/-3.99), Reward fraction 0.93\tTime 0.52, Noise rate 0.012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3700, Average Score: 30.98, (35.50/20.49), Reward fraction 0.93\tTime 0.85, Noise rate 0.012.\n",
      "Episode 3757, Average Score: 35.19, (84.53/35.19), Reward fraction 0.93\tTime 1.73, Noise rate 0.010. Better model.\n",
      "Episode 3758, Average Score: 35.25, (68.39/26.76), Reward fraction 0.93\tTime 1.30, Noise rate 0.010. Better model.\n",
      "Episode 3767, Average Score: 35.29, (69.17/44.81), Reward fraction 0.93\tTime 1.60, Noise rate 0.011. Better model.\n",
      "Episode 3768, Average Score: 35.37, (41.74/16.14), Reward fraction 0.93\tTime 0.80, Noise rate 0.011. Better model.\n",
      "Episode 3769, Average Score: 35.43, (39.52/31.39), Reward fraction 0.93\tTime 0.57, Noise rate 0.011. Better model.\n",
      "Episode 3770, Average Score: 35.52, (47.56/23.47), Reward fraction 0.93\tTime 1.10, Noise rate 0.011. Better model.\n",
      "Episode 3771, Average Score: 35.62, (50.33/15.25), Reward fraction 0.93\tTime 0.92, Noise rate 0.011. Better model.\n",
      "Episode 3772, Average Score: 35.98, (78.57/40.00), Reward fraction 0.93\tTime 1.67, Noise rate 0.010. Better model.\n",
      "Episode 3773, Average Score: 36.10, (39.38/31.08), Reward fraction 0.93\tTime 0.79, Noise rate 0.010. Better model.\n",
      "Episode 3774, Average Score: 36.14, (34.13/30.59), Reward fraction 0.93\tTime 0.84, Noise rate 0.010. Better model.\n",
      "Episode 3775, Average Score: 36.18, (45.44/31.66), Reward fraction 0.93\tTime 0.78, Noise rate 0.010. Better model.\n",
      "Episode 3776, Average Score: 36.24, (38.30/32.12), Reward fraction 0.93\tTime 0.85, Noise rate 0.010. Better model.\n",
      "Episode 3777, Average Score: 36.27, (41.58/14.28), Reward fraction 0.93\tTime 0.79, Noise rate 0.010. Better model.\n",
      "Episode 3787, Average Score: 36.29, (38.63/12.63), Reward fraction 0.93\tTime 0.54, Noise rate 0.010. Better model.\n",
      "Episode 3800, Average Score: 35.60, (52.52/9.66), Reward fraction 0.93\tTime 1.23, Noise rate 0.009..\n",
      "Episode 3900, Average Score: 33.27, (41.68/28.61), Reward fraction 0.93\tTime 0.88, Noise rate 0.009.\n",
      "Episode 3930, Average Score: 36.31, (54.72/17.76), Reward fraction 0.93\tTime 1.21, Noise rate 0.008. Better model.\n",
      "Episode 3932, Average Score: 36.57, (80.29/11.60), Reward fraction 0.93\tTime 2.05, Noise rate 0.008. Better model.\n",
      "Episode 3933, Average Score: 36.60, (41.07/15.49), Reward fraction 0.93\tTime 0.88, Noise rate 0.008. Better model.\n",
      "Episode 3934, Average Score: 36.86, (70.22/5.39), Reward fraction 0.93\tTime 1.57, Noise rate 0.008. Better model.\n",
      "Episode 3939, Average Score: 36.97, (59.52/13.44), Reward fraction 0.93\tTime 1.25, Noise rate 0.008. Better model.\n",
      "Episode 3982, Average Score: 36.99, (54.55/20.64), Reward fraction 0.93\tTime 0.89, Noise rate 0.008. Better model.\n",
      "Episode 3983, Average Score: 37.00, (36.57/19.85), Reward fraction 0.93\tTime 0.74, Noise rate 0.008. Better model.\n",
      "Episode 3985, Average Score: 37.13, (54.01/36.19), Reward fraction 0.93\tTime 0.84, Noise rate 0.008. Better model.\n",
      "Episode 3986, Average Score: 37.14, (45.53/34.69), Reward fraction 0.93\tTime 0.88, Noise rate 0.008. Better model.\n",
      "Episode 3987, Average Score: 37.36, (40.44/33.22), Reward fraction 0.93\tTime 0.78, Noise rate 0.008. Better model.\n",
      "Episode 3988, Average Score: 37.53, (90.44/40.92), Reward fraction 0.93\tTime 1.67, Noise rate 0.008. Better model.\n",
      "Episode 4000, Average Score: 36.79, (46.60/19.48), Reward fraction 0.93\tTime 0.89, Noise rate 0.008.\n",
      "Episode 4011, Average Score: 37.58, (51.99/35.36), Reward fraction 0.93\tTime 1.10, Noise rate 0.008. Better model.\n",
      "Episode 4013, Average Score: 37.78, (72.34/44.36), Reward fraction 0.93\tTime 1.31, Noise rate 0.007. Better model.\n",
      "Episode 4018, Average Score: 37.93, (61.09/20.08), Reward fraction 0.93\tTime 1.18, Noise rate 0.007. Better model.\n",
      "Episode 4021, Average Score: 37.95, (70.25/14.48), Reward fraction 0.93\tTime 1.65, Noise rate 0.007. Better model.\n",
      "Episode 4022, Average Score: 38.24, (71.51/42.18), Reward fraction 0.93\tTime 1.26, Noise rate 0.007. Better model.\n",
      "Episode 4023, Average Score: 38.54, (84.75/50.91), Reward fraction 0.93\tTime 1.69, Noise rate 0.007. Better model.\n",
      "Episode 4024, Average Score: 38.86, (91.63/38.66), Reward fraction 0.93\tTime 1.99, Noise rate 0.007. Better model.\n",
      "Episode 4028, Average Score: 38.88, (56.03/35.05), Reward fraction 0.93\tTime 0.92, Noise rate 0.007. Better model.\n",
      "Episode 4035, Average Score: 39.03, (47.15/37.32), Reward fraction 0.93\tTime 0.80, Noise rate 0.007. Better model.\n",
      "Episode 4036, Average Score: 39.28, (95.04/37.99), Reward fraction 0.93\tTime 2.48, Noise rate 0.007. Better model.\n",
      "Episode 4037, Average Score: 39.33, (41.26/25.67), Reward fraction 0.93\tTime 0.79, Noise rate 0.007. Better model.\n",
      "Episode 4041, Average Score: 39.44, (58.30/24.89), Reward fraction 0.93\tTime 1.23, Noise rate 0.007. Better model.\n",
      "Episode 4042, Average Score: 39.46, (49.77/35.92), Reward fraction 0.93\tTime 0.79, Noise rate 0.007. Better model.\n",
      "Episode 4043, Average Score: 39.78, (79.72/34.43), Reward fraction 0.93\tTime 1.31, Noise rate 0.007. Better model.\n",
      "Episode 4044, Average Score: 39.83, (43.78/36.44), Reward fraction 0.93\tTime 0.79, Noise rate 0.007. Better model.\n",
      "Episode 4046, Average Score: 40.03, (81.99/20.03), Reward fraction 0.93\tTime 1.59, Noise rate 0.007. Better model.\n",
      "Episode 4049, Average Score: 40.16, (74.61/31.77), Reward fraction 0.93\tTime 1.51, Noise rate 0.007. Better model.\n",
      "Episode 4051, Average Score: 40.18, (54.87/18.16), Reward fraction 0.93\tTime 0.83, Noise rate 0.007. Better model.\n",
      "Episode 4053, Average Score: 40.22, (36.38/16.77), Reward fraction 0.93\tTime 0.77, Noise rate 0.007. Better model.\n",
      "Episode 4054, Average Score: 40.25, (31.96/22.72), Reward fraction 0.93\tTime 0.54, Noise rate 0.006. Better model.\n",
      "Episode 4055, Average Score: 40.40, (34.05/11.58), Reward fraction 0.93\tTime 0.76, Noise rate 0.006. Better model.\n",
      "Episode 4056, Average Score: 40.53, (38.14/15.42), Reward fraction 0.93\tTime 0.85, Noise rate 0.006. Better model.\n",
      "Episode 4058, Average Score: 40.69, (49.65/23.99), Reward fraction 0.93\tTime 1.36, Noise rate 0.006. Better model.\n",
      "Episode 4059, Average Score: 40.71, (40.69/17.48), Reward fraction 0.93\tTime 0.87, Noise rate 0.006. Better model.\n",
      "Episode 4060, Average Score: 40.77, (74.46/28.59), Reward fraction 0.93\tTime 1.32, Noise rate 0.006. Better model.\n",
      "Episode 4063, Average Score: 40.83, (60.95/24.26), Reward fraction 0.93\tTime 1.17, Noise rate 0.006. Better model.\n",
      "Episode 4064, Average Score: 41.14, (113.38/24.86), Reward fraction 0.93\tTime 6.65, Noise rate 0.008. Better model.\n",
      "Episode 4068, Average Score: 41.34, (69.35/42.31), Reward fraction 0.93\tTime 1.30, Noise rate 0.008. Better model.\n",
      "Episode 4070, Average Score: 41.56, (81.38/40.30), Reward fraction 0.93\tTime 1.21, Noise rate 0.007. Better model.\n",
      "Episode 4100, Average Score: 40.37, (41.24/24.89), Reward fraction 0.93\tTime 0.79, Noise rate 0.007.\n",
      "Episode 4200, Average Score: 40.45, (45.55/13.06), Reward fraction 0.93\tTime 0.79, Noise rate 0.006..\n",
      "Episode 4235, Average Score: 41.71, (172.73/19.94), Reward fraction 0.93\tTime 3.28, Noise rate 0.004. Better model.\n",
      "Episode 4238, Average Score: 41.74, (69.41/15.58), Reward fraction 0.93\tTime 0.94, Noise rate 0.004. Better model.\n",
      "Episode 4247, Average Score: 41.92, (99.62/23.80), Reward fraction 0.93\tTime 7.00, Noise rate 0.004. Better model.\n",
      "Episode 4249, Average Score: 42.03, (74.18/35.93), Reward fraction 0.93\tTime 1.21, Noise rate 0.006. Better model.\n",
      "Episode 4250, Average Score: 42.09, (50.15/22.41), Reward fraction 0.93\tTime 1.20, Noise rate 0.006. Better model.\n",
      "Episode 4251, Average Score: 42.33, (65.66/34.17), Reward fraction 0.93\tTime 1.23, Noise rate 0.006. Better model.\n",
      "Episode 4252, Average Score: 42.65, (85.86/43.51), Reward fraction 0.93\tTime 1.23, Noise rate 0.006. Better model.\n",
      "Episode 4253, Average Score: 42.69, (78.06/13.16), Reward fraction 0.93\tTime 1.64, Noise rate 0.006. Better model.\n",
      "Episode 4254, Average Score: 42.75, (36.30/28.42), Reward fraction 0.93\tTime 0.54, Noise rate 0.006. Better model.\n",
      "Episode 4255, Average Score: 42.94, (58.86/22.62), Reward fraction 0.93\tTime 1.12, Noise rate 0.006. Better model.\n",
      "Episode 4256, Average Score: 43.29, (88.48/25.28), Reward fraction 0.93\tTime 1.61, Noise rate 0.006. Better model.\n",
      "Episode 4257, Average Score: 43.42, (91.75/33.51), Reward fraction 0.93\tTime 1.36, Noise rate 0.005. Better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4261, Average Score: 43.48, (96.35/37.39), Reward fraction 0.93\tTime 1.70, Noise rate 0.005. Better model.\n",
      "Episode 4262, Average Score: 43.70, (72.54/23.79), Reward fraction 0.93\tTime 1.50, Noise rate 0.005. Better model.\n",
      "Episode 4263, Average Score: 43.88, (78.22/13.14), Reward fraction 0.93\tTime 1.27, Noise rate 0.005. Better model.\n",
      "Episode 4264, Average Score: 44.19, (106.29/29.06), Reward fraction 0.93\tTime 3.73, Noise rate 0.006. Better model.\n",
      "Episode 4265, Average Score: 44.24, (45.74/15.58), Reward fraction 0.93\tTime 0.87, Noise rate 0.006. Better model.\n",
      "Episode 4286, Average Score: 44.46, (83.55/41.95), Reward fraction 0.93\tTime 1.64, Noise rate 0.005. Better model.\n",
      "Episode 4287, Average Score: 44.56, (86.64/20.51), Reward fraction 0.93\tTime 1.65, Noise rate 0.005. Better model.\n",
      "Episode 4288, Average Score: 44.78, (75.61/38.55), Reward fraction 0.93\tTime 0.87, Noise rate 0.005. Better model.\n",
      "Episode 4289, Average Score: 44.79, (44.27/29.05), Reward fraction 0.93\tTime 1.18, Noise rate 0.005. Better model.\n",
      "Episode 4290, Average Score: 44.79, (74.55/33.55), Reward fraction 0.93\tTime 1.28, Noise rate 0.005. Better model.\n",
      "Episode 4294, Average Score: 44.79, (96.31/19.61), Reward fraction 0.93\tTime 1.99, Noise rate 0.005. Better model.\n",
      "Episode 4295, Average Score: 44.85, (46.46/30.64), Reward fraction 0.93\tTime 0.87, Noise rate 0.005. Better model.\n",
      "Episode 4296, Average Score: 45.02, (108.97/46.17), Reward fraction 0.93\tTime 1.76, Noise rate 0.005. Better model.\n",
      "Episode 4297, Average Score: 45.36, (83.74/40.48), Reward fraction 0.93\tTime 1.62, Noise rate 0.005. Better model.\n",
      "Episode 4298, Average Score: 45.60, (130.56/42.91), Reward fraction 0.93\tTime 2.42, Noise rate 0.005. Better model.\n",
      "Episode 4299, Average Score: 46.22, (165.06/41.65), Reward fraction 0.93\tTime 3.32, Noise rate 0.005. Better model.\n",
      "Episode 4300, Average Score: 46.22, (42.34/31.12), Reward fraction 0.93\tTime 0.85, Noise rate 0.005.\n",
      "Episode 4302, Average Score: 46.62, (101.68/57.87), Reward fraction 0.93\tTime 2.09, Noise rate 0.005. Better model.\n",
      "Episode 4303, Average Score: 46.70, (61.42/7.12), Reward fraction 0.93\tTime 1.21, Noise rate 0.005. Better model.\n",
      "Episode 4305, Average Score: 46.77, (60.96/35.54), Reward fraction 0.93\tTime 1.22, Noise rate 0.005. Better model.\n",
      "Episode 4327, Average Score: 46.88, (77.25/50.67), Reward fraction 0.93\tTime 1.29, Noise rate 0.004. Better model.\n",
      "Episode 4330, Average Score: 46.89, (57.68/38.76), Reward fraction 0.93\tTime 1.15, Noise rate 0.004. Better model.\n",
      "Episode 4331, Average Score: 47.19, (78.15/44.66), Reward fraction 0.93\tTime 1.33, Noise rate 0.004. Better model.\n",
      "Episode 4332, Average Score: 47.64, (117.59/53.79), Reward fraction 0.93\tTime 2.02, Noise rate 0.004. Better model.\n",
      "Episode 4333, Average Score: 47.88, (74.43/36.21), Reward fraction 0.93\tTime 1.66, Noise rate 0.004. Better model.\n",
      "Episode 4337, Average Score: 48.14, (99.24/61.75), Reward fraction 0.93\tTime 1.73, Noise rate 0.004. Better model.\n",
      "Episode 4339, Average Score: 48.20, (58.11/28.97), Reward fraction 0.93\tTime 0.81, Noise rate 0.004. Better model.\n",
      "Episode 4340, Average Score: 48.58, (87.05/39.04), Reward fraction 0.93\tTime 1.60, Noise rate 0.004. Better model.\n",
      "Episode 4342, Average Score: 48.91, (97.66/19.77), Reward fraction 0.93\tTime 1.65, Noise rate 0.004. Better model.\n",
      "Episode 4343, Average Score: 48.98, (78.23/25.90), Reward fraction 0.93\tTime 1.28, Noise rate 0.004. Better model.\n",
      "Episode 4344, Average Score: 48.99, (34.77/29.71), Reward fraction 0.93\tTime 0.84, Noise rate 0.004. Better model.\n",
      "Episode 4346, Average Score: 49.10, (72.12/18.71), Reward fraction 0.93\tTime 1.28, Noise rate 0.004. Better model.\n",
      "Episode 4348, Average Score: 49.13, (37.68/21.88), Reward fraction 0.93\tTime 0.77, Noise rate 0.004. Better model.\n",
      "Episode 4368, Average Score: 49.26, (97.19/38.66), Reward fraction 0.93\tTime 1.70, Noise rate 0.004. Better model.\n",
      "Episode 4377, Average Score: 49.59, (152.05/48.85), Reward fraction 0.93\tTime 2.44, Noise rate 0.004. Better model.\n",
      "Episode 4381, Average Score: 49.65, (138.38/41.26), Reward fraction 0.93\tTime 3.26, Noise rate 0.004. Better model.\n",
      "Episode 4383, Average Score: 49.79, (90.38/32.57), Reward fraction 0.93\tTime 1.54, Noise rate 0.004. Better model.\n",
      "Episode 4384, Average Score: 50.18, (102.78/52.69), Reward fraction 0.93\tTime 2.15, Noise rate 0.004. Better model.\n",
      "Episode 4400, Average Score: 47.69, (34.26/28.25), Reward fraction 0.93\tTime 0.84, Noise rate 0.004..\n",
      "Episode 4500, Average Score: 48.87, (63.30/19.19), Reward fraction 0.93\tTime 1.24, Noise rate 0.003..\n",
      "Episode 4600, Average Score: 42.21, (46.76/9.57), Reward fraction 0.93\tTime 0.95, Noise rate 0.003....\n",
      "Episode 4700, Average Score: 34.48, (36.66/30.38), Reward fraction 0.93\tTime 0.56, Noise rate 0.003..\n",
      "Episode 4800, Average Score: 44.00, (45.98/35.78), Reward fraction 0.93\tTime 0.88, Noise rate 0.002..\n",
      "Episode 4900, Average Score: 48.21, (21.04/6.62), Reward fraction 0.93\tTime 0.42, Noise rate 0.002...\n",
      "Episode 5000, Average Score: 44.49, (39.65/27.34), Reward fraction 0.92\tTime 0.76, Noise rate 0.001..\n"
     ]
    }
   ],
   "source": [
    "# Run for the crawler agent environment \n",
    "with Environment (envFile='.\\Crawler_Windows_x86_64\\Crawler.exe') as env:\n",
    "    crawler = ddpg ( 'Crawler', Agent(env, random_seed=2), goal=2000, n_episodes=5000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotScores( crawler )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crawler environment is not solved. But it shows and continous improvement over time and tuning the parameters to this environment could probably also make it resolve the environment. It may be nessecary to run it for additional episodes.\n",
    "\n",
    "\n",
    "\n",
    "### 3. Conclusion\n",
    "\n",
    "It is possible to create a deep reinforcement learning network that almost without changes can solve a number of different tasks. Though it dident solve all environments here it show a positive trend that with additional tuning of the hyper parameters most likely would be able to solve it.\n",
    "\n",
    "The 20 agent version of the Reacher environment was solved in 107 episodes.\n",
    "\n",
    "\n",
    "The adjustment of hyper parameters for the neural networks, replay buffers and noise generators is highly handcraft and luck. What seems to be intuitive has the complete opposite result. An example would be to increasing the replay buffer - and therefor having more old data in it. I would assume that it lowered the performance but to opposite happened.\n",
    "\n",
    "The experiment to fill the replay buffer with succesful actions would also seem to be a way to improve leaning, but as can be taken from the first run this did not happen.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 4. Future improvements\n",
    "\n",
    "Futur improvements could be:\n",
    "* Automation of hyper parameter finding. Ex: grid search.\n",
    "* Futher fine tuning of the hyper parameters to solve all environments. \n",
    "* Try out other deep reinforcement learning algorithmes like PPO\n",
    "* Investigate why the arm does not learn to find the goal by putting it up in place and wait for the goal to come and hit.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
